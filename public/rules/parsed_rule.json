{
  "rules": [
    {
      "name": "CollectDuplexSeqMetrics",
      "input": {
        "default": "mapped/{sample}.gu.bam"
      },
      "output": {
        "family_sizes": "stats/{sample}.family_sizes.txt",
        "duplex_family_sizes": "stats/{sample}.duplex_family_sizes.txt",
        "duplex_yield_metrics": "stats/{sample}.duplex_yield_metrics.txt",
        "umi_counts": "stats/{sample}.umi_counts.txt",
        "duplex_qc": "stats/{sample}.duplex_qc.pdf",
        "duplex_umi_counts": "stats/{sample}.duplex_umi_counts.txt"
      },
      "log": {
        "default": "logs/fgbio/collectduplexseqmetrics/{sample}.log"
      },
      "params": {
        "extra": "lambda wildcards: '-d ' + wildcards.sample"
      },
      "wrapper": {
        "default": "master/bio/fgbio/collectduplexseqmetrics"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule CollectDuplexSeqMetrics:\n    input:\n        \"mapped/{sample}.gu.bam\"\n    output:\n        family_sizes=\"stats/{sample}.family_sizes.txt\",\n        duplex_family_sizes=\"stats/{sample}.duplex_family_sizes.txt\",\n        duplex_yield_metrics=\"stats/{sample}.duplex_yield_metrics.txt\",\n        umi_counts=\"stats/{sample}.umi_counts.txt\",\n        duplex_qc=\"stats/{sample}.duplex_qc.pdf\",\n        duplex_umi_counts=\"stats/{sample}.duplex_umi_counts.txt\",\n    params:\n        extra=lambda wildcards: \"-d \" + wildcards.sample\n    log:\n        \"logs/fgbio/collectduplexseqmetrics/{sample}.log\"\n    wrapper:\n        \"master/bio/fgbio/collectduplexseqmetrics\"\n"
    },
    {
      "name": "CollectTargetedPcrMetrics",
      "input": {
        "bam": "mapped/{sample}.bam",
        "amplicon_intervals": "amplicon.interval_list",
        "target_intervals": "target.interval_list"
      },
      "output": {
        "default": "stats/{sample}.pcr.txt"
      },
      "log": {
        "default": "logs/picard/collecttargetedpcrmetrics/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/picard/collecttargetedpcrmetrics"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule CollectTargetedPcrMetrics:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        amplicon_intervals=\"amplicon.interval_list\",\n        target_intervals=\"target.interval_list\",\n    output:\n        \"stats/{sample}.pcr.txt\",\n    log:\n        \"logs/picard/collecttargetedpcrmetrics/{sample}.log\",\n    params:\n        extra=\"\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/collecttargetedpcrmetrics\"\n"
    },
    {
      "name": "ConsensusReads",
      "input": {
        "default": "mapped/a.bam"
      },
      "output": {
        "default": "mapped/{sample}.m3.bam"
      },
      "log": {
        "default": "logs/fgbio/consensus_reads/{sample}.log"
      },
      "params": {
        "extra": "-M 3"
      },
      "wrapper": {
        "default": "master/bio/fgbio/callmolecularconsensusreads"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule ConsensusReads:\n    input:\n        \"mapped/a.bam\"\n    output:\n        \"mapped/{sample}.m3.bam\"\n    params:\n        extra=\"-M 3\"\n    log:\n        \"logs/fgbio/consensus_reads/{sample}.log\"\n    wrapper:\n        \"master/bio/fgbio/callmolecularconsensusreads\"\n"
    },
    {
      "name": "FilterConsensusReads",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.filtered.bam"
      },
      "log": {
        "default": "logs/fgbio/filterconsensusreads/{sample}.log"
      },
      "params": {
        "extra": "",
        "min_base_quality": 2,
        "min_reads": [
          2,
          2,
          2
        ],
        "ref": "genome.fasta"
      },
      "wrapper": {
        "default": "master/bio/fgbio/filterconsensusreads"
      },
      "input_types": [
        "bam file",
        "vcf files",
        "reference genome"
      ],
      "output_types": [
        "filtered bam file"
      ],
      "rule": "rule FilterConsensusReads:\n    input:\n        \"mapped/{sample}.bam\"\n    output:\n        \"mapped/{sample}.filtered.bam\"\n    params:\n        extra=\"\",\n        min_base_quality=2,\n        min_reads=[2, 2, 2],\n        ref=\"genome.fasta\"\n    log:\n        \"logs/fgbio/filterconsensusreads/{sample}.log\"\n    threads: 1\n    wrapper:\n        \"master/bio/fgbio/filterconsensusreads\"\n"
    },
    {
      "name": "GroupReads",
      "input": {
        "default": "mapped/a.bam"
      },
      "output": {
        "bam": "mapped/{sample}.gu.bam",
        "hist": "mapped/{sample}.gu.histo.tsv"
      },
      "log": {
        "default": "logs/fgbio/group_reads/{sample}.log"
      },
      "params": {
        "extra": "-s adjacency --edits 1"
      },
      "wrapper": {
        "default": "master/bio/fgbio/groupreadsbyumi"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule GroupReads:\n    input:\n        \"mapped/a.bam\"\n    output:\n        bam=\"mapped/{sample}.gu.bam\",\n        hist=\"mapped/{sample}.gu.histo.tsv\",\n    params:\n        extra=\"-s adjacency --edits 1\"\n    log:\n        \"logs/fgbio/group_reads/{sample}.log\"\n    wrapper:\n        \"master/bio/fgbio/groupreadsbyumi\"\n"
    },
    {
      "name": "SetMateInfo",
      "input": {
        "default": "mapped/a.bam"
      },
      "output": {
        "default": "mapped/{sample}.mi.bam"
      },
      "log": {
        "default": "logs/fgbio/set_mate_info/{sample}.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/fgbio/setmateinformation"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule SetMateInfo:\n    input:\n        \"mapped/a.bam\"\n    output:\n        \"mapped/{sample}.mi.bam\"\n    params: \"\"\n    log:\n        \"logs/fgbio/set_mate_info/{sample}.log\"\n    wrapper:\n        \"master/bio/fgbio/setmateinformation\"\n"
    },
    {
      "name": "abundance",
      "input": {
        "reads": "{sample}.fa",
        "db": "database"
      },
      "output": {
        "abundances": "{sample}_rel-abundance.tsv",
        "alignments": "{sample}_emu_alignments.sam",
        "unclassified": "{sample}_unclassified.fas",
        "unmapped": "{sample}_unmapped.fas"
      },
      "log": {
        "default": "logs/emu/{sample}_abundance.log"
      },
      "params": {
        "extra": "--type map-ont --keep-counts"
      },
      "wrapper": {
        "default": "master/bio/emu/abundance"
      },
      "input_types": [
        {
          "reads": "single FASTA file or paired FASTQ files"
        },
        {
          "db": "emu database (optional; check documentation for pre-built databases and how to build them)."
        }
      ],
      "output_types": [
        {
          "abundances": "TSV with relative (and optionally, absolute abundances)."
        },
        {
          "alignments": "SAM file with the alignments (optional)."
        },
        {
          "unclassified": "FASTA/Q file with unclassified sequences (optional)."
        },
        {
          "unmapped": "FASTA/Q file with unmapped sequences (optional)."
        }
      ],
      "rule": "rule abundance:\n    input:\n        reads=\"{sample}.fa\",\n        db=\"database\",\n    output:\n        abundances=\"{sample}_rel-abundance.tsv\",\n        alignments=\"{sample}_emu_alignments.sam\",\n        unclassified=\"{sample}_unclassified.fas\",\n        unmapped=\"{sample}_unmapped.fas\",\n    log:\n        \"logs/emu/{sample}_abundance.log\",\n    params:\n        extra=\"--type map-ont --keep-counts\",\n    threads: 3  # optional, defaults to 1\n    wrapper:\n        \"master/bio/emu/abundance\"\n\n\nrule abundance_paired:\n    input:\n        reads=[\"{sample}_R1.fq\", \"{sample}_R2.fq\"],\n        db=\"database\",\n    output:\n        abundances=\"{sample}_rel-abundance_paired.tsv\",\n        alignments=\"{sample}_emu_alignments_paired.sam\",\n        unclassified=\"{sample}_unclassified_paired.fq\",\n        unmapped=\"{sample}_unmapped_paired.fq\",\n    log:\n        \"logs/emu/{sample}_abundance_paired.log\",\n    params:\n        extra=\"--type sr --keep-counts\",\n    threads: 3  # optional, defaults to 1\n    wrapper:\n        \"master/bio/emu/abundance\"\n"
    },
    {
      "name": "adapterremoval_se",
      "input": {
        "sample": [
          "reads/se/{sample}.fastq"
        ]
      },
      "output": {
        "fq": "trimmed/se/{sample}.fastq.gz",
        "discarded": "trimmed/se/{sample}.discarded.fastq.gz",
        "settings": "stats/se/{sample}.settings"
      },
      "log": {
        "default": "logs/adapterremoval/se/{sample}.log"
      },
      "params": {
        "adapters": "--adapter1 ACGGCTAGCTA",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/adapterremoval"
      },
      "input_types": [
        {
          "sample": [
            "raw fastq file with R1 reads",
            "raw fastq file with R2 reads (PE only)"
          ]
        }
      ],
      "output_types": [
        {
          "fq": "path to single fastq file (SE only)"
        },
        {
          "fq1": "path to fastq R1 (PE only)"
        },
        {
          "fq2": "path to fastq R2 (PE only)"
        },
        {
          "singleton": "fastq file with singleton reads (PE only; PE reads for which the mate has been discarded)"
        },
        {
          "collapsed": "fastq file with collapsed reads (PE only; overlapping mate-pairs which have been merged into a single read)"
        },
        {
          "collapsed_trunc": "fastq file with collapsed truncated reads (PE only; collapsed reads that were quality trimmed)"
        },
        {
          "discarded": "fastq file with discarded reads (reads that did not pass filters)"
        },
        {
          "settings": "settings and stats file"
        }
      ],
      "rule": "\nrule adapterremoval_se:\n    input:\n        sample=[\"reads/se/{sample}.fastq\"]\n    output:\n        fq=\"trimmed/se/{sample}.fastq.gz\",                               # trimmed reads\n        discarded=\"trimmed/se/{sample}.discarded.fastq.gz\",              # reads that did not pass filters\n        settings=\"stats/se/{sample}.settings\"                            # parameters as well as overall statistics\n    log:\n        \"logs/adapterremoval/se/{sample}.log\"\n    params:\n        adapters=\"--adapter1 ACGGCTAGCTA\",\n        extra=\"\",\n    threads: 1\n    wrapper:\n        \"master/bio/adapterremoval\"\n\n\nrule adapterremoval_pe:\n    input:\n        sample=[\"reads/pe/{sample}.1.fastq\", \"reads/pe/{sample}.2.fastq\"] \n    output:\n        fq1=\"trimmed/pe/{sample}_R1.fastq.gz\",                           # trimmed mate1 reads\n        fq2=\"trimmed/pe/{sample}_R2.fastq.gz\",                           # trimmed mate2 reads\n        collapsed=\"trimmed/pe/{sample}.collapsed.fastq.gz\",              # overlapping mate-pairs which have been merged into a single read\n        collapsed_trunc=\"trimmed/pe/{sample}.collapsed_trunc.fastq.gz\",  # collapsed reads that were quality trimmed\n        singleton=\"trimmed/pe/{sample}.singleton.fastq.gz\",              # mate-pairs for which the mate has been discarded\n        discarded=\"trimmed/pe/{sample}.discarded.fastq.gz\",              # reads that did not pass filters\n        settings=\"stats/pe/{sample}.settings\"                            # parameters as well as overall statistics\n    log:\n        \"logs/adapterremoval/pe/{sample}.log\"\n    params:\n        adapters=\"--adapter1 ACGGCTAGCTA --adapter2 AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\",\n        extra=\"--collapse --collapse-deterministic\",\n    threads: 2\n    wrapper:\n        \"master/bio/adapterremoval\"\n"
    },
    {
      "name": "alignment_summary",
      "input": {
        "bam": "mapped/a.bam",
        "ref": "genome.fasta"
      },
      "output": {
        "metrics": "results/a.gcmetrics.txt",
        "chart": "results/a.gc.pdf",
        "summary": "results/a.summary.txt"
      },
      "log": {
        "default": "logs/picard/a.gcmetrics.log"
      },
      "params": {
        "extra": "--MINIMUM_GENOME_FRACTION 1E-5"
      },
      "wrapper": {
        "default": "master/bio/picard/collectgcbiasmetrics"
      },
      "input_types": [
        "BAM file of RNA-seq data aligned to genome",
        "REF_FLAT formatted file of transcriptome annotations"
      ],
      "output_types": [
        "GC metrics text file",
        "GC metrics PDF figure",
        "GC summary metrics text file"
      ],
      "rule": "rule alignment_summary:\n    input:\n        # BAM aligned to reference genome\n        bam=\"mapped/a.bam\",\n        # reference genome FASTA from which GC-context is inferred\n        ref=\"genome.fasta\",\n    output:\n        metrics=\"results/a.gcmetrics.txt\",\n        chart=\"results/a.gc.pdf\",\n        summary=\"results/a.summary.txt\",\n    params:\n        # optional additional parameters, for example,\n        extra=\"--MINIMUM_GENOME_FRACTION 1E-5\",\n    log:\n        \"logs/picard/a.gcmetrics.log\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/collectgcbiasmetrics\"\n"
    },
    {
      "name": "all",
      "input": {
        "default": "results/consensus/sampleA.1.fq"
      },
      "output": {},
      "log": {},
      "params": {},
      "wrapper": {},
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule all:  # [hide]\n    input:  # [hide]\n        \"results/consensus/sampleA.1.fq\",  # [hide]\n\n\nrule calc_consensus_reads:\n    input:\n        \"mapped/{sample}.marked.bam\",\n    output:\n        consensus_r1=\"results/consensus/{sample}.1.fq\",\n        consensus_r2=\"results/consensus/{sample}.2.fq\",\n        consensus_se=\"results/consensus/{sample}.se.fq\",\n        skipped=\"results/consensus/{sample}.skipped.bam\",\n    params:\n        extra=\"--annotate-record-ids\",\n    log:\n        \"logs/consensus/{sample}.log\",\n    wrapper:\n        \"master/bio/rbt/collapse_reads_to_fragments-bam\"\n"
    },
    {
      "name": "annotate_bam_single_fastq",
      "input": {
        "bam": "mapped/{sample}.bam",
        "umi": "umi/{sample}.fastq"
      },
      "output": {
        "default": "mapped/{sample}.annotated.bam"
      },
      "log": {
        "default": "logs/fgbio/annotate_bam/{sample}.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/fgbio/annotatebamwithumis"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule annotate_bam_single_fastq:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        umi=\"umi/{sample}.fastq\",\n    output:\n        \"mapped/{sample}.annotated.bam\",\n    params:\n        \"\",\n    resources:\n        # suggestion assuming unsorted input, so that memory should\n        # be proportional to input size:\n        # https://fulcrumgenomics.github.io/fgbio/tools/latest/AnnotateBamWithUmis.html\n        mem_mb=lambda wildcards, input: max([input.size_mb * 1.3, 200]),\n    log:\n        \"logs/fgbio/annotate_bam/{sample}.log\",\n    wrapper:\n        \"master/bio/fgbio/annotatebamwithumis\"\n\n\nrule annotate_bam_multiple_fastqs:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        umi=[\n            \"umi/{sample}.fastq\",\n            \"umi/{sample}.fastq\",\n        ],\n    output:\n        \"mapped/{sample}-{sample}.annotated.bam\",\n    params:\n        \"\",\n    resources:\n        # suggestion assuming unsorted input, so that memory should\n        # be proportional to input size:\n        # https://fulcrumgenomics.github.io/fgbio/tools/latest/AnnotateBamWithUmis.html\n        mem_mb=lambda wildcards, input: max([input.size_mb * 1.3, 200]),\n    log:\n        \"logs/fgbio/annotate_bam/{sample}-{sample}.log\",\n    wrapper:\n        \"master/bio/fgbio/annotatebamwithumis\"\n"
    },
    {
      "name": "annotate_variants",
      "input": {
        "calls": "variants.bcf",
        "cache": "resources/vep/cache",
        "plugins": "resources/vep/plugins"
      },
      "output": {
        "calls": "variants.annotated.bcf",
        "stats": "variants.html"
      },
      "log": {
        "default": "logs/vep/annotate.log"
      },
      "params": {
        "plugins": [
          "LoFtool"
        ],
        "extra": "--everything"
      },
      "wrapper": {
        "default": "master/bio/vep/annotate"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule annotate_variants:\n    input:\n        calls=\"variants.bcf\",  # .vcf, .vcf.gz or .bcf\n        cache=\"resources/vep/cache\",  # can be omitted if fasta and gff are specified\n        plugins=\"resources/vep/plugins\",\n        # optionally add reference genome fasta\n        # fasta=\"genome.fasta\",\n        # fai=\"genome.fasta.fai\", # fasta index\n        # gff=\"annotation.gff\",\n        # csi=\"annotation.gff.csi\", # tabix index\n        # add mandatory aux-files required by some plugins if not present in the VEP plugin directory specified above.\n        # aux files must be defined as following: \"<plugin> = /path/to/file\" where plugin must be in lowercase\n        # revel = path/to/revel_scores.tsv.gz\n    output:\n        calls=\"variants.annotated.bcf\",  # .vcf, .vcf.gz or .bcf\n        stats=\"variants.html\",\n    params:\n        # Pass a list of plugins to use, see https://www.ensembl.org/info/docs/tools/vep/script/vep_plugins.html\n        # Plugin args can be added as well, e.g. via an entry \"MyPlugin,1,FOO\", see docs.\n        plugins=[\"LoFtool\"],\n        extra=\"--everything\",  # optional: extra arguments\n    log:\n        \"logs/vep/annotate.log\",\n    threads: 4\n    wrapper:\n        \"master/bio/vep/annotate\"\n"
    },
    {
      "name": "apply_vqsr",
      "input": {
        "vcf": "test.vcf",
        "recal": "snps.recal",
        "tranches": "snps.tranches",
        "ref": "ref.fasta"
      },
      "output": {
        "vcf": "test.snp_recal.vcf"
      },
      "log": {
        "default": "logs/gatk/applyvqsr.log"
      },
      "params": {
        "mode": "SNP",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/applyvqsr"
      },
      "input_types": [
        "VCF file",
        "Recalibration file",
        "Tranches file"
      ],
      "output_types": [
        "Variant QualityScore-Recalibrated VCF"
      ],
      "rule": "rule apply_vqsr:\n    input:\n        vcf=\"test.vcf\",\n        recal=\"snps.recal\",\n        tranches=\"snps.tranches\",\n        ref=\"ref.fasta\",\n    output:\n        vcf=\"test.snp_recal.vcf\",\n    log:\n        \"logs/gatk/applyvqsr.log\",\n    params:\n        mode=\"SNP\",  # set mode, must be either SNP, INDEL or BOTH\n        extra=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/applyvqsr\"\n"
    },
    {
      "name": "arriba",
      "input": {
        "bam": "{sample}.bam",
        "genome": "genome.fasta",
        "annotation": "annotation.gtf",
        "custom_blacklist": []
      },
      "output": {
        "fusions": "fusions/{sample}.tsv",
        "discarded": "fusions/{sample}.discarded.tsv"
      },
      "log": {
        "default": "logs/arriba/{sample}.log"
      },
      "params": {
        "genome_build": "GRCh38",
        "default_blacklist": false,
        "default_known_fusions": true,
        "sv_file": "",
        "extra": "-i 1,2"
      },
      "wrapper": {
        "default": "master/bio/arriba"
      },
      "input_types": [
        {
          "bam": "Path to bam formatted alignment file from STAR"
        },
        {
          "genome": "Path to fasta formatted genome sequence"
        },
        {
          "annotation": "Path to GTF formatted genome annotation"
        }
      ],
      "output_types": [
        {
          "fusions": "Path to output fusion file"
        }
      ],
      "rule": "rule arriba:\n    input:\n        # STAR bam containing chimeric alignments\n        bam=\"{sample}.bam\",\n        # path to reference genome\n        genome=\"genome.fasta\",\n        # path to annotation gtf\n        annotation=\"annotation.gtf\",\n        # optional arriba blacklist file\n        custom_blacklist=[],\n    output:\n        # approved gene fusions\n        fusions=\"fusions/{sample}.tsv\",\n        # discarded gene fusions\n        discarded=\"fusions/{sample}.discarded.tsv\",  # optional\n    log:\n        \"logs/arriba/{sample}.log\",\n    params:\n        # required when blacklist or known_fusions is set \n        genome_build=\"GRCh38\",\n        # strongly recommended, see https://arriba.readthedocs.io/en/latest/input-files/#blacklist\n        # only set blacklist input-file or blacklist-param\n        default_blacklist=False,  # optional\n        default_known_fusions=True,  # optional\n        # file containing information from structural variant analysis\n        sv_file=\"\",  # optional\n        # optional parameters\n        extra=\"-i 1,2\",\n    threads: 1\n    wrapper:\n        \"master/bio/arriba\"\n"
    },
    {
      "name": "art_profiler_illumina",
      "input": {
        "default": "data/{sample}.fq"
      },
      "output": {
        "default": "profiles/{sample}.txt"
      },
      "log": {
        "default": "logs/art_profiler_illumina/{sample}.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/art/profiler_illumina"
      },
      "input_types": [
        "Path to fastq-formatted input file (first place in the input list of files)"
      ],
      "output_types": [
        "Path to txt formatted profile (first place in the output list of files)"
      ],
      "rule": "rule art_profiler_illumina:\n    input:\n        \"data/{sample}.fq\",\n    output:\n        \"profiles/{sample}.txt\"\n    log:\n        \"logs/art_profiler_illumina/{sample}.log\"\n    params: \"\"\n    threads: 2\n    wrapper:\n        \"master/bio/art/profiler_illumina\"\n"
    },
    {
      "name": "bam2nuc_for_genome",
      "input": {
        "genome_fa": "indexes/{genome}/{genome}.fa.gz"
      },
      "output": {
        "default": "indexes/{genome}/genomic_nucleotide_frequencies.txt"
      },
      "log": {
        "default": "logs/indexes/{genome}/genomic_nucleotide_frequencies.txt.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/bismark/bam2nuc"
      },
      "input_types": [
        {
          "genome_fa": "Path to genome in FastA format (e.g. \\*.fa, \\*.fasta, \\*.fa.gz, \\*.fasta.gz). All genomes FastA from it's parent folder will be taken"
        },
        {
          "bam": "Optional BAM or CRAM file (or multiple space separated files). If bam arg isn't provided, option `--genomic_composition_only` will be used to generate genomic composition table `genomic_nucleotide_frequencies.txt`."
        }
      ],
      "output_types": [
        "Genome nucleotide frequencies `genomic_nucleotide_frequencies.txt` will be generated in 'genome_fa' directory, optional output.",
        {
          "report": "Report file (or space separated files), pattern '{bam_file_name}.nucleotide_stats.txt'."
        }
      ],
      "rule": "# Nucleotide stats for genome is required for further stats for BAM file\nrule bam2nuc_for_genome:\n    input:\n        genome_fa=\"indexes/{genome}/{genome}.fa.gz\"\n    output:\n        \"indexes/{genome}/genomic_nucleotide_frequencies.txt\"\n    log:\n        \"logs/indexes/{genome}/genomic_nucleotide_frequencies.txt.log\"\n    wrapper:\n        \"master/bio/bismark/bam2nuc\"\n\n# Nucleotide stats for BAM file\nrule bam2nuc_for_bam:\n    input:\n        genome_fa=\"indexes/{genome}/{genome}.fa.gz\",\n        bam=\"bams/{sample}_{genome}.bam\"\n    output:\n        report=\"bams/{sample}_{genome}.nucleotide_stats.txt\"\n    log:\n        \"logs/{sample}_{genome}.nucleotide_stats.txt.log\"\n    wrapper:\n        \"master/bio/bismark/bam2nuc\"\n"
    },
    {
      "name": "bam_to_fastq",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "fastq1": "reads/{sample}.R1.fastq",
        "fastq2": "reads/{sample}.R2.fastq"
      },
      "log": {
        "default": "logs/picard/sam_to_fastq/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/picard/samtofastq"
      },
      "input_types": [
        "sam/bam file"
      ],
      "output_types": [
        "fastq files."
      ],
      "rule": "rule bam_to_fastq:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        fastq1=\"reads/{sample}.R1.fastq\",\n        fastq2=\"reads/{sample}.R2.fastq\",\n    log:\n        \"logs/picard/sam_to_fastq/{sample}.log\",\n    params:\n        extra=\"\",  # optional: Extra arguments for picard.\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/samtofastq\"\n"
    },
    {
      "name": "bamtobed",
      "input": {
        "default": "{sample}.bam"
      },
      "output": {
        "default": "{sample}.bed"
      },
      "log": {
        "default": "logs/bamtobed/{sample}.log"
      },
      "params": {
        "extra": "-bedpe"
      },
      "wrapper": {
        "default": "master/bio/bedtools/bamtobed"
      },
      "input_types": [
        "BAM file, this must be the first file in the input file list"
      ],
      "output_types": [
        "BED file, this must be the first file in the output file list"
      ],
      "rule": "\nrule bamtobed:\n    input:\n        \"{sample}.bam\",\n    output:\n        \"{sample}.bed\",\n    log:\n        \"logs/bamtobed/{sample}.log\",\n    params:\n        extra=\"-bedpe\",  # optional parameters\n    wrapper:\n        \"master/bio/bedtools/bamtobed\"\n\nrule bamtobed_gz:\n    input:\n        \"{sample}.bam\",\n    output:\n        \"{sample}.bed.gz\",\n    log:\n        \"logs/bamtobed/{sample}.gz.log\",\n    params:\n        extra=\"-bedpe\",  # optional parameters\n    wrapper:\n        \"master/bio/bedtools/bamtobed\"\n"
    },
    {
      "name": "bamtools_filter",
      "input": {
        "default": "{sample}.bam"
      },
      "output": {
        "default": "filtered/{sample}.bam"
      },
      "log": {
        "default": "logs/bamtools/filtered/{sample}.log"
      },
      "params": {
        "tags": [
          "NM:<4",
          "MQ:>=10"
        ],
        "min_size": "-2000",
        "max_size": "2000",
        "min_length": "10",
        "max_length": "20",
        "additional_params": "-mapQuality \">=0\" -isMapped \"true\""
      },
      "wrapper": {
        "default": "master/bio/bamtools/filter"
      },
      "input_types": [
        "bam files (.bam), must be in first position"
      ],
      "output_types": [
        "bam file (.bam), must be in first position"
      ],
      "rule": "rule bamtools_filter:\n    input:\n        \"{sample}.bam\"\n    output:\n        \"filtered/{sample}.bam\"\n    params:\n        # optional parameters\n        tags = [ \"NM:<4\", \"MQ:>=10\" ],    # list of key:value pair strings\n        min_size = \"-2000\",\n        max_size = \"2000\",\n        min_length = \"10\",\n        max_length = \"20\",\n        # to add more optional parameters (see bamtools filter --help):\n        additional_params = \"-mapQuality \\\">=0\\\" -isMapped \\\"true\\\"\"\n    log:\n        \"logs/bamtools/filtered/{sample}.log\"\n    wrapper:\n        \"master/bio/bamtools/filter\"\n"
    },
    {
      "name": "bamtools_filter_json",
      "input": {
        "default": "{sample}.bam"
      },
      "output": {
        "default": "filtered/{sample}.bam"
      },
      "log": {
        "default": "logs/bamtools/filtered/{sample}.log"
      },
      "params": {
        "json": "filtering-rules.json",
        "region": ""
      },
      "wrapper": {
        "default": "master/bio/bamtools/filter_json"
      },
      "input_types": [
        "bam files (.bam), must be in first position"
      ],
      "output_types": [
        "bam file (.bam), must be in first position"
      ],
      "rule": "rule bamtools_filter_json:\n    input:\n        \"{sample}.bam\"\n    output:\n        \"filtered/{sample}.bam\"\n    params:\n        json=\"filtering-rules.json\",\n        region=\"\" # optional parameter for defining a specific region, e.g. \"chr1:500..chr3:750\"\n    log:\n        \"logs/bamtools/filtered/{sample}.log\"\n    wrapper:\n        \"master/bio/bamtools/filter_json\"\n"
    },
    {
      "name": "bamtools_split",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.REF_xx.bam"
      },
      "log": {
        "default": "logs/bamtoos_split/{sample}.log"
      },
      "params": {
        "extra": "-reference"
      },
      "wrapper": {
        "default": "master/bio/bamtools/split"
      },
      "input_types": [
        "bam file, this must be the only file in input."
      ],
      "output_types": [
        "multiple bam file multiple formats."
      ],
      "rule": "rule bamtools_split:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"mapped/{sample}.REF_xx.bam\",\n    params:\n        extra=\"-reference\",\n    log:\n        \"logs/bamtoos_split/{sample}.log\",\n    wrapper:\n        \"master/bio/bamtools/split\"\n"
    },
    {
      "name": "bamtools_stats",
      "input": {
        "default": "{sample}.bam"
      },
      "output": {
        "default": "{sample}.bamstats"
      },
      "log": {
        "default": "logs/bamtools/stats/{sample}.log"
      },
      "params": {
        "default": "-insert"
      },
      "wrapper": {
        "default": "master/bio/bamtools/stats"
      },
      "input_types": [
        "bam files (.bam), must be in first position"
      ],
      "output_types": [
        "bamstats file (.bamstats), must be in first position"
      ],
      "rule": "rule bamtools_stats:\n    input:\n        \"{sample}.bam\"\n    output:\n        \"{sample}.bamstats\"\n    params:\n        \"-insert\" # optional summarize insert size data\n    log:\n        \"logs/bamtools/stats/{sample}.log\"\n    wrapper:\n        \"master/bio/bamtools/stats\"\n"
    },
    {
      "name": "barrnap",
      "input": {
        "fasta": "{sample}.fasta"
      },
      "output": {
        "gff": "{sample}.gff",
        "fasta": "{sample}_hits.fasta"
      },
      "log": {
        "default": "logs/barrnap/{sample}.log"
      },
      "params": {
        "kingdom": "bac",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/barrnap"
      },
      "input_types": [
        {
          "fasta": "query fasta file"
        }
      ],
      "output_types": [
        {
          "gff": "The rRNA locations in GFF3 format."
        },
        {
          "fasta": "Optional. Fasta file with the hit sequences."
        }
      ],
      "rule": "rule barrnap:\n    input:\n        fasta=\"{sample}.fasta\",\n    output:\n        gff=\"{sample}.gff\",\n        fasta=\"{sample}_hits.fasta\",\n    params:\n        kingdom=\"bac\",\n        extra=\"\",\n    threads: 1\n    log:\n        \"logs/barrnap/{sample}.log\",\n    wrapper:\n        \"master/bio/barrnap\"\n"
    },
    {
      "name": "baserecalibrator",
      "input": {
        "bam": "{sample}.bam",
        "bai": "{sample}.bai",
        "ref": "genome.fasta",
        "fai": "genome.fasta.fai",
        "dict": "genome.dict",
        "known": "dbsnp.vcf.gz",
        "known_idx": "dbsnp.vcf.gz.tbi"
      },
      "output": {
        "recal_table": "{sample}.recal_data_table"
      },
      "log": {
        "default": "logs/gatk3/bqsr/{sample}.log"
      },
      "params": {
        "extra": "--defaultBaseQualities 20 --filter_reads_with_N_cigar"
      },
      "wrapper": {
        "default": "master/bio/gatk3/baserecalibrator"
      },
      "input_types": [
        "bam file",
        "vcf files",
        "reference genome"
      ],
      "output_types": [
        "recalibration table"
      ],
      "rule": "rule baserecalibrator:\n    input:\n        bam=\"{sample}.bam\",\n        bai=\"{sample}.bai\",\n        ref=\"genome.fasta\",\n        fai=\"genome.fasta.fai\",\n        dict=\"genome.dict\",\n        known=\"dbsnp.vcf.gz\",\n        known_idx=\"dbsnp.vcf.gz.tbi\",\n    output:\n        recal_table=\"{sample}.recal_data_table\",\n    log:\n        \"logs/gatk3/bqsr/{sample}.log\",\n    params:\n        extra=\"--defaultBaseQualities 20 --filter_reads_with_N_cigar\",  # optional\n    resources:\n        mem_mb=1024,\n    threads: 16\n    wrapper:\n        \"master/bio/gatk3/baserecalibrator\"\n"
    },
    {
      "name": "bazam_interleaved",
      "input": {
        "bam": "mapped/{sample}.bam",
        "bai": "mapped/{sample}.bam.bai"
      },
      "output": {
        "reads": "results/reads/{sample}.fastq.gz"
      },
      "log": {
        "default": "logs/bazam/{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/bazam"
      },
      "input_types": [
        {
          "bam": "Path to mapping file (BAM/CRAM formatted)"
        },
        {
          "reference": "Optional path to reference genome sequence (FASTA formatted). Required for CRAM input."
        }
      ],
      "output_types": [
        {
          "reads": "Path to realigned reads (single-ended or interleaved) (FASTQ formatted) *OR*"
        },
        {
          "r1": "Path to upstream reads (FASTQ formatted) *AND*"
        },
        {
          "r2": "Path to downstream reads (FASTQ formatted)"
        }
      ],
      "rule": "rule bazam_interleaved:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        bai=\"mapped/{sample}.bam.bai\",\n    output:\n        reads=\"results/reads/{sample}.fastq.gz\",\n    resources:\n        # suggestion according to:\n        # https://github.com/ssadedin/bazam/blob/c5988daf4cda4492e3d519c94f2f1e2022af5efe/README.md?plain=1#L46-L55\n        mem_mb=lambda wildcards, input: max([0.2 * input.size_mb, 200]),\n    log:\n        \"logs/bazam/{sample}.log\",\n    wrapper:\n        \"master/bio/bazam\"\n\n\nrule bazam_separated:\n    input:\n        bam=\"mapped/{sample}.cram\",\n        bai=\"mapped/{sample}.cram.crai\",\n        reference=\"genome.fasta\",\n    output:\n        r1=\"results/reads/{sample}.r1.fastq.gz\",\n        r2=\"results/reads/{sample}.r2.fastq.gz\",\n    resources:\n        # suggestion according to:\n        # https://github.com/ssadedin/bazam/blob/c5988daf4cda4492e3d519c94f2f1e2022af5efe/README.md?plain=1#L46-L55\n        mem_mb=lambda wildcards, input: max([0.4 * input.size_mb, 200]),\n    log:\n        \"logs/bazam/{sample}.log\",\n    wrapper:\n        \"master/bio/bazam\"\n"
    },
    {
      "name": "bcf_filter_sample",
      "input": {
        "samples": "samples.txt"
      },
      "output": {
        "default": "{prefix}.filter_sample.vcf"
      },
      "log": {
        "default": "log/{prefix}.filter_sample.vcf.log"
      },
      "params": {
        "filter": "lambda w, input: f\"\"\"--exclude 'GT[@{input.samples}]=\"0/1\"'\"\"\"",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bcftools/filter"
      },
      "input_types": [
        "VCF/BCF file"
      ],
      "output_types": [
        "Filtered VCF/BCF file"
      ],
      "rule": "rule bcf_filter_sample:\n    input:\n        \"{prefix}.bcf\",  # input bcf/vcf needs to be first input\n        samples=\"samples.txt\",  # other inputs, e.g. sample files, are optional\n    output:\n        \"{prefix}.filter_sample.vcf\",\n    log:\n        \"log/{prefix}.filter_sample.vcf.log\",\n    params:\n        filter=lambda w, input: f\"--exclude 'GT[@{input.samples}]=\\\"0/1\\\"'\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/filter\"\n\n\nrule bcf_filter_o_vcf:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.filter.vcf\",\n    log:\n        \"log/{prefix}.filter.vcf.log\",\n    params:\n        filter=\"-i 'QUAL > 5'\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/filter\"\n\n\nrule bcf_filter_o_vcf_gz:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.filter.vcf.gz\",\n    log:\n        \"log/{prefix}.filter.vcf.gz.log\",\n    params:\n        filter=\"-i 'QUAL > 5'\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/filter\"\n\n\nrule bcf_filter_o_bcf:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.filter.bcf\",\n    log:\n        \"log/{prefix}.filter.bcf.log\",\n    params:\n        filter=\"-i 'QUAL > 5'\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/filter\"\n\n\nrule bcf_filter_o_uncompressed_bcf:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.filter.uncompressed.bcf\",\n    log:\n        \"log/{prefix}.filter.uncompressed.bcf.log\",\n    params:\n        uncompressed_bcf=True,\n        filter=\"-i 'QUAL > 5'\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/filter\"\n"
    },
    {
      "name": "bcf_stats",
      "input": {
        "default": "{prefix}"
      },
      "output": {
        "default": "{prefix}.stats.txt"
      },
      "log": {
        "default": "{prefix}.bcftools.stats.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/bcftools/stats"
      },
      "input_types": [
        "BCF, VCF, or VCF.gz input"
      ],
      "output_types": [
        "stats text file"
      ],
      "rule": "rule bcf_stats:\n    input:\n        \"{prefix}\",\n    output:\n        \"{prefix}.stats.txt\",\n    log:\n        \"{prefix}.bcftools.stats.log\",\n    params:\n        \"\",\n    wrapper:\n        \"master/bio/bcftools/stats\"\n"
    },
    {
      "name": "bcf_view_sample_file",
      "input": {
        "index": "{prefix}.bcf.csi",
        "samples": "samples.txt"
      },
      "output": {
        "default": "{prefix}.view_sample.vcf"
      },
      "log": {
        "default": "log/{prefix}.view_sample.vcf.log"
      },
      "params": {
        "extra": "lambda w, input: f'-S {input.samples}'"
      },
      "wrapper": {
        "default": "master/bio/bcftools/view"
      },
      "input_types": [
        "VCF/BCF file"
      ],
      "output_types": [
        "Filtered VCF/BCF file"
      ],
      "rule": "rule bcf_view_sample_file:\n    input:\n        \"{prefix}.bcf\",  # input bcf/vcf needs to be first input\n        index=\"{prefix}.bcf.csi\",  # other inputs are optional\n        samples=\"samples.txt\",\n    output:\n        \"{prefix}.view_sample.vcf\",\n    log:\n        \"log/{prefix}.view_sample.vcf.log\",\n    params:\n        # optional extra parameters\n        extra=lambda w, input: f\"-S {input.samples}\",\n    wrapper:\n        \"master/bio/bcftools/view\"\n\n\nrule bcf_view_o_vcf:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.view.vcf\",\n    log:\n        \"log/{prefix}.view.vcf.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/view\"\n\n\nrule bcf_view_o_vcf_gz:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.view.vcf.gz\",\n    log:\n        \"log/{prefix}.view.vcf.gz.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/view\"\n\n\nrule bcf_view_o_bcf:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.view.bcf\",\n    log:\n        \"log/{prefix}.view.bcf.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/view\"\n\n\nrule bcf_view_o_uncompressed_bcf:\n    input:\n        \"{prefix}.bcf\",\n    output:\n        \"{prefix}.view.uncompressed.bcf\",\n    log:\n        \"log/{prefix}.view.uncompressed.bcf.log\",\n    params:\n        uncompressed_bcf=True,\n        extra=\"\",\n    wrapper:\n        \"master/bio/bcftools/view\"\n"
    },
    {
      "name": "bcftools_call",
      "input": {
        "pileup": "{sample}.pileup.bcf"
      },
      "output": {
        "calls": "{sample}.calls.bcf"
      },
      "log": {
        "default": "logs/bcftools_call/{sample}.log"
      },
      "params": {
        "uncompressed_bcf": false,
        "caller": "-m",
        "extra": "--ploidy 1 --prior 0.001"
      },
      "wrapper": {
        "default": "master/bio/bcftools/call"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bcftools_call:\n    input:\n        pileup=\"{sample}.pileup.bcf\",\n    output:\n        calls=\"{sample}.calls.bcf\",\n    params:\n        uncompressed_bcf=False,\n        caller=\"-m\",  # valid options include -c/--consensus-caller or -m/--multiallelic-caller\n        extra=\"--ploidy 1 --prior 0.001\",\n    log:\n        \"logs/bcftools_call/{sample}.log\",\n    wrapper:\n        \"master/bio/bcftools/call\"\n"
    },
    {
      "name": "bcftools_concat",
      "input": {
        "calls": [
          "a.bcf",
          "b.bcf"
        ]
      },
      "output": {
        "default": "all.bcf"
      },
      "log": {
        "default": "logs/all.log"
      },
      "params": {
        "uncompressed_bcf": false,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bcftools/concat"
      },
      "input_types": [
        "vcf files"
      ],
      "output_types": [
        "Concatenated VCF/BCF file"
      ],
      "rule": "rule bcftools_concat:\n    input:\n        calls=[\"a.bcf\", \"b.bcf\"],\n    output:\n        \"all.bcf\",\n    log:\n        \"logs/all.log\",\n    params:\n        uncompressed_bcf=False,\n        extra=\"\",  # optional parameters for bcftools concat (except -o)\n    threads: 4\n    resources:\n        mem_mb=10,\n    wrapper:\n        \"master/bio/bcftools/concat\"\n"
    },
    {
      "name": "bcftools_index",
      "input": {
        "default": "a.bcf"
      },
      "output": {
        "default": "a.bcf.csi"
      },
      "log": {
        "default": "index/a.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bcftools/index"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bcftools_index:\n    input:\n        \"a.bcf\",\n    output:\n        \"a.bcf.csi\",\n    log:\n        \"index/a.log\",\n    params:\n        extra=\"\",  # optional parameters for bcftools index\n    wrapper:\n        \"master/bio/bcftools/index\"\n"
    },
    {
      "name": "bcftools_merge",
      "input": {
        "calls": [
          "a.bcf",
          "b.bcf"
        ],
        "idx": [
          "a.bcf.csi",
          "b.bcf.csi"
        ]
      },
      "output": {
        "default": "all.bcf"
      },
      "log": {
        "default": "all.log"
      },
      "params": {
        "uncompressed_bcf": false,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bcftools/merge"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bcftools_merge:\n    input:\n        calls=[\"a.bcf\", \"b.bcf\"],\n        idx=[\"a.bcf.csi\", \"b.bcf.csi\"],\n    output:\n        \"all.bcf\",\n    log:\n        \"all.log\",\n    params:\n        uncompressed_bcf=False,\n        extra=\"\",  # optional parameters for bcftools concat (except -o)\n    wrapper:\n        \"master/bio/bcftools/merge\"\n"
    },
    {
      "name": "bcftools_mpileup",
      "input": {
        "alignments": [
          "mapped/{sample}.bam",
          "mapped/{sample}.bam"
        ],
        "ref": "genome.fasta",
        "index": "genome.fasta.fai"
      },
      "output": {
        "pileup": "pileups/{sample}.pileup.bcf"
      },
      "log": {
        "default": "logs/bcftools_mpileup/{sample}.log"
      },
      "params": {
        "uncompressed_bcf": false,
        "extra": "--max-depth 100 --min-BQ 15"
      },
      "wrapper": {
        "default": "master/bio/bcftools/mpileup"
      },
      "input_types": [
        {
          "alignments": "SAM/BAM/CRAM file(s)"
        },
        {
          "ref": "reference genome"
        },
        "reference genome index"
      ],
      "output_types": [
        "pileup file"
      ],
      "rule": "rule bcftools_mpileup:\n    input:\n        alignments=[\"mapped/{sample}.bam\", \"mapped/{sample}.bam\"],\n        ref=\"genome.fasta\",  # this can be left out if --no-reference is in options\n        index=\"genome.fasta.fai\",\n    output:\n        pileup=\"pileups/{sample}.pileup.bcf\",\n    params:\n        uncompressed_bcf=False,\n        extra=\"--max-depth 100 --min-BQ 15\",\n    log:\n        \"logs/bcftools_mpileup/{sample}.log\",\n    wrapper:\n        \"master/bio/bcftools/mpileup\"\n"
    },
    {
      "name": "bcftools_reheader",
      "input": {
        "vcf": "a.bcf",
        "header": "header.txt",
        "samples": "samples.tsv"
      },
      "output": {
        "default": "a.reheader.bcf"
      },
      "log": {
        "default": "a.reheader.log"
      },
      "params": {
        "uncompressed_bcf": false,
        "extra": "",
        "view_extra": ""
      },
      "wrapper": {
        "default": "master//bio/bcftools/reheader"
      },
      "input_types": [
        "VCF/BCF file",
        {
          "header": "new header (optional if \"samples\" is set)"
        },
        {
          "samples": "new sample names (optional if \"header\" is set)"
        }
      ],
      "output_types": [
        "VCF/BCF file with new header"
      ],
      "rule": "rule bcftools_reheader:\n    input:\n        vcf=\"a.bcf\",\n        ## new header, can be omitted if \"samples\" is set\n        header=\"header.txt\",\n        ## file containing new sample names, can be omitted if \"header\" is set\n        samples=\"samples.tsv\",\n    output:\n        \"a.reheader.bcf\",\n    log:\n        \"a.reheader.log\",\n    params:\n        uncompressed_bcf=False,\n        extra=\"\",  # optional parameters for bcftools reheader\n        view_extra=\"\",  # optional parameters for bcftools view\n    threads: 2\n    wrapper:\n        \"master//bio/bcftools/reheader\"\n\n\nuse rule bcftools_reheader as bcftools_reheader_map with:\n    input:\n        vcf=\"a.bcf\",\n        header=\"header.txt\",\n        samples=\"samples_map.tsv\",\n    output:\n        \"a.reheader_map.bcf\",\n    log:\n        \"a.reheader_map.log\",\n"
    },
    {
      "name": "bcftools_sort",
      "input": {
        "default": "{sample}.bcf"
      },
      "output": {
        "default": "{sample}.sorted.bcf"
      },
      "log": {
        "default": "logs/bcftools/sort/{sample}.log"
      },
      "params": {
        "uncompressed_bcf": false,
        "extras": ""
      },
      "wrapper": {
        "default": "master/bio/bcftools/sort"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bcftools_sort:\n    input:\n        \"{sample}.bcf\",\n    output:\n        \"{sample}.sorted.bcf\",\n    log:\n        \"logs/bcftools/sort/{sample}.log\",\n    params:\n        # Set to True, in case you want uncompressed BCF output\n        uncompressed_bcf=False,\n        # Extra arguments\n        extras=\"\",\n    resources:\n        mem_mb=8000,\n    wrapper:\n        \"master/bio/bcftools/sort\"\n"
    },
    {
      "name": "bedGraphToBigWig",
      "input": {
        "bedGraph": "{sample}.bedGraph",
        "chromsizes": "genome.chrom.sizes"
      },
      "output": {
        "default": "{sample}.bw"
      },
      "log": {
        "default": "logs/{sample}.bed-graph_to_big-wig.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/ucsc/bedGraphToBigWig"
      },
      "input_types": [
        {
          "bedGraph": "Path to \\*.bedGraph file"
        },
        {
          "chromsizes": "Chrom sizes file, could be generated by twoBitInfo or downloaded from UCSC"
        }
      ],
      "output_types": [
        "Path to output '\\*.bw' file"
      ],
      "rule": "rule bedGraphToBigWig:\n    input:\n        bedGraph=\"{sample}.bedGraph\",\n        chromsizes=\"genome.chrom.sizes\"\n    output:\n        \"{sample}.bw\"\n    log:\n        \"logs/{sample}.bed-graph_to_big-wig.log\"\n    params:\n        \"\" # optional params string\n    wrapper:\n        \"master/bio/ucsc/bedGraphToBigWig\"\n"
    },
    {
      "name": "bed_to_interval_list",
      "input": {
        "bed": "resources/a.bed",
        "dict": "resources/genome.dict"
      },
      "output": {
        "default": "a.interval_list"
      },
      "log": {
        "default": "logs/picard/bedtointervallist/a.log"
      },
      "params": {
        "extra": "--SORT true"
      },
      "wrapper": {
        "default": "master/bio/picard/bedtointervallist"
      },
      "input_types": [
        {
          "bed": "region file"
        },
        {
          "dict": "genome dictionary file (from samtools dict or `picard CreateSequenceDictionary <https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/picard/createsequencedictionary.html>`_ )"
        }
      ],
      "output_types": [
        "interval_list Picard format"
      ],
      "rule": "rule bed_to_interval_list:\n    input:\n        bed=\"resources/a.bed\",\n        dict=\"resources/genome.dict\",\n    output:\n        \"a.interval_list\",\n    log:\n        \"logs/picard/bedtointervallist/a.log\",\n    params:\n        # optional parameters\n        extra=\"--SORT true\",  # sort output interval list before writing\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/bedtointervallist\"\n"
    },
    {
      "name": "bedtools_complement_bed",
      "input": {
        "in_file": "a.bed",
        "genome": "dummy.genome"
      },
      "output": {
        "default": "results/bed-complement/a.complement.bed"
      },
      "log": {
        "default": "logs/a.complement.bed.log"
      },
      "params": {
        "extra": "-L"
      },
      "wrapper": {
        "default": "master/bio/bedtools/complement"
      },
      "input_types": [
        {
          "in_file": "interval files (BED/GFF/VCF)"
        },
        {
          "genome": "genome file"
        }
      ],
      "output_types": [
        "complemented BED/GFF/VCF file"
      ],
      "rule": "rule bedtools_complement_bed:\n    input:\n        in_file=\"a.bed\",\n        genome=\"dummy.genome\"\n    output:\n        \"results/bed-complement/a.complement.bed\"\n    params:\n        ## Add optional parameters\n        extra=\"-L\"\n    log:\n        \"logs/a.complement.bed.log\"\n    wrapper:\n        \"master/bio/bedtools/complement\"\n\nrule bedtools_complement_bed_gz:\n    input:\n        in_file=\"a.bed\",\n        genome=\"dummy.genome\"\n    output:\n        \"results/bed-complement/a.complement.bed.gz\"\n    params:\n        ## Add optional parameters\n        extra=\"-L\"\n    log:\n        \"logs/a.complement.bed.gz.log\"\n    wrapper:\n        \"master/bio/bedtools/complement\"\n\nrule bedtools_complement_vcf:\n    input:\n        in_file=\"a.vcf\",\n        genome=\"dummy.genome\"\n    output:\n        \"results/vcf-complement/a.complement.vcf\"\n    params:\n        ## Add optional parameters\n        extra=\"-L\"\n    log:\n        \"logs/a.complement.vcf.log\"\n    wrapper:\n        \"master/bio/bedtools/complement\"\n"
    },
    {
      "name": "bedtools_intersect",
      "input": {
        "left": "A.bed",
        "right": "B.bed"
      },
      "output": {
        "default": "A_B.intersected.bed"
      },
      "log": {
        "default": "logs/intersect/A_B.log"
      },
      "params": {
        "extra": "-wa -wb"
      },
      "wrapper": {
        "default": "master/bio/bedtools/intersect"
      },
      "input_types": [
        {
          "left": "Path to the left region file. Each feature in left region file is compared to right region(s) file(s) in search of overlaps. (BAM/BED/GFF/VCF formatted)"
        },
        {
          "right": "Path or list of paths to region(s) file(s) (BAM/BED/GFF/VCF formatted)"
        }
      ],
      "output_types": [
        "Path to the intersection."
      ],
      "rule": "rule bedtools_intersect:\n    input:\n        left=\"A.bed\",\n        right=\"B.bed\"\n    output:\n        \"A_B.intersected.bed\"\n    params:\n        ## Add optional parameters \n        extra=\"-wa -wb\" ## In this example, we want to write original entries in A and B for each overlap.\n    log:\n        \"logs/intersect/A_B.log\"\n    wrapper:\n        \"master/bio/bedtools/intersect\"\n\n\nrule bedtools_intersect_gz:\n    input:\n        left=\"A.bed\",\n        right=\"B.bed\"\n    output:\n        \"A_B.intersected.bed.gz\"\n    params:\n        ## Add optional parameters \n        extra=\"-wa -wb\" ## In this example, we want to write original entries in A and B for each overlap.\n    log:\n        \"logs/intersect/A_B_gz.log\"\n    wrapper:\n        \"master/bio/bedtools/intersect\"\n"
    },
    {
      "name": "bedtools_merge",
      "input": {
        "default": "A.bed"
      },
      "output": {
        "default": "A.merged.bed"
      },
      "log": {
        "default": "logs/merge/A.log"
      },
      "params": {
        "extra": "-c 1 -o count"
      },
      "wrapper": {
        "default": "master/bio/bedtools/merge"
      },
      "input_types": [
        "Path or list of paths to interval(s) file(s) (BED/GFF/VCF/BAM)"
      ],
      "output_types": [
        "Path to merged interval(s) file."
      ],
      "rule": "rule bedtools_merge:\n    input:\n        # Multiple bed-files can be added as list\n        \"A.bed\"\n    output:\n        \"A.merged.bed\"\n    params:\n        ## Add optional parameters \n        extra=\"-c 1 -o count\" ## In this example, we want to count how many input lines we merged per output line\n    log:\n        \"logs/merge/A.log\"\n    wrapper:\n        \"master/bio/bedtools/merge\"\n"
    },
    {
      "name": "bedtools_sort",
      "input": {
        "in_file": "a.bed"
      },
      "output": {
        "default": "results/bed-sorted/a.sorted.bed"
      },
      "log": {
        "default": "logs/a.sorted.bed.log"
      },
      "params": {
        "extra": "-sizeA"
      },
      "wrapper": {
        "default": "master/bio/bedtools/sort"
      },
      "input_types": [
        {
          "in_file": "Path to interval file (BED/GFF/VCF formatted)"
        },
        {
          "genome": "optional a tab separating file that determines the sorting order and contains the chromosome names in the first column"
        },
        {
          "faidx": "optional a fasta index file"
        }
      ],
      "output_types": [
        "Path to the sorted interval file (BED/GFF/VCF formatted)"
      ],
      "rule": "rule bedtools_sort:\n    input:\n        in_file=\"a.bed\"\n    output:\n        \"results/bed-sorted/a.sorted.bed\"\n    params:\n        ## Add optional parameters for sorting order\n        extra=\"-sizeA\"\n    log:\n        \"logs/a.sorted.bed.log\"\n    wrapper:\n        \"master/bio/bedtools/sort\"\n\nrule bedtools_sort_bed:\n    input:\n        in_file=\"a.bed\",\n        # an optional sort file can be set as genomefile by the variable genome or\n        # as fasta index file by the variable faidx\n        genome=\"dummy.genome\"\n    output:\n        \"results/bed-sorted/a.sorted_by_file.bed\"\n    params:\n        ## Add optional parameters\n        extra=\"\"\n    log:\n        \"logs/a.sorted.bed.log\"\n    wrapper:\n        \"master/bio/bedtools/sort\"\n\nrule bedtools_sort_vcf:\n    input:\n        in_file=\"a.vcf\",\n        # an optional sort file can be set either as genomefile by the variable genome or\n        # as fasta index file by the variable faidx\n        faidx=\"genome.fasta.fai\"\n    output:\n        \"results/vcf-sorted/a.sorted_by_file.vcf\"\n    params:\n        ## Add optional parameters\n        extra=\"\"\n    log:\n        \"logs/a.sorted.vcf.log\"\n    wrapper:\n        \"master/bio/bedtools/sort\"\n"
    },
    {
      "name": "bellerophon_sam",
      "input": {
        "fwd": "test_1500_forward.bam",
        "rev": "test_1500_reverse.bam"
      },
      "output": {
        "bam": "out.sam"
      },
      "log": {
        "default": "logs/bellerophon.log"
      },
      "params": {
        "extra": "--quality 20",
        "sorting": "none",
        "sort_extra": "--no-PG"
      },
      "wrapper": {
        "default": "master/bio/bellerophon"
      },
      "input_types": [
        "Forward reads (BAM format)",
        "Reverse reads (BAM format)"
      ],
      "output_types": [
        "SAM/BAM/CRAM file"
      ],
      "rule": "rule bellerophon_sam:\n    input:\n        fwd=\"test_1500_forward.bam\",\n        rev=\"test_1500_reverse.bam\",\n    output:\n        bam=\"out.sam\",\n    log:\n        \"logs/bellerophon.log\",\n    params:\n        extra=\"--quality 20\",\n        sorting=\"none\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"--no-PG\",  # optional: extra arguments for samtools/picard\n    threads: 2\n    wrapper:\n        \"master/bio/bellerophon\"\n\n\nrule bellerophon_bam:\n    input:\n        fwd=\"test_1500_forward.bam\",\n        rev=\"test_1500_reverse.bam\",\n    output:\n        bam=\"out.bam\",\n    log:\n        \"logs/bellerophon.log\",\n    params:\n        extra=\"--quality 20\",\n        sorting=\"coordinate\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"--no-PG\",  # optional: extra arguments for samtools/picard\n    threads: 2\n    wrapper:\n        \"master/bio/bellerophon\"\n"
    },
    {
      "name": "benchmark_variants",
      "input": {
        "truth": "truth.vcf",
        "query": "query.vcf",
        "truth_regions": "truth.bed",
        "strats": "stratifications.tsv",
        "strat_dir": "strats_dir",
        "genome": "genome.fasta",
        "genome_index": "genome.fasta.fai"
      },
      "output": {
        "default": "multiext('results', '.runinfo.json', '.vcf.gz', '.summary.csv', '.extended.csv', '.metrics.json.gz', '.roc.all.csv.gz', '.roc.Locations.INDEL.csv.gz', '.roc.Locations.INDEL.PASS.csv.gz', '.roc.Locations.SNP.csv.gz', '.roc.tsv')"
      },
      "log": {
        "default": "happy.log"
      },
      "params": {
        "engine": "vcfeval",
        "prefix": "lambda wc, input, output: output[0].split('.')[0]",
        "extra": "--verbose"
      },
      "wrapper": {
        "default": "master/bio/hap.py/hap.py"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule benchmark_variants:\n    input:\n        truth=\"truth.vcf\",\n        query=\"query.vcf\",\n        truth_regions=\"truth.bed\",\n        strats=\"stratifications.tsv\",\n        strat_dir=\"strats_dir\",\n        genome=\"genome.fasta\",\n        genome_index=\"genome.fasta.fai\"\n    output:\n        multiext(\"results\",\".runinfo.json\",\".vcf.gz\",\".summary.csv\",\n                \".extended.csv\",\".metrics.json.gz\",\".roc.all.csv.gz\",\n                \".roc.Locations.INDEL.csv.gz\",\".roc.Locations.INDEL.PASS.csv.gz\",\n                \".roc.Locations.SNP.csv.gz\",\".roc.tsv\")\n    params:\n        engine=\"vcfeval\",\n        prefix=lambda wc, input, output: output[0].split('.')[0],\n        ## parameters such as -L to left-align variants\n        extra=\"--verbose\"\n    log: \"happy.log\"\n    threads: 2\n    wrapper: \"master/bio/hap.py/hap.py\"\n"
    },
    {
      "name": "bgzip",
      "input": {
        "default": "{prefix}.vcf"
      },
      "output": {
        "default": "{prefix}.vcf.gz"
      },
      "log": {
        "default": "logs/bgzip/{prefix}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bgzip"
      },
      "input_types": [
        "file to be compressed or decompressed"
      ],
      "output_types": [
        "compressed or decompressed output"
      ],
      "rule": "rule bgzip:\n    input:\n        \"{prefix}.vcf\",\n    output:\n        \"{prefix}.vcf.gz\",\n    params:\n        extra=\"\", # optional\n    threads: 1\n    log:\n        \"logs/bgzip/{prefix}.log\",\n    wrapper:\n        \"master/bio/bgzip\"\n"
    },
    {
      "name": "bismark2bedGraph_noncpg",
      "input": {
        "default": "meth/CHG_context_{sample}.txt.gz"
      },
      "output": {
        "bedGraph": "meth_non_cpg/{sample}_non_cpg.bedGraph.gz",
        "cov": "meth_non_cpg/{sample}_non_cpg.bismark.cov.gz"
      },
      "log": {
        "default": "logs/meth_non_cpg/{sample}_non_cpg.log"
      },
      "params": {
        "extra": "--CX"
      },
      "wrapper": {
        "default": "master/bio/bismark/bismark2bedGraph"
      },
      "input_types": [
        "Files generated by bismark_methylation_extractor, e.g. CpG_context\\*.txt.gz, CHG_context\\*.txt.gz, CHH_context\\*.txt.gz. By default only CpG file is required, if '--CX' option is output is build by merged input files."
      ],
      "output_types": [
        {
          "bedGraph": "Bismark methylation level track, \\*.bedGraph.gz (0-based start, 1-based end coordintates, i.e. end offset exclusive)"
        },
        {
          "cov": "Optional bismark coverage file \\*.bismark.cov.gz, file name is calculated by bedGraph name (1-based start and end, i.e. end offset inclusive)"
        }
      ],
      "rule": "# Example for CHG+CHH summary coverage:\nrule bismark2bedGraph_noncpg:\n    input:\n        \"meth/CHG_context_{sample}.txt.gz\",\n        \"meth/CHH_context_{sample}.txt.gz\"\n    output:\n        bedGraph=\"meth_non_cpg/{sample}_non_cpg.bedGraph.gz\",\n        cov=\"meth_non_cpg/{sample}_non_cpg.bismark.cov.gz\"\n    log:\n        \"logs/meth_non_cpg/{sample}_non_cpg.log\"\n    params:\n        extra=\"--CX\"\n    wrapper:\n        \"master/bio/bismark/bismark2bedGraph\"\n\n# Example for CpG only coverage\nrule bismark2bedGraph_cpg:\n    input:\n        \"meth/CpG_context_{sample}.txt.gz\"\n    output:\n        bedGraph=\"meth_cpg/{sample}_CpG.bedGraph.gz\",\n        cov=\"meth_cpg/{sample}_CpG.bismark.cov.gz\"\n    log:\n        \"logs/meth_cpg/{sample}_CpG.log\"\n    wrapper:\n        \"master/bio/bismark/bismark2bedGraph\"\n"
    },
    {
      "name": "bismark2report_pe",
      "input": {
        "alignment_report": "bams/{sample}_{genome}_PE_report.txt",
        "nucleotide_report": "bams/{sample}_{genome}_pe.nucleotide_stats.txt",
        "dedup_report": "bams/{sample}_{genome}_pe.deduplication_report.txt",
        "mbias_report": "meth/{sample}_{genome}_pe.deduplicated.M-bias.txt",
        "splitting_report": "meth/{sample}_{genome}_pe.deduplicated_splitting_report.txt"
      },
      "output": {
        "html": "qc/meth/{sample}_{genome}.bismark2report.html"
      },
      "log": {
        "default": "logs/qc/meth/{sample}_{genome}.bismark2report.html.log"
      },
      "params": {
        "skip_optional_reports": true
      },
      "wrapper": {
        "default": "master/bio/bismark/bismark2report"
      },
      "input_types": [
        {
          "alignment_report": "Alignment report (if not specified bismark will try to find it current directory)"
        },
        {
          "nucleotide_report": "Optional Bismark nucleotide coverage report (if not specified bismark will try to find it current directory)"
        },
        {
          "dedup_report": "Optional deduplication report (if not specified bismark will try to find it current directory)"
        },
        {
          "splitting_report": "Optional Bismark methylation extractor report (if not specified bismark will try to find it current directory)"
        },
        {
          "mbias_report": "Optional Bismark methylation extractor report (if not specified bismark will try to find it current directory)"
        }
      ],
      "output_types": [
        {
          "html": "Output HTML file path, if batch mode isn't used."
        },
        {
          "html_dir": "Output dir path for HTML reports if batch mode is used"
        }
      ],
      "rule": "# Example: Pair-ended reads\nrule bismark2report_pe:\n    input:\n        alignment_report=\"bams/{sample}_{genome}_PE_report.txt\",\n        nucleotide_report=\"bams/{sample}_{genome}_pe.nucleotide_stats.txt\",\n        dedup_report=\"bams/{sample}_{genome}_pe.deduplication_report.txt\",\n        mbias_report=\"meth/{sample}_{genome}_pe.deduplicated.M-bias.txt\",\n        splitting_report=\"meth/{sample}_{genome}_pe.deduplicated_splitting_report.txt\"\n    output:\n        html=\"qc/meth/{sample}_{genome}.bismark2report.html\",\n    log:\n        \"logs/qc/meth/{sample}_{genome}.bismark2report.html.log\",\n    params:\n        skip_optional_reports=True\n    wrapper:\n        \"master/bio/bismark/bismark2report\"\n\n# Example: Single-ended reads\nrule bismark2report_se:\n    input:\n        alignment_report=\"bams/{sample}_{genome}_SE_report.txt\",\n        nucleotide_report=\"bams/{sample}_{genome}.nucleotide_stats.txt\",\n        dedup_report=\"bams/{sample}_{genome}.deduplication_report.txt\",\n        mbias_report=\"meth/{sample}_{genome}.deduplicated.M-bias.txt\",\n        splitting_report=\"meth/{sample}_{genome}.deduplicated_splitting_report.txt\"\n    output:\n        html=\"qc/meth/{sample}_{genome}.bismark2report.html\",\n    log:\n        \"logs/qc/meth/{sample}_{genome}.bismark2report.html.log\",\n    params:\n        skip_optional_reports=True\n    wrapper:\n        \"master/bio/bismark/bismark2report\"\n"
    },
    {
      "name": "bismark_genome_preparation_fa",
      "input": {
        "genome": "resources/{genome}/{genome}.fa"
      },
      "output": {
        "bismark_genome_dir": "directory('resources/{genome}/bismark/')"
      },
      "log": {
        "default": "logs/resources/{genome}/bismark_genome_preparation.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bismark/bismark_genome_preparation"
      },
      "input_types": {
        "genome": "path to genome \\*.fa (or \\*.fasta, \\*.fa.gz, \\*.fasta.gz) file"
      },
      "output_types": {
        "bismark_genome_dir": "output directory where generated bismark indexes are moved and input fasta file is soft-linked"
      },
      "rule": "# For *.fa file\nrule bismark_genome_preparation_fa:\n    input:\n        genome=\"resources/{genome}/{genome}.fa\",\n    output:\n        bismark_genome_dir=directory(\"resources/{genome}/bismark/\"),\n    log:\n        \"logs/resources/{genome}/bismark_genome_preparation.log\",\n    params:\n        extra=\"\",  # optional params string\n    threads: 2  # bismark_genome_preparation requires least 2 threads and at least --cores 2 from workflow run\n    wrapper:\n        \"master/bio/bismark/bismark_genome_preparation\"\n\n\n# For *.fa.gz file:\nrule bismark_genome_preparation_fa_gz:\n    input:\n        genome=\"resources/{genome}/{genome}.fa.gz\",\n    output:\n        bismark_genome_dir=directory(\"resources/{genome}/bismark/\"),\n    log:\n        \"logs/resources/{genome}/bismark_genome_preparation.log\",\n    params:\n        extra=\"\",  # optional params string\n    threads: 2  # bismark_genome_preparation requires least 2 threads and at least --cores 2 from workflow run\n    wrapper:\n        \"master/bio/bismark/bismark_genome_preparation\"\n"
    },
    {
      "name": "bismark_methylation_extractor",
      "input": {
        "default": "bams/{sample}.bam"
      },
      "output": {
        "mbias_r1": "qc/meth/{sample}.M-bias_R1.png",
        "mbias_report": "meth/{sample}.M-bias.txt",
        "splitting_report": "meth/{sample}_splitting_report.txt",
        "methylome_CpG_cov": "meth_cpg/{sample}.bismark.cov.gz",
        "methylome_CpG_mlevel_bedGraph": "meth_cpg/{sample}.bedGraph.gz",
        "read_base_meth_state_cpg": "meth/CpG_context_{sample}.txt.gz",
        "read_base_meth_state_chg": "meth/CHG_context_{sample}.txt.gz",
        "read_base_meth_state_chh": "meth/CHH_context_{sample}.txt.gz"
      },
      "log": {
        "default": "logs/meth/{sample}.log"
      },
      "params": {
        "output_dir": "meth",
        "extra": "--gzip --comprehensive --bedGraph"
      },
      "wrapper": {
        "default": "master/bio/bismark/bismark_methylation_extractor"
      },
      "input_types": [
        "Input BAM file aligned by Bismark"
      ],
      "output_types": [
        "Depends on bismark options passed to `params.extra`, optional for this wrapper",
        {
          "mbias_report": "M-bias report, \\*.M-bias.txt (if key is provided, the out file will be renamed to this name)"
        },
        {
          "mbias_r1": "M-Bias plot for R1, \\*.M-bias_R1.png (if key is provided, the out file will be renamed to this name)"
        },
        {
          "mbias_r2": "M-Bias plot for R2, \\*.M-bias_R2.png (if key is provided, the out file will be renamed to this name)"
        },
        {
          "splitting_report": "Splitting report, \\*_splitting_report.txt (if key is provided, the out file will be renamed to this name)"
        },
        {
          "methylome_CpG_cov": "Bismark coverage file for CpG context, \\*.bismark.cov.gz (if key is provided, the out file will be renamed to this name)"
        },
        {
          "methylome_CpG_mlevel_bedGraph": "Bismark methylation level track, \\*.bedGraph.gz"
        },
        {
          "read_base_meth_state_cpg": "Per read CpG base methylation info, CpG_context\\_\\*.txt.gz  (if key is provided, the out file will be renamed to this name)"
        },
        {
          "read_base_meth_state_chg": "Per read CpG base methylation info, CHG_context\\_\\*.txt.gz  (if key is provided, the out file will be renamed to this name)"
        },
        {
          "read_base_meth_state_chh": "Per read CpG base methylation info, CHH_context\\_\\*.txt.gz  (if key is provided, the out file will be renamed to this name)"
        }
      ],
      "rule": "rule bismark_methylation_extractor:\n    input: \"bams/{sample}.bam\"\n    output:\n        mbias_r1=\"qc/meth/{sample}.M-bias_R1.png\",\n        # Only for PE BAMS:\n        # mbias_r2=\"qc/meth/{sample}.M-bias_R2.png\",\n\n        mbias_report=\"meth/{sample}.M-bias.txt\",\n        splitting_report=\"meth/{sample}_splitting_report.txt\",\n\n        # 1-based start, 1-based end ('inclusive') methylation info: % and counts\n        methylome_CpG_cov=\"meth_cpg/{sample}.bismark.cov.gz\",\n        # BedGraph with methylation percentage: 0-based start, end exclusive\n        methylome_CpG_mlevel_bedGraph=\"meth_cpg/{sample}.bedGraph.gz\",\n\n        # Primary output files: methylation status at each read cytosine position: (extremely large)\n        read_base_meth_state_cpg=\"meth/CpG_context_{sample}.txt.gz\",\n        # * You could merge CHG, CHH using: --merge_non_CpG\n        read_base_meth_state_chg=\"meth/CHG_context_{sample}.txt.gz\",\n        read_base_meth_state_chh=\"meth/CHH_context_{sample}.txt.gz\"\n    log:\n        \"logs/meth/{sample}.log\"\n    params:\n        output_dir=\"meth\",  # optional output dir\n        extra=\"--gzip --comprehensive --bedGraph\"  # optional params string\n    wrapper:\n        \"master/bio/bismark/bismark_methylation_extractor\"\n"
    },
    {
      "name": "bismark_pe",
      "input": {
        "fq_1": "reads/{sample}.1.fastq",
        "fq_2": "reads/{sample}.2.fastq",
        "bismark_indexes_dir": "resources/{genome}/"
      },
      "output": {
        "bam": "results/bismark/{sample}_{genome}_pe.bam",
        "report": "results/bismark/{sample}_{genome}_pe_report.txt",
        "fq_unmapped_1": "results/bismark/{sample}_{genome}.unmapped_reads_1.fq.gz",
        "fq_unmapped_2": "results/bismark/{sample}_{genome}.unmapped_reads_2.fq.gz",
        "fq_ambiguous_1": "results/bismark/{sample}_{genome}.ambiguous_reads_1.fq.gz",
        "fq_ambiguous_2": "results/bismark/{sample}_{genome}.ambiguous_reads_2.fq.gz"
      },
      "log": {
        "default": "logs/bismark/{sample}_{genome}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bismark/bismark"
      },
      "input_types": [
        "For single end data, provide one read file with the names `fq=...`.",
        "For paired end data, provide two read files with the names `fq_1=...` and `fq_2=...`/",
        {
          "bismark_indexes_dir": "The path to the folder that contains the `Bisulfite_Genome` created by the `bismark_genome_preparation` script, e.g. 'resources/hg19/bismark'"
        },
        {
          "genomic_freqs (optional)": "When requesting the optional output `nucleotide_stats`, please include a `genomic_nucleotide_frequencies.txt` file for this input (precomputed with `bam2nuc`)."
        }
      ],
      "output_types": [
        {
          "bam, cram, or sam": "The output file's name as `bam=`, `sam=` or `cram=` determines the output format, by implicitly setting the respective `--sam` or `--cram` options."
        },
        {
          "report": "Alignment report file."
        },
        {
          "nucleotide_stats (optional)": "Report on the mono- and di-nucleotide sequence composition of covered positions in the analysed `.bam` file in comparison to the average genomic composition. Requires `genomic_freqs=` to be provided as an input, and is incompatible with `sam=` output."
        },
        {
          "fq_unmapped (optional)": "Write unmapped reads to a `.fq.gz` file. Implicitly activates `--unmapped`."
        },
        {
          "fq_ambiguous (optional)": "Write ambiguously mapped reads to a `.fq.gz` file. Implicitly activates `--ambiguous`."
        },
        {
          "bam_ambiguous (optional)": "Write one mapping per ambiguously mapped read to a `.bam` file. Implicitly activates `--ambig_bam`."
        }
      ],
      "rule": "# Example: Pair-end reads\nrule bismark_pe:\n    input:\n        fq_1=\"reads/{sample}.1.fastq\",\n        fq_2=\"reads/{sample}.2.fastq\",\n        bismark_indexes_dir=\"resources/{genome}/\",\n    output:\n        bam=\"results/bismark/{sample}_{genome}_pe.bam\",\n        report=\"results/bismark/{sample}_{genome}_pe_report.txt\",\n        fq_unmapped_1=\"results/bismark/{sample}_{genome}.unmapped_reads_1.fq.gz\",  # optional: implicitly activates --unmapped\n        fq_unmapped_2=\"results/bismark/{sample}_{genome}.unmapped_reads_2.fq.gz\",  # optional: implicitly activates --unmapped\n        fq_ambiguous_1=\"results/bismark/{sample}_{genome}.ambiguous_reads_1.fq.gz\",  # optional: implicitly activates --ambiguous\n        fq_ambiguous_2=\"results/bismark/{sample}_{genome}.ambiguous_reads_2.fq.gz\",  # optional: implicitly activates --ambiguous\n    log:\n        \"logs/bismark/{sample}_{genome}.log\",\n    params:\n        # optional params string, e.g: \"-L32 -N0 -X400\"\n        # Useful options to tune:\n        # (for bowtie2)\n        # -N: The maximum number of mismatches permitted in the \"seed\", i.e. the first L base pairs\n        # of the read (deafault: 1)\n        # -L: The \"seed length\" (deafault: 28)\n        # -I: The minimum insert size for valid paired-end alignments. ~ min fragment size filter (for\n        # PE reads)\n        # -X: The maximum insert size for valid paired-end alignments. ~ max fragment size filter (for\n        # PE reads)\n        extra=\"\",\n    threads: 5  # bismark in pe mode will run parallel with a minimum of 5 threads, no matter what - please ensure your workflow provides at least --cores 5\n    wrapper:\n        \"master/bio/bismark/bismark\"\n\n\n# Example: Single-end reads\nrule bismark_se:\n    input:\n        fq=\"reads/{sample}.fq.gz\",\n        bismark_indexes_dir=\"resources/{genome}/\",\n        genomic_freq=\"resources/{genome}/genomic_nucleotide_frequencies.txt\",  # only required for nucleotide_stats output, to avoid race conditions; generate with bam2nuc wrapper\n    output:\n        cram=\"results/bismark/{sample}_{genome}.cram\",\n        report=\"results/bismark/{sample}_{genome}_se_report.txt\",\n        nucleotide_stats=\"results/bismark/{sample}_{genome}.nucleotide_stats.txt\",  # optional: implicitly activates --nucleotide_coverage\n        fq_unmapped=\"results/bismark/{sample}_{genome}.unmapped_reads.fq.gz\",  # optional: implicitly activates --unmapped\n        fq_ambiguous=\"results/bismark/{sample}_{genome}.ambiguous_reads.fq.gz\",  # optional: implicitly activates --ambiguous\n        bam_ambiguous=\"results/bismark/{sample}_{genome}.ambiguous_reads.bam\",  # optional: implicitly activates --ambig_bam\n    log:\n        \"logs/bismark/{sample}_{genome}.log\",\n    params:\n        extra=\"\",\n    threads: 3  # bismark in se mode will run parallel with a minimum of 3 threads, no matter what - please ensure your workflow provides at least --cores 3\n    wrapper:\n        \"master/bio/bismark/bismark\"\n"
    },
    {
      "name": "blast_makedatabase_nucleotide",
      "input": {
        "fasta": "genome/{genome}.fasta"
      },
      "output": {
        "default": "multiext('results/{genome}.fasta', '.ndb', '.nhr', '.nin', '.not', '.nsq', '.ntf', '.nto')"
      },
      "log": {
        "default": "logs/{genome}.log"
      },
      "params": {
        "default": "-input_type fasta -blastdb_version 5 -parse_seqids"
      },
      "wrapper": {
        "default": "master/bio/blast/makeblastdb"
      },
      "input_types": [
        {
          "fasta": "Path to FASTA file"
        }
      ],
      "output_types": [
        "Path to database multiple files with different extensions (e.g. .nin, .nsq, .nhr for nucleotides or .pin, .psq, .phr for proteins)"
      ],
      "rule": "rule blast_makedatabase_nucleotide:\n    input:\n        fasta=\"genome/{genome}.fasta\"\n    output:\n        multiext(\"results/{genome}.fasta\",\n            \".ndb\",\n            \".nhr\",\n            \".nin\",\n            \".not\",\n            \".nsq\",\n            \".ntf\",\n            \".nto\"\n        )\n    log:\n        \"logs/{genome}.log\"\n    params:\n        \"-input_type fasta -blastdb_version 5 -parse_seqids\"\n    wrapper:\n        \"master/bio/blast/makeblastdb\"\n\nrule blast_makedatabase_protein:\n    input:\n        fasta=\"protein/{protein}.fasta\"\n    output:\n        multiext(\"results/{protein}.fasta\",\n            \".pdb\",\n            \".phr\",\n            \".pin\",\n            \".pot\",\n            \".psq\",\n            \".ptf\",\n            \".pto\"\n        )\n    log:\n        \"logs/{protein}.log\"\n    params:\n        \"-input_type fasta -blastdb_version 5\"\n    wrapper:\n        \"master/bio/blast/makeblastdb\"\n"
    },
    {
      "name": "blast_nucleotide",
      "input": {
        "query": "{sample}.fasta",
        "blastdb": "multiext('blastdb/blastdb', '.ndb', '.nhr', '.nin', '.not', '.nsq', '.ntf', '.nto')"
      },
      "output": {
        "default": "{sample}.blast.txt"
      },
      "log": {
        "default": "logs/{sample}.blast.log"
      },
      "params": {
        "format": "6 qseqid sseqid evalue",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/blast/blastn"
      },
      "input_types": [
        {
          "query": "FASTA file OR bare sequence file (`more information <https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp>`_) OR identifiers (`more information <https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp>`_)"
        },
        {
          "blastdb": "Path to blast database"
        }
      ],
      "output_types": [
        "Path to result file depending on the formatting option, different output files can be generated (see tables above)"
      ],
      "rule": "rule blast_nucleotide:\n    input:\n        query = \"{sample}.fasta\",\n        blastdb=multiext(\"blastdb/blastdb\",\n            \".ndb\",\n            \".nhr\",\n            \".nin\",\n            \".not\",\n            \".nsq\",\n            \".ntf\",\n            \".nto\"\n        )\n    output:\n        \"{sample}.blast.txt\"\n    log:\n        \"logs/{sample}.blast.log\"\n    threads:\n        2\n    params:\n        # Usable options and specifiers for the different output formats are listed here:\n        # https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/blast/blastn.html.\n        format=\"6 qseqid sseqid evalue\",\n        extra=\"\"\n    wrapper:\n        \"master/bio/blast/blastn\"\n"
    },
    {
      "name": "bowtie2_build",
      "input": {
        "ref": "genome.fasta"
      },
      "output": {
        "default": "multiext('genome', '.1.bt2', '.2.bt2', '.3.bt2', '.4.bt2', '.rev.1.bt2', '.rev.2.bt2')"
      },
      "log": {
        "default": "logs/bowtie2_build/build.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bowtie2/build"
      },
      "input_types": [
        {
          "ref": "Path to FASTA reference"
        }
      ],
      "output_types": [
        "Path to Bowtie2 reference index"
      ],
      "rule": "rule bowtie2_build:\n    input:\n        ref=\"genome.fasta\",\n    output:\n        multiext(\n            \"genome\",\n            \".1.bt2\",\n            \".2.bt2\",\n            \".3.bt2\",\n            \".4.bt2\",\n            \".rev.1.bt2\",\n            \".rev.2.bt2\",\n        ),\n    log:\n        \"logs/bowtie2_build/build.log\",\n    params:\n        extra=\"\",  # optional parameters\n    threads: 8\n    wrapper:\n        \"master/bio/bowtie2/build\"\n\n\n\nrule bowtie2_build_large:\n    input:\n        ref=\"genome.fasta\",\n    output:\n        multiext(\n            \"genome\",\n            \".1.bt2l\",\n            \".2.bt2l\",\n            \".3.bt2l\",\n            \".4.bt2l\",\n            \".rev.1.bt2l\",\n            \".rev.2.bt2l\",\n        ),\n    log:\n        \"logs/bowtie2_build/build.log\",\n    params:\n        extra=\"--large-index\",  # optional parameters\n    threads: 8\n    wrapper:\n        \"master/bio/bowtie2/build\"\n"
    },
    {
      "name": "bwa_aln",
      "input": {
        "fastq": "reads/{sample}.{pair}.fastq",
        "idx": "multiext('genome', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "output": {
        "default": "sai/{sample}.{pair}.sai"
      },
      "log": {
        "default": "logs/bwa_aln/{sample}.{pair}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bwa/aln"
      },
      "input_types": [
        "fastq\" FASTQ file(s)",
        {
          "idx": "BWA reference genome index"
        }
      ],
      "output_types": [
        "SAI file"
      ],
      "rule": "rule bwa_aln:\n    input:\n        fastq=\"reads/{sample}.{pair}.fastq\",\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"sai/{sample}.{pair}.sai\",\n    params:\n        extra=\"\",\n    log:\n        \"logs/bwa_aln/{sample}.{pair}.log\",\n    threads: 8\n    wrapper:\n        \"master/bio/bwa/aln\"\n"
    },
    {
      "name": "bwa_index",
      "input": {
        "default": "{genome}.fasta"
      },
      "output": {
        "idx": "multiext('{genome}.{alg}', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "log": {
        "default": "logs/bwa_index/{genome}.{alg}.log"
      },
      "params": {
        "extra": "lambda w: f'-a {w.alg}'"
      },
      "wrapper": {
        "default": "master/bio/bwa/index"
      },
      "input_types": [
        "fasta file"
      ],
      "output_types": [
        "BWA index files"
      ],
      "rule": "rule bwa_index:\n    input:\n        \"{genome}.fasta\",\n    output:\n        idx=multiext(\"{genome}.{alg}\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    log:\n        \"logs/bwa_index/{genome}.{alg}.log\",\n    params:\n        extra=lambda w: f\"-a {w.alg}\",\n    wrapper:\n        \"master/bio/bwa/index\"\n"
    },
    {
      "name": "bwa_mem",
      "input": {
        "reads": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "idx": "multiext('genome', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "output": {
        "bam": "mapped/{sample}.bam",
        "bai": "mapped/{sample}.bam.bai"
      },
      "log": {
        "default": "logs/bwa_mem_sambamba/{sample}.log"
      },
      "params": {
        "extra": "-R '@RG\\tID:{sample}\\tSM:{sample}'",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/bwa/mem-samblaster"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bwa_mem:\n    input:\n        reads=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        bam=\"mapped/{sample}.bam\",\n        bai=\"mapped/{sample}.bam.bai\",\n    log:\n        \"logs/bwa_mem_sambamba/{sample}.log\",\n    params:\n        extra=r\"-R '@RG\\tID:{sample}\\tSM:{sample}'\",\n        sort_extra=\"\",  # Extra args for sambamba.\n    threads: 8\n    wrapper:\n        \"master/bio/bwa/mem-samblaster\"\n"
    },
    {
      "name": "bwa_mem2_index",
      "input": {
        "default": "{genome}"
      },
      "output": {
        "default": "{genome}.0123"
      },
      "log": {
        "default": "logs/bwa-mem2_index/{genome}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/bwa-mem2/index"
      },
      "input_types": [
        "Reference genome (FASTA )"
      ],
      "output_types": [
        "Indexed reference genome"
      ],
      "rule": "rule bwa_mem2_index:\n    input:\n        \"{genome}\",\n    output:\n        \"{genome}.0123\",\n        \"{genome}.amb\",\n        \"{genome}.ann\",\n        \"{genome}.bwt.2bit.64\",\n        \"{genome}.pac\",\n    log:\n        \"logs/bwa-mem2_index/{genome}.log\",\n    wrapper:\n        \"master/bio/bwa-mem2/index\"\n"
    },
    {
      "name": "bwa_mem2_mem",
      "input": {
        "reads": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "idx": "multiext('genome.fasta', '.amb', '.ann', '.bwt.2bit.64', '.pac', '.0123')"
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/bwa_mem2/{sample}.log"
      },
      "params": {
        "extra": "-R '@RG\\tID:{sample}\\tSM:{sample}'",
        "sort": "none",
        "sort_order": "coordinate",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/bwa-mem2/mem"
      },
      "input_types": [
        {
          "reads": "List of path(s) to FASTQ file(s)"
        },
        {
          "idx": "List of paths to indexed reference genome files.\nAll index files required need to be declared:\n\".0123\", \".amb\", \".ann\", \".bwt.2bit.64\", \".pac\"\n"
        }
      ],
      "output_types": [
        "SAM/BAM/CRAM file"
      ],
      "rule": "rule bwa_mem2_mem:\n    input:\n        reads=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        # Index needs to be a list of all index files created by bwa\n        idx=multiext(\"genome.fasta\", \".amb\", \".ann\", \".bwt.2bit.64\", \".pac\", \".0123\"),\n    output:\n        \"mapped/{sample}.bam\",\n    log:\n        \"logs/bwa_mem2/{sample}.log\",\n    params:\n        extra=r\"-R '@RG\\tID:{sample}\\tSM:{sample}'\",\n        sort=\"none\",  # Can be 'none', 'samtools', or 'picard'.\n        sort_order=\"coordinate\",  # Can be 'coordinate' (default) or 'queryname'.\n        sort_extra=\"\",  # Extra args for samtools/picard sorts.\n    threads: 8\n    wrapper:\n        \"master/bio/bwa-mem2/mem\"\n\n\nrule bwa_mem2_mem_sam:\n    input:\n        reads=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        # Index needs to be a list of all index files created by bwa\n        idx=multiext(\"genome.fasta\", \".amb\", \".ann\", \".bwt.2bit.64\", \".pac\", \".0123\"),\n    output:\n        \"mapped/{sample}.sam\",\n    log:\n        \"logs/bwa_mem2/{sample}.log\",\n    params:\n        extra=r\"-R '@RG\\tID:{sample}\\tSM:{sample}'\",\n        sort=\"none\",  # Can be 'none', 'samtools', or 'picard'.\n        sort_order=\"coordinate\",  # Can be 'coordinate' (default) or 'queryname'.\n        sort_extra=\"\",  # Extra args for samtools/picard sorts.\n    threads: 8\n    wrapper:\n        \"master/bio/bwa-mem2/mem\"\n"
    },
    {
      "name": "bwa_mem_index",
      "input": {
        "default": "{genome}"
      },
      "output": {
        "default": "multiext('{genome}', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "log": {
        "default": "logs/bwa-mem_index/{genome}.log"
      },
      "params": {
        "bwa": "bwa-mem"
      },
      "wrapper": {
        "default": "master/bio/bwa-memx/index"
      },
      "input_types": [
        "fasta file"
      ],
      "output_types": [
        "BWA index files, which should all share a common prefix. Note that this prefix can include an output directory path, for example \"myindex/prefix\"."
      ],
      "rule": "rule bwa_mem_index:\n    input:\n        \"{genome}\",\n    output:\n        multiext(\n            \"{genome}\",\n            \".amb\",\n            \".ann\",\n            \".bwt\",\n            \".pac\",\n            \".sa\",\n        ),\n    log:\n        \"logs/bwa-mem_index/{genome}.log\",\n    params:\n        bwa=\"bwa-mem\",\n    threads: 8\n    wrapper:\n        \"master/bio/bwa-memx/index\"\n\n\nrule bwa_mem2_index:\n    input:\n        \"{genome}\",\n    output:\n        multiext(\n            \"{genome}\",\n            \".0123\",\n            \".amb\",\n            \".ann\",\n            \".bwt.2bit.64\",\n            \".pac\",\n        ),\n    log:\n        \"logs/bwa-mem2_index/{genome}.log\",\n    params:\n        bwa=\"bwa-mem2\",\n    threads: 8\n    wrapper:\n        \"master/bio/bwa-memx/index\"\n\n\nrule bwa_meme_index:\n    input:\n        \"{genome}\",\n    output:\n        multiext(\n            \"{genome}\",\n            \".0123\",\n            \".amb\",\n            \".ann\",\n            \".pac\",\n            \".pos_packed\",\n            \".suffixarray_uint64\",\n            \".suffixarray_uint64_L0_PARAMETERS\",\n            \".suffixarray_uint64_L1_PARAMETERS\",\n            \".suffixarray_uint64_L2_PARAMETERS\",\n        ),\n    log:\n        \"logs/bwa-meme_index/{genome}.log\",\n    params:\n        bwa=\"bwa-meme\",\n        num_models=100000,  #[hide]\n    threads: 8\n    wrapper:\n        \"master/bio/bwa-memx/index\"\n"
    },
    {
      "name": "bwa_meme_index",
      "input": {
        "default": "{genome}"
      },
      "output": {
        "default": "multiext('{genome}', '.0123', '.amb', '.ann', '.pac', '.pos_packed', '.suffixarray_uint64', '.suffixarray_uint64_L0_PARAMETERS', '.suffixarray_uint64_L1_PARAMETERS', '.suffixarray_uint64_L2_PARAMETERS')"
      },
      "log": {
        "default": "logs/bwa-meme_index/{genome}.log"
      },
      "params": {
        "num_models": 100000
      },
      "wrapper": {
        "default": "master/bio/bwa-meme/index"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bwa_meme_index:\n    input:\n        \"{genome}\",\n    output:\n        multiext(\n            \"{genome}\",\n            \".0123\",\n            \".amb\",\n            \".ann\",\n            \".pac\",\n            \".pos_packed\",\n            \".suffixarray_uint64\",\n            \".suffixarray_uint64_L0_PARAMETERS\",\n            \".suffixarray_uint64_L1_PARAMETERS\",\n            \".suffixarray_uint64_L2_PARAMETERS\",\n        ),\n    log:\n        \"logs/bwa-meme_index/{genome}.log\",\n    params:  #[hide]\n        num_models=100000,  #[hide]\n    threads: 8\n    wrapper:\n        \"master/bio/bwa-meme/index\"\n"
    },
    {
      "name": "bwa_sam_pe",
      "input": {
        "fastq": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "sai": [
          "sai/{sample}.1.sai",
          "sai/{sample}.2.sai"
        ],
        "idx": "multiext('genome', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "output": {
        "default": "mapped/{sample}.pe.sam"
      },
      "log": {
        "default": "logs/bwa_sam_pe/{sample}.log"
      },
      "params": {
        "extra": "-r '@RG\\tID:{sample}\\tSM:{sample}'",
        "sort": "none"
      },
      "wrapper": {
        "default": "master/bio/bwa/samxe"
      },
      "input_types": [
        {
          "fastq": "FASTQ file(s)"
        },
        {
          "sai": "SAI file(s)"
        },
        {
          "idx": "BWA reference genome index"
        }
      ],
      "output_types": [
        "SAM/BAM alignment file"
      ],
      "rule": "rule bwa_sam_pe:\n    input:\n        fastq=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        sai=[\"sai/{sample}.1.sai\", \"sai/{sample}.2.sai\"],\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"mapped/{sample}.pe.sam\",\n    params:\n        extra=r\"-r '@RG\\tID:{sample}\\tSM:{sample}'\",  # optional: Extra parameters for bwa.\n        sort=\"none\",\n    log:\n        \"logs/bwa_sam_pe/{sample}.log\",\n    wrapper:\n        \"master/bio/bwa/samxe\"\n\n\nrule bwa_sam_se:\n    input:\n        fastq=\"reads/{sample}.1.fastq\",\n        sai=\"sai/{sample}.1.sai\",\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"mapped/{sample}.se.sam\",\n    params:\n        extra=r\"-r '@RG\\tID:{sample}\\tSM:{sample}'\",  # optional: Extra parameters for bwa.\n        sort=\"none\",\n    log:\n        \"logs/bwa_sam_se/{sample}.log\",\n    wrapper:\n        \"master/bio/bwa/samxe\"\n\n\nrule bwa_bam_pe:\n    input:\n        fastq=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        sai=[\"sai/{sample}.1.sai\", \"sai/{sample}.2.sai\"],\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"mapped/{sample}.pe.bam\",\n    params:\n        extra=r\"-r '@RG\\tID:{sample}\\tSM:{sample}'\",  # optional: Extra parameters for bwa.\n        sort=\"none\",\n    log:\n        \"logs/bwa_bam_pe/{sample}.log\",\n    wrapper:\n        \"master/bio/bwa/samxe\"\n\n\nrule bwa_bam_se:\n    input:\n        fastq=\"reads/{sample}.1.fastq\",\n        sai=\"sai/{sample}.1.sai\",\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"mapped/{sample}.se.bam\",\n    params:\n        extra=r\"-r '@RG\\tID:{sample}\\tSM:{sample}'\",  # optional: Extra parameters for bwa.\n        sort=\"none\",\n    log:\n        \"logs/bwa_bam_se/{sample}.log\",\n    wrapper:\n        \"master/bio/bwa/samxe\"\n"
    },
    {
      "name": "bwa_sampe",
      "input": {
        "fastq": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "sai": [
          "sai/{sample}.1.sai",
          "sai/{sample}.2.sai"
        ],
        "idx": "multiext('genome', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/bwa_sampe/{sample}.log"
      },
      "params": {
        "extra": "-r '@RG\\tID:{sample}\\tSM:{sample}'",
        "sort": "none",
        "sort_order": "queryname",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/bwa/sampe"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bwa_sampe:\n    input:\n        fastq=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        sai=[\"sai/{sample}.1.sai\", \"sai/{sample}.2.sai\"],\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"mapped/{sample}.bam\",\n    params:\n        extra=r\"-r '@RG\\tID:{sample}\\tSM:{sample}'\",  # optional: Extra parameters for bwa.\n        sort=\"none\",  # optional: Enable sorting. Possible values: 'none', 'samtools' or 'picard'`\n        sort_order=\"queryname\",  # optional: Sort by 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    log:\n        \"logs/bwa_sampe/{sample}.log\",\n    wrapper:\n        \"master/bio/bwa/sampe\"\n"
    },
    {
      "name": "bwa_samse",
      "input": {
        "fastq": "reads/{sample}.1.fastq",
        "sai": "sai/{sample}.1.sai",
        "idx": "multiext('genome', '.amb', '.ann', '.bwt', '.pac', '.sa')"
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/bwa_samse/{sample}.log"
      },
      "params": {
        "extra": "-r '@RG\\tID:{sample}\\tSM:{sample}'",
        "sort": "none",
        "sort_order": "queryname",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/bwa/samse"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule bwa_samse:\n    input:\n        fastq=\"reads/{sample}.1.fastq\",\n        sai=\"sai/{sample}.1.sai\",\n        idx=multiext(\"genome\", \".amb\", \".ann\", \".bwt\", \".pac\", \".sa\"),\n    output:\n        \"mapped/{sample}.bam\",\n    params:\n        extra=r\"-r '@RG\\tID:{sample}\\tSM:{sample}'\",  # optional: Extra parameters for bwa.\n        sort=\"none\",  # optional: Enable sorting. Possible values: 'none', 'samtools' or 'picard'`\n        sort_order=\"queryname\",  # optional: Sort by 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    log:\n        \"logs/bwa_samse/{sample}.log\",\n    wrapper:\n        \"master/bio/bwa/samse\"\n"
    },
    {
      "name": "calculate_expression",
      "input": {
        "bam": "mapped/a.bam",
        "reference": "multiext('index/reference', '.grp', '.ti', '.transcripts.fa', '.seq', '.idx.fa', '.n2g.idx.fa')"
      },
      "output": {
        "genes_results": "output/a.genes.results",
        "isoforms_results": "output/a.isoforms.results"
      },
      "log": {
        "default": "logs/rsem/calculate_expression/a.log"
      },
      "params": {
        "paired_end": true,
        "extra": "--seed 42"
      },
      "wrapper": {
        "default": "master/bio/rsem/calculate-expression"
      },
      "input_types": [
        {
          "bam": "BAM file with reads aligned to transcriptome"
        },
        {
          "fq_one": "FASTQ file of reads (read_1 for paired-end sequencing)"
        },
        {
          "fq_two": "Optional second FASTQ file of reads (read_2 for paired-end sequencing)"
        },
        {
          "reference": "Index files created by rsem-prepare-reference"
        },
        {
          "reference_bowtie": "Additionally needed for FASTQ input; Index files created (by bowtie-build) from the reference transcriptome"
        }
      ],
      "output_types": [
        {
          "genes_results": "This file contains per-gene quantification data for the sample"
        },
        {
          "isoforms_results": "This file contains per-transcript quantification data for the sample"
        }
      ],
      "rule": "rule calculate_expression:\n    input:\n        # input.bam or input.fq_one must be specified (and if input.fq_one, optionally input.fq_two if paired-end)\n        # an aligned to transcriptome BAM\n        bam=\"mapped/a.bam\",\n        # Index files created by rsem-prepare-reference\n        reference=multiext(\"index/reference\", \".grp\", \".ti\", \".transcripts.fa\", \".seq\", \".idx.fa\", \".n2g.idx.fa\"),\n        # reference_bowtie: Additionally needed for FASTQ input; Index files created (by bowtie-build) from the reference transcriptome\n        # reference_bowtie=multiext(\"index/reference\", \".1.ebwt\", \".2.ebwt\", \".3.ebwt\", \".4.ebwt\", \".rev.1.ebwt\", \".rev.2.ebwt\"),\n    output:\n        # genes_results must end in .genes.results; this suffix is stripped and passed to rsem as an output name prefix\n        # this file contains per-gene quantification data for the sample\n        genes_results=\"output/a.genes.results\",\n        # isoforms_results must end in .isoforms.results and otherwise have the same prefix as genes_results\n        # this file contains per-transcript quantification data for the sample\n        isoforms_results=\"output/a.isoforms.results\",\n    params:\n        # optional, specify if sequencing is paired-end\n        paired_end=True,\n        # additional optional parameters to pass to rsem, for example,\n        extra=\"--seed 42\",\n    log:\n        \"logs/rsem/calculate_expression/a.log\",\n    threads: 2\n    wrapper:\n        \"master/bio/rsem/calculate-expression\"\n"
    },
    {
      "name": "call_copy_ratio_segments",
      "input": {
        "copy_ratio_seg": "a.cr.seg"
      },
      "output": {
        "called_copy_ratio_seg": "a.called.seg",
        "igv_seg": "a.called.igv.seg"
      },
      "log": {
        "default": "logs/gatk/call_copy_ratio_segments.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/callcopyratiosegments"
      },
      "input_types": [
        {
          "copy_ratio_seg": "cr.seq file from ModelSegments"
        }
      ],
      "output_types": [
        {
          "copy_ratio_seg": "called copy ratio segments file"
        },
        {
          "igv_seg": "CBS formatted igv.seg file, optional"
        }
      ],
      "rule": "rule call_copy_ratio_segments:\n    input:\n        copy_ratio_seg=\"a.cr.seg\",\n    output:\n        called_copy_ratio_seg=\"a.called.seg\",\n        igv_seg=\"a.called.igv.seg\",\n    log:\n        \"logs/gatk/call_copy_ratio_segments.log\",\n    params:\n        #prefix=\"a.den.test\",\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/callcopyratiosegments\"\n"
    },
    {
      "name": "callpeak",
      "input": {
        "treatment": "samples/a.bam",
        "control": "samples/b.bam"
      },
      "output": {
        "default": "multiext('callpeak/basename', '_peaks.xls', '_peaks.narrowPeak', '_summits.bed')"
      },
      "log": {
        "default": "logs/macs2/callpeak.log"
      },
      "params": {
        "default": "-f BAM -g hs --nomodel"
      },
      "wrapper": {
        "default": "master/bio/macs2/callpeak"
      },
      "input_types": [
        "SAM, BAM, BED, ELAND, ELANDMULTI, ELANDEXPORT, BOWTIE, BAMPE or BEDPE files"
      ],
      "output_types": [
        "tabular file in excel format (.xls) AND",
        "different optional metrics in bedGraph or BED formats"
      ],
      "rule": "rule callpeak:\n    input:\n        treatment=\"samples/a.bam\",   # required: treatment sample(s)\n        control=\"samples/b.bam\"      # optional: control sample(s)\n    output:\n        # all output-files must share the same basename and only differ by it's extension\n        # Usable extensions (and which tools they implicitly call) are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/macs2/callpeak.html.\n        multiext(\"callpeak/basename\",\n                 \"_peaks.xls\",   ### required\n                 ### optional output files\n                 \"_peaks.narrowPeak\",\n                 \"_summits.bed\"\n                 )\n    log:\n        \"logs/macs2/callpeak.log\"\n    params:\n        \"-f BAM -g hs --nomodel\"\n    wrapper:\n        \"master/bio/macs2/callpeak\"\n\nrule callpeak_options:\n    input:\n        treatment=\"samples/a.bam\",   # required: treatment sample(s)\n        control=\"samples/b.bam\"      # optional: control sample(s)\n    output:\n        # all output-files must share the same basename and only differ by it's extension\n        # Usable extensions (and which tools they implicitly call) are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/macs2/callpeak.html.\n        multiext(\"callpeak_options/basename\",\n                 \"_peaks.xls\",   ### required\n                 ### optional output files\n                 # these output extensions internally set the --bdg or -B option:\n                 \"_treat_pileup.bdg\",\n                 \"_control_lambda.bdg\",\n                 # these output extensions internally set the --broad option:\n                 \"_peaks.broadPeak\",\n                 \"_peaks.gappedPeak\"\n                 )\n    log:\n        \"logs/macs2/callpeak.log\"\n    params:\n        \"-f BAM -g hs --broad-cutoff 0.1 --nomodel\"\n    wrapper:\n        \"master/bio/macs2/callpeak\"\n"
    },
    {
      "name": "chm_eval_kit",
      "input": {},
      "output": {
        "default": "directory('resources/chm-eval-kit')"
      },
      "log": {
        "default": "logs/chm-eval-kit.log"
      },
      "params": {
        "tag": "v0.5",
        "version": "20180222"
      },
      "wrapper": {
        "default": "master/bio/benchmark/chm-eval-kit"
      },
      "input_types": [
        {
          "kit": "Path to annotation directory"
        },
        {
          "vcf": "Path to VCF to evaluate (can be gzipped)"
        }
      ],
      "output_types": [
        {
          "summary": "Path to statistics and evaluations"
        },
        {
          "bed": "Path to list of errors (BED formatted)"
        }
      ],
      "rule": "rule chm_eval_kit:  # [hide]\n    output:  # [hide]\n        directory(\"resources/chm-eval-kit\"),  # [hide]\n    params:  # [hide]\n        tag=\"v0.5\",  # [hide]\n        version=\"20180222\",  # [hide]\n    log:  # [hide]\n        \"logs/chm-eval-kit.log\",  # [hide]\n    cache: \"omit-software\"  # [hide]\n    wrapper:  # [hide]\n        \"master/bio/benchmark/chm-eval-kit\"  # [hide]\n        # [hide]\n\n\nrule chm_eval:\n    input:\n        kit=\"resources/chm-eval-kit\",\n        vcf=\"{sample}.vcf\",\n    output:\n        summary=\"chm-eval/{sample}.summary\",  # summary statistics\n        bed=\"chm-eval/{sample}.err.bed.gz\",  # bed file with errors\n    params:\n        extra=\"\",\n        build=\"38\",\n    log:\n        \"logs/chm-eval/{sample}.log\",\n    wrapper:\n        \"master/bio/benchmark/chm-eval\"\n"
    },
    {
      "name": "chm_eval_sample",
      "input": {},
      "output": {
        "bam": "resources/chm-eval-sample.bam",
        "bai": "resources/chm-eval-sample.bam.bai"
      },
      "log": {
        "default": "logs/chm-eval-sample.log"
      },
      "params": {
        "first_n": 100
      },
      "wrapper": {
        "default": "master/bio/benchmark/chm-eval-sample"
      },
      "input_types": "undefined",
      "output_types": [
        {
          "bam": "Path to CHM-eval sample (BAM formatted)"
        },
        {
          "bai": "Path to the corresponding BAM index"
        }
      ],
      "rule": "rule chm_eval_sample:\n    output:\n        bam=\"resources/chm-eval-sample.bam\",\n        bai=\"resources/chm-eval-sample.bam.bai\"\n    params:\n        # Optionally only grab the first 100 records.\n        # This is for testing, remove next line to grab all records.\n        first_n=100\n    log:\n        \"logs/chm-eval-sample.log\"\n    wrapper:\n        \"master/bio/benchmark/chm-eval-sample\"\n"
    },
    {
      "name": "clustalo",
      "input": {
        "default": "{sample}.fa"
      },
      "output": {
        "default": "{sample}.msa.fa"
      },
      "log": {
        "default": "logs/clustalo/test/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/clustalo"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule clustalo:\n    input:\n        \"{sample}.fa\"\n    output:\n        \"{sample}.msa.fa\"\n    params:\n        extra=\"\"\n    log:\n        \"logs/clustalo/test/{sample}.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/clustalo\"\n"
    },
    {
      "name": "cmscan_profile",
      "input": {
        "fasta": "test-transcript.fa",
        "profile": "test-covariance-model.cm.i1i"
      },
      "output": {
        "tblout": "tr-infernal-tblout.txt"
      },
      "log": {
        "default": "logs/cmscan.log"
      },
      "params": {
        "evalue_threshold": 10,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/infernal/cmscan"
      },
      "input_types": [
        "sequence file",
        "RNA covariance models (CMs)"
      ],
      "output_types": [
        "rna alignments"
      ],
      "rule": "rule cmscan_profile:\n    input:\n        fasta=\"test-transcript.fa\",\n        profile=\"test-covariance-model.cm.i1i\"\n    output:\n        tblout=\"tr-infernal-tblout.txt\",\n    log:\n        \"logs/cmscan.log\"\n    params:\n        evalue_threshold=10, # In the per-target output, report target sequences with an E-value of <= <x>. default=10.0 (on average, ~10 false positives reported per query)\n        extra= \"\",\n        #score_threshold=50, # Instead of thresholding per-CM output on E-value, report target sequences with a bit score of >= <x>. \n    threads: 4\n    wrapper:\n        \"master/bio/infernal/cmscan\"\n"
    },
    {
      "name": "cnvkit_antitarget",
      "input": {
        "bed": "test.bed"
      },
      "output": {
        "bed": "test.antitarget.bed"
      },
      "log": {
        "default": "logs/test.target.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cnvkit/antitarget"
      },
      "input_types": [
        {
          "bed": "bed file"
        },
        {
          "accessible": "sequence-accessible coordinates in chromosomes from the given reference genome"
        }
      ],
      "output_types": [
        {
          "bed": "bed file"
        }
      ],
      "rule": "rule cnvkit_antitarget:\n    input:\n        bed=\"test.bed\",\n    output:\n        bed=\"test.antitarget.bed\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/antitarget\"\n"
    },
    {
      "name": "cnvkit_batch_build_reference",
      "input": {
        "bam": [
          "mapped/a.bam"
        ],
        "bai": [
          "mapped/a.bam.bai"
        ],
        "fasta": "ref/ref.fa",
        "antitarget": "ref/a.antitarget.bed",
        "target": "ref/a.target.bed"
      },
      "output": {
        "reference": "cnvkit/reference.cnn"
      },
      "log": {
        "default": "cnvkit/a.reference.cnn.log"
      },
      "params": {
        "method": "hybrid",
        "extra": "--target-avg-size 10"
      },
      "wrapper": {
        "default": "master/bio/cnvkit/batch"
      },
      "input_types": [
        {
          "bam": "one or more bam files"
        },
        {
          "reference": "copy reference file, when calling samples"
        },
        {
          "fasta": "reference gneome, when building new reference"
        },
        {
          "antitarget": "bed antitarget file, when building new reference"
        },
        {
          "target": "bed target file, when building new reference"
        },
        {
          "mappability": "mappability file, when building new reference"
        }
      ],
      "output_types": [
        "a set of cnvkit generated files, multiple types of cns, cnr and cnn files\n",
        "or a new reference file"
      ],
      "rule": "rule cnvkit_batch_build_reference:\n    input:\n        bam=[\"mapped/a.bam\"],\n        bai=[\"mapped/a.bam.bai\"],\n        fasta=\"ref/ref.fa\",\n        antitarget=\"ref/a.antitarget.bed\",\n        target=\"ref/a.target.bed\",\n    output:\n        reference=\"cnvkit/reference.cnn\",\n    log:\n        \"cnvkit/a.reference.cnn.log\",\n    params:\n        method='hybrid',  # optional\n        extra=\"--target-avg-size 10\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/cnvkit/batch\"\n\nrule cnvkit_batch:\n    input:\n        bam=[\"mapped/a.bam\"],\n        bai=[\"mapped/a.bam.bai\"],\n        reference=\"ref/reference.cnn\",\n    output:\n        antitarget_coverage=\"cnvkit/a.antitargetcoverage.cnn\",\n        bins=\"cnvkit/a.bintest.cns\",\n        regions=\"cnvkit/a.cnr\",\n        segments=\"cnvkit/a.cns\",\n        segments_called=\"cnvkit/a.call.cns\",\n        target_coverage=\"cnvkit/a.targetcoverage.cnn\",\n    log:\n        \"cnvkit/a.antitargetcoverage.cnn.log\",\n    params:\n        method='hybrid',  # optional\n        extra=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/cnvkit/batch\"\n"
    },
    {
      "name": "cnvkit_call",
      "input": {
        "segment": "test.cns",
        "vcf": "test.vcf"
      },
      "output": {
        "segment": "test.call.cns"
      },
      "log": {
        "default": "logs/test.call.cns.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cnvkit/call"
      },
      "input_types": [
        {
          "segments": "Copy ratios (.cnr or .cns)"
        },
        {
          "vcf": "VCF file name containing variants for calculation of b-allele frequencies"
        }
      ],
      "output_types": [
        {
          "segments": "Output table file name (CNR-like table of segments, .cns)"
        }
      ],
      "rule": "rule cnvkit_call:\n    input:\n        segment=\"test.cns\",\n        vcf=\"test.vcf\",\n    output:\n        segment=\"test.call.cns\",\n    log:\n        \"logs/test.call.cns.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/call\"\n"
    },
    {
      "name": "cnvkit_diagram_cns",
      "input": {
        "default": "test.cns"
      },
      "output": {
        "default": "test.cns.pdf"
      },
      "log": {
        "default": "logs/test.cns.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cnvkit/diagram"
      },
      "input_types": [
        "cns file (optional, if cnr is provided)",
        "cnr/cnn file (optional, if cns is provided)"
      ],
      "output_types": [
        "pdf report"
      ],
      "rule": "rule cnvkit_diagram_cns:\n    input:\n        \"test.cns\",\n    output:\n        \"test.cns.pdf\",\n    log:\n        \"logs/test.cns.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/diagram\"\n\nrule cnvkit_diagram_cnr:\n    input:\n        \"test.cnr\",\n    output:\n        \"test.cnr.pdf\",\n    log:\n        \"logs/test.cnr.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/diagram\"\n\nrule cnvkit_diagram_cnn:\n    input:\n        \"test.cnn\",\n    output:\n        \"test.cnn.pdf\",\n    log:\n        \"logs/test.cnn.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/diagram\"\n\nrule cnvkit_diagram_cnscnr:\n    input:\n        [\"test.cns\", \"test.cnr\"]\n    output:\n        \"test.cnscnr.pdf\",\n    log:\n        \"logs/test.cnscnr.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/diagram\""
    },
    {
      "name": "cnvkit_export_seg",
      "input": {
        "default": [
          "test1.cns",
          "test2.cns"
        ]
      },
      "output": {
        "default": "test.cns.seg"
      },
      "log": {
        "default": "logs/test.target.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cnvkit/export"
      },
      "input_types": [
        {
          "cns": "cns or cnr file(s)"
        }
      ],
      "output_types": [
        "bed/vcf/vcf.gz/cdt/seq file"
      ],
      "rule": "rule cnvkit_export_seg:\n    input:\n        [\"test1.cns\",\"test2.cns\"],\n    output:\n        \"test.cns.seg\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/export\"\n\nrule cnvkit_export_vcf:\n    input:\n        \"test1.cns\",\n    output:\n        \"test.cns.vcf\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"-y -x female\" # optional\n    wrapper:\n        \"master/bio/cnvkit/export\"\n\nrule cnvkit_export_vcf_gz:\n    input:\n        \"test1.cns\",\n    output:\n        \"test.cns.vcf.gz\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"-y -x female\" # optional\n    wrapper:\n        \"master/bio/cnvkit/export\"\n\nrule cnvkit_export_cdt:\n    input:\n        [\"test1.cnr\", \"test2.cnr\"]\n    output:\n        \"test.cns.cdt\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/export\"\n\nrule cnvkit_export_jtv:\n    input:\n        [\"test1.cnr\", \"test2.cnr\"]\n    output:\n        \"test.cns.jtv\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"\" # optional\n    wrapper:\n        \"master/bio/cnvkit/export\"\n\nrule cnvkit_export_bed:\n    input:\n        bed=\"test1.cns\",\n    output:\n        \"test.cns.bed\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"--show all -y\" # optional\n    wrapper:\n        \"master/bio/cnvkit/export\""
    },
    {
      "name": "cnvkit_targetl",
      "input": {
        "bed": "test.bed",
        "annotate": "refflat-mini.txt"
      },
      "output": {
        "bed": "test.target.bed"
      },
      "log": {
        "default": "logs/test.target.log"
      },
      "params": {
        "extra": "--split"
      },
      "wrapper": {
        "default": "master/bio/cnvkit/target"
      },
      "input_types": [
        {
          "bed": "bed file"
        },
        {
          "annotate": "gene annotation databases, e.g. RefSeq or Ensembl, as a \u201cflat\u201d format (can be found at UCSC) (optional)"
        }
      ],
      "output_types": [
        {
          "bed": "bed file"
        }
      ],
      "rule": "rule cnvkit_targetl:\n    input:\n        bed=\"test.bed\",\n        annotate=\"refflat-mini.txt\",\n    output:\n        bed=\"test.target.bed\",\n    log:\n        \"logs/test.target.log\",\n    params:\n        extra = \"--split\" # optional\n    wrapper:\n        \"master/bio/cnvkit/target\"\n"
    },
    {
      "name": "collapse_taxonomy",
      "input": {
        "default": "full_length_rel-abundance.tsv"
      },
      "output": {
        "default": "full_length_rel-abundance_collapsed.tsv"
      },
      "log": {
        "default": "logs/emu/full_length_collapsed.log"
      },
      "params": {
        "rank": "genus"
      },
      "wrapper": {
        "default": "master/bio/emu/collapse-taxonomy"
      },
      "input_types": [
        "A TSV output file generated with emu."
      ],
      "output_types": [
        "A TSV output file collapsed at the desired taxonomic rank."
      ],
      "rule": "rule collapse_taxonomy:\n    input:\n        \"full_length_rel-abundance.tsv\",\n    output:\n        \"full_length_rel-abundance_collapsed.tsv\",\n    log:\n        \"logs/emu/full_length_collapsed.log\",\n    params:\n        rank=\"genus\",\n    wrapper:\n        \"master/bio/emu/collapse-taxonomy\"\n"
    },
    {
      "name": "collect_multiple_metrics",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta"
      },
      "output": {
        "default": "multiext('stats/{sample}', '.alignment_summary_metrics', '.insert_size_metrics', '.insert_size_histogram.pdf', '.quality_distribution_metrics', '.quality_distribution.pdf', '.quality_by_cycle_metrics', '.quality_by_cycle.pdf', '.base_distribution_by_cycle_metrics', '.base_distribution_by_cycle.pdf', '.gc_bias.detail_metrics', '.gc_bias.summary_metrics', '.gc_bias.pdf', '.rna_metrics', '.bait_bias_detail_metrics', '.bait_bias_summary_metrics', '.error_summary_metrics', '.pre_adapter_detail_metrics', '.pre_adapter_summary_metrics', '.quality_yield_metrics')"
      },
      "log": {
        "default": "logs/picard/multiple_metrics/{sample}.log"
      },
      "params": {
        "extra": "--VALIDATION_STRINGENCY LENIENT --METRIC_ACCUMULATION_LEVEL null --METRIC_ACCUMULATION_LEVEL SAMPLE --REF_FLAT ref_flat.txt"
      },
      "wrapper": {
        "default": "master/bio/picard/collectmultiplemetrics"
      },
      "input_types": [
        "BAM file (.bam)",
        "FASTA reference sequence file (.fasta or .fa)"
      ],
      "output_types": [
        "multiple metrics text files (_metrics) AND",
        "multiple metrics pdf files (.pdf)",
        "the appropriate extensions for the output files must be used depending on the desired tools"
      ],
      "rule": "rule collect_multiple_metrics:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n    output:\n        # Through the output file extensions the different tools for the metrics can be selected\n        # so that it is not necessary to specify them under params with the \"PROGRAM\" option.\n        # Usable extensions (and which tools they implicitly call) are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/picard/collectmultiplemetrics.html.\n        multiext(\n            \"stats/{sample}\",\n            \".alignment_summary_metrics\",\n            \".insert_size_metrics\",\n            \".insert_size_histogram.pdf\",\n            \".quality_distribution_metrics\",\n            \".quality_distribution.pdf\",\n            \".quality_by_cycle_metrics\",\n            \".quality_by_cycle.pdf\",\n            \".base_distribution_by_cycle_metrics\",\n            \".base_distribution_by_cycle.pdf\",\n            \".gc_bias.detail_metrics\",\n            \".gc_bias.summary_metrics\",\n            \".gc_bias.pdf\",\n            \".rna_metrics\",\n            \".bait_bias_detail_metrics\",\n            \".bait_bias_summary_metrics\",\n            \".error_summary_metrics\",\n            \".pre_adapter_detail_metrics\",\n            \".pre_adapter_summary_metrics\",\n            \".quality_yield_metrics\",\n        ),\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=4096,\n    log:\n        \"logs/picard/multiple_metrics/{sample}.log\",\n    params:\n        # optional parameters\n        # REF_FLAT is required if RnaSeqMetrics are used\n        extra=\"--VALIDATION_STRINGENCY LENIENT --METRIC_ACCUMULATION_LEVEL null --METRIC_ACCUMULATION_LEVEL SAMPLE --REF_FLAT ref_flat.txt\",\n    wrapper:\n        \"master/bio/picard/collectmultiplemetrics\"\n"
    },
    {
      "name": "collectalleliccounts",
      "input": {
        "bam": [
          "mapped/a.bam"
        ],
        "intervals": [
          "a.interval_list"
        ],
        "ref": "ref/genome.fasta"
      },
      "output": {
        "counts": "a.counts.tsv"
      },
      "log": {
        "default": "logs/gatk/collectalleliccounts.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/collectalleliccounts"
      },
      "input_types": [
        {
          "bam": "BAM/SAM/CRAM file containing reads"
        },
        {
          "intervals": "one or more genomic intervals over which to operate"
        },
        {
          "ref": "reference FASTA file"
        }
      ],
      "output_types": [
        {
          "counts": "tab-separated values (TSV) file with allelic counts and a SAM-style header"
        }
      ],
      "rule": "rule collectalleliccounts:\n    input:\n        bam=[\"mapped/a.bam\"],\n        intervals=[\"a.interval_list\"],\n        ref=\"ref/genome.fasta\"\n    output:\n        counts=\"a.counts.tsv\",\n    log:\n        \"logs/gatk/collectalleliccounts.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/collectalleliccounts\"\n"
    },
    {
      "name": "collectreadcounts",
      "input": {
        "bam": [
          "mapped/a.bam"
        ],
        "intervals": [
          "a.interval_list"
        ]
      },
      "output": {
        "counts": "a.counts.hdf5"
      },
      "log": {
        "default": "logs/gatk/collectreadcounts.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/collectreadcounts"
      },
      "input_types": [
        {
          "bam": "BAM/SAM/CRAM file containing reads"
        },
        {
          "intervals": "one or more genomic intervals over which to operate"
        }
      ],
      "output_types": [
        {
          "counts": "output file for read counts, `tsv` or `hdf5`"
        }
      ],
      "rule": "rule collectreadcounts:\n    input:\n        bam=[\"mapped/a.bam\"],\n        intervals=[\"a.interval_list\"],\n    output:\n        counts=\"a.counts.hdf5\",\n    log:\n        \"logs/gatk/collectreadcounts.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/collectreadcounts\"\n"
    },
    {
      "name": "combine_outputs",
      "input": {
        "default": "expand('{sample}_rel-abundance.tsv', sample=['sample1', 'sample2'])"
      },
      "output": {
        "abundances": "ensure('combined_abundances.tsv', non_empty=True)"
      },
      "log": {
        "default": "logs/emu/combined_abundances.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/emu/combine-outputs"
      },
      "input_types": [
        "A list of TSV files obtained with emu abundance."
      ],
      "output_types": [
        {
          "abundances": "TSV file containing the abundance of different taxa."
        },
        {
          "taxonomy": "TSV file containing the taxonomy (optional; otherwise, taxonomy will be included in the abundance table)."
        }
      ],
      "rule": "rule combine_outputs:\n    input:\n        expand(\"{sample}_rel-abundance.tsv\", sample=[\"sample1\", \"sample2\"]),\n    output:\n        abundances=ensure(\"combined_abundances.tsv\", non_empty=True),\n    log:\n        \"logs/emu/combined_abundances.log\",\n    wrapper:\n        \"master/bio/emu/combine-outputs\"\n\n\nrule combine_outputs_split:\n    input:\n        expand(\"{sample}.txt\", sample=[\"sample1\", \"sample2\"]),\n    output:\n        abundances = ensure(\"counts.tsv\", non_empty=True),\n        taxonomy = ensure(\"taxonomy.tsv\", non_empty=True),\n    log:\n        \"logs/emu/combined_split.log\",\n    params:\n        rank=\"genus\",\n        extra=\"--counts\",\n    wrapper:\n        \"master/bio/emu/combine-outputs\"\n"
    },
    {
      "name": "compute_matrix",
      "input": {
        "bed": "expand('{sample}.bed', sample=['a', 'b'])",
        "bigwig": "expand('{sample}.bw', sample=['a', 'b'])"
      },
      "output": {
        "matrix_gz": "matrix_files/matrix.gz",
        "matrix_tab": "matrix_files/matrix.tab",
        "matrix_bed": "matrix_files/matrix.bed"
      },
      "log": {
        "default": "logs/deeptools/compute_matrix.log"
      },
      "params": {
        "command": "scale-regions",
        "extra": "--regionBodyLength 200 --verbose"
      },
      "wrapper": {
        "default": "master/bio/deeptools/computematrix"
      },
      "input_types": [
        {
          "bed": "Path to BED or GTF files (.bed or .gtf) AND"
        },
        {
          "bigwig": "Path to bigWig files (.bw)"
        }
      ],
      "output_types": [
        {
          "matrix_gz": "gzipped matrix file (.gz) AND/OR"
        },
        {
          "matrix_tab": "tab-separated table of matrix file (.tab) AND/OR"
        },
        {
          "matrix_bed": "BED matrix file with sorted regions after skiping zeros or min/max threshold values (.bed)"
        }
      ],
      "rule": "rule compute_matrix:\n    input:\n        # Please note that the -R and -S options are defined via input files\n        bed=expand(\"{sample}.bed\", sample=[\"a\", \"b\"]),\n        bigwig=expand(\"{sample}.bw\", sample=[\"a\", \"b\"]),\n        # Optional blacklist file\n        # blacklist=\"\",\n    output:\n        # Please note that --outFileName, --outFileNameMatrix and --outFileSortedRegions are exclusively defined via output files.\n        # Usable output variables, their extensions and which option they implicitly call are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/deeptools/computematrix.html.\n        matrix_gz=\"matrix_files/matrix.gz\",  # required\n        # optional output files\n        matrix_tab=\"matrix_files/matrix.tab\",\n        matrix_bed=\"matrix_files/matrix.bed\",\n    log:\n        \"logs/deeptools/compute_matrix.log\",\n    params:\n        # required argument, choose \"scale-regions\" or \"reference-point\"\n        command=\"scale-regions\",\n        # optional parameters\n        extra=\"--regionBodyLength 200 --verbose\",\n    wrapper:\n        \"master/bio/deeptools/computematrix\"\n"
    },
    {
      "name": "construct",
      "input": {
        "ref": "c.fa",
        "vcfgz": "c.vcf.gz"
      },
      "output": {
        "vg": "graph/c.vg"
      },
      "log": {
        "default": "logs/vg/construct/c.log"
      },
      "params": {
        "default": "--node-max 10"
      },
      "wrapper": {
        "default": "master/bio/vg/construct"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule construct:\n    input:\n        ref=\"c.fa\",\n        vcfgz=\"c.vcf.gz\"\n    output:\n        vg=\"graph/c.vg\"\n    params:\n        \"--node-max 10\"\n    log:\n        \"logs/vg/construct/c.log\"\n    threads:\n        4\n    wrapper:\n        \"master/bio/vg/construct\"\n"
    },
    {
      "name": "coolpuppy",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "features": "CN.mm9.toy_features.bed",
        "expected": "CN.mm9.toy_expected.tsv",
        "view": "CN.mm9.toy_regions.bed"
      },
      "output": {
        "default": "CN_{resolution,[0-9]+}.clpy"
      },
      "log": {
        "default": "logs/CN_{resolution}_coolpuppy.log"
      },
      "params": {
        "features_format": "bed",
        "extra": "--local"
      },
      "wrapper": {
        "default": "master/bio/coolpuppy"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "a file with features to pileup",
        "(optional) file with expected",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "A file (.clpy, HDF5-based format) with the pileup. Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule coolpuppy:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        features=\"CN.mm9.toy_features.bed\",  ## Feature file\n        expected=\"CN.mm9.toy_expected.tsv\",  ## Expected file\n        view=\"CN.mm9.toy_regions.bed\",  ## File with the region names and coordinates\n    output:\n        \"CN_{resolution,[0-9]+}.clpy\",\n    params:\n        ## Add optional parameters\n        features_format=\"bed\",  ## Format of the features file\n        extra=\"--local\",  ## Add extra parameters\n    threads: 2\n    log:\n        \"logs/CN_{resolution}_coolpuppy.log\",\n    wrapper:\n        \"master/bio/coolpuppy\"\n"
    },
    {
      "name": "cooltools_dots",
      "input": {
        "cooler": "small_test.mcool",
        "expected": "test_expected.tsv",
        "view": "test_view.txt"
      },
      "output": {
        "default": "HFF_{resolution,[0-9]+}.dots.bedpe"
      },
      "log": {
        "default": "logs/HFF_{resolution}_dots.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/dots"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "an expected file",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "A .bedpe file with coordinates of detected dots. Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "\nrule cooltools_dots:\n    input:\n        cooler=\"small_test.mcool\",  ## Multiresolution cooler file\n        expected=\"test_expected.tsv\",  ## Expected file\n        view=\"test_view.txt\",  ## File with the region names and coordinates\n    output:\n        \"HFF_{resolution,[0-9]+}.dots.bedpe\",\n    params:\n        extra=\"\",  ## Add extra parameters\n    threads: 4\n    log:\n        \"logs/HFF_{resolution}_dots.log\",\n    wrapper:\n        \"master/bio/cooltools/dots\"\n"
    },
    {
      "name": "cooltools_eigs_cis",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "view": "mm9_view.txt",
        "track": "mm9_1000000_gc.bed"
      },
      "output": {
        "vecs": "CN_{resolution,[0-9]+}.cis.vecs.tsv",
        "lam": "CN_{resolution,[0-9]+}.cis.lam.tsv",
        "bigwig": "CN_{resolution,[0-9]+}.cis.bw"
      },
      "log": {
        "default": "logs/CN_{resolution}_cis_eigs.log"
      },
      "params": {
        "track_col_name": "GC",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/eigs_cis"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "(optional) phasing track file",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": {
        "vecs": "A .tsv file with values of cis eigenvectors at each bin.",
        "lams": "A file with eigenvalues",
        "bigwig": "A .bigwig file for visualization of the first eigenvector"
      },
      "rule": "rule cooltools_eigs_cis:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        view=\"mm9_view.txt\",  ## File with the region names and coordinates\n        track=\"mm9_1000000_gc.bed\",\n    output:\n        vecs=\"CN_{resolution,[0-9]+}.cis.vecs.tsv\",\n        lam=\"CN_{resolution,[0-9]+}.cis.lam.tsv\",\n        bigwig=\"CN_{resolution,[0-9]+}.cis.bw\",\n    params:\n        ## Add optional parameters\n        track_col_name=\"GC\",\n        extra=\"\",\n    log:\n        \"logs/CN_{resolution}_cis_eigs.log\",\n    wrapper:\n        \"master/bio/cooltools/eigs_cis\"\n"
    },
    {
      "name": "cooltools_eigs_trans",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "track": "mm9_1000000_gc.bed"
      },
      "output": {
        "vecs": "CN_{resolution,[0-9]+}.trans.vecs.tsv",
        "lam": "CN_{resolution,[0-9]+}.trans.lam.tsv",
        "bigwig": "CN_{resolution,[0-9]+}.trans.bw"
      },
      "log": {
        "default": "logs/CN_{resolution}_trans_eigs.log"
      },
      "params": {
        "track_col_name": "GC",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/eigs_trans"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "(optional) phasing track file"
      ],
      "output_types": {
        "vecs": "A .tsv file with values of trans eigenvectors at each bin.",
        "lams": "A file with eigenvalues",
        "bigwig": "A .bigwig file for visualization of the first eigenvector"
      },
      "rule": "rule cooltools_eigs_trans:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        track=\"mm9_1000000_gc.bed\",\n    output:\n        vecs=\"CN_{resolution,[0-9]+}.trans.vecs.tsv\",\n        lam=\"CN_{resolution,[0-9]+}.trans.lam.tsv\",\n        bigwig=\"CN_{resolution,[0-9]+}.trans.bw\",\n    params:\n        ## Add optional parameters\n        track_col_name=\"GC\",\n        extra=\"\",\n    log:\n        \"logs/CN_{resolution}_trans_eigs.log\",\n    wrapper:\n        \"master/bio/cooltools/eigs_trans\"\n"
    },
    {
      "name": "cooltools_expected_cis",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "view": "mm9_view.txt"
      },
      "output": {
        "default": "CN_{resolution,[0-9]+}.cis.expected.tsv"
      },
      "log": {
        "default": "logs/CN_{resolution}_cis_expected.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/expected_cis"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "A .tsv file with mean interaction frequency at each diagonal. Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule cooltools_expected_cis:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        view=\"mm9_view.txt\",  ## File with the region names and coordinates\n    output:\n        \"CN_{resolution,[0-9]+}.cis.expected.tsv\",\n    params:\n        ## Add optional parameters \n        extra=\"\",  ## File with the chromosome names and lengths\n    threads: 4\n    log:\n        \"logs/CN_{resolution}_cis_expected.log\",\n    wrapper:\n        \"master/bio/cooltools/expected_cis\"\n"
    },
    {
      "name": "cooltools_expected_trans",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "view": "mm9_view.txt"
      },
      "output": {
        "default": "{sample}_{resolution,[0-9]+}.trans.expected.tsv"
      },
      "log": {
        "default": "logs/{sample}_{resolution}_trans_expected.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/expected_trans"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "A .tsv file with mean interaction frequency between chromosomes. Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule cooltools_expected_trans:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        view=\"mm9_view.txt\",  ## File with the region names and coordinates\n    output:\n        \"{sample}_{resolution,[0-9]+}.trans.expected.tsv\",\n    params:\n        ## Add optional parameters\n        extra=\"\",\n    threads: 4\n    log:\n        \"logs/{sample}_{resolution}_trans_expected.log\",\n    wrapper:\n        \"master/bio/cooltools/expected_trans\"\n"
    },
    {
      "name": "cooltools_genome_binnify",
      "input": {
        "chromsizes": "hg38_chromsizes.txt"
      },
      "output": {
        "default": "hg38_1000000_bins.bed"
      },
      "log": {
        "default": "logs/binnify.log"
      },
      "params": {
        "binsize": 1000000
      },
      "wrapper": {
        "default": "master/bio/cooltools/genome/binnify"
      },
      "input_types": [
        "a chromsizes file"
      ],
      "output_types": [
        "A .bed file with bin coordinates.  Can have a {binsize} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule cooltools_genome_binnify:\n    input:\n        chromsizes=\"hg38_chromsizes.txt\",  ## Chromsizes file\n    output:\n        \"hg38_1000000_bins.bed\",\n    params:\n        binsize=1000000,\n    threads: 1\n    log:\n        \"logs/binnify.log\",\n    wrapper:\n        \"master/bio/cooltools/genome/binnify\"\n"
    },
    {
      "name": "cooltools_genome_gc",
      "input": {
        "bins": "ASM584v2/bins_100000.bed",
        "fasta": "ASM584v2/ASM584v2.fa"
      },
      "output": {
        "default": "gc_100000.tsv"
      },
      "log": {
        "default": "logs/gc.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/genome/gc"
      },
      "input_types": [
        ".bed file with bin coordinates",
        "fasta file with the genome sequence"
      ],
      "output_types": [
        "A tsv file with GC content in bins\n"
      ],
      "rule": "rule cooltools_genome_gc:\n    input:\n        bins=\"ASM584v2/bins_100000.bed\",  # 100000 bins\n        fasta=\"ASM584v2/ASM584v2.fa\",  # genome fasta for E. coli\n    output:\n        \"gc_100000.tsv\",\n    params:\n        extra=\"\",\n    threads: 1\n    log:\n        \"logs/gc.log\",\n    wrapper:\n        \"master/bio/cooltools/genome/gc\"\n"
    },
    {
      "name": "cooltools_insulation",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "view": "mm9_view.txt"
      },
      "output": {
        "default": "CN_{resolution,[0-9]+}.insulation.tsv"
      },
      "log": {
        "default": "logs/CN_{resolution}_insulation.log"
      },
      "params": {
        "window": [
          10000000,
          12000000
        ],
        "chunksize": 20000000
      },
      "wrapper": {
        "default": "master/bio/cooltools/insulation"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "A .tsv file with insulation score and called boundaries for all window sizes. Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule cooltools_insulation:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        view=\"mm9_view.txt\",  ## File with the region names and coordinates\n    output:\n        \"CN_{resolution,[0-9]+}.insulation.tsv\",\n    params:\n        ## Add optional parameters \n        window=[10000000, 12000000],  ## In this example, we test with two window sizes\n        chunksize=20000000,  ## How many pixels are loaded in memory at once\n    threads: 4  ## Number of threads to use\n    log:\n        \"logs/CN_{resolution}_insulation.log\",\n    wrapper:\n        \"master/bio/cooltools/insulation\"\n"
    },
    {
      "name": "cooltools_pileup",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "features": "CN.mm9.toy_features.bed",
        "expected": "CN.mm9.toy_expected.tsv",
        "view": "CN.mm9.toy_regions.bed"
      },
      "output": {
        "default": "CN_{resolution,[0-9]+}.pileup.npz"
      },
      "log": {
        "default": "logs/CN_{resolution}_pileup.log"
      },
      "params": {
        "features_format": "bed",
        "extra": "--aggregate mean"
      },
      "wrapper": {
        "default": "master/bio/cooltools/pileup"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "a file with features to pileup",
        "(optional) file with expected",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "A file (.npz or .h5) with piled up snippets. Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule cooltools_pileup:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        features=\"CN.mm9.toy_features.bed\",  ## Feature file\n        expected=\"CN.mm9.toy_expected.tsv\",  ## Expected file\n        view=\"CN.mm9.toy_regions.bed\",  ## File with the region names and coordinates\n    output:\n        \"CN_{resolution,[0-9]+}.pileup.npz\",\n    params:\n        ## Add optional parameters \n        features_format=\"bed\",  ## Format of the features file\n        extra=\"--aggregate mean\",  ## Add extra parameters\n    threads: 4\n    log:\n        \"logs/CN_{resolution}_pileup.log\",\n    wrapper:\n        \"master/bio/cooltools/pileup\"\n"
    },
    {
      "name": "cooltools_saddle",
      "input": {
        "cooler": "CN.mm9.1000kb.mcool",
        "track": "CN_1000000.eigs.tsv",
        "expected": "CN_1000000.cis.expected.tsv",
        "view": "mm9_view.txt"
      },
      "output": {
        "saddle": "CN_{resolution,[0-9]+}.saddledump.npz",
        "digitized_track": "CN_{resolution,[0-9]+}.digitized.tsv",
        "fig": "CN_{resolution,[0-9]+}.saddle.pdf"
      },
      "log": {
        "default": "logs/CN_{resolution}_saddle.log"
      },
      "params": {
        "range": "--qrange 0.01 0.99",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cooltools/saddle"
      },
      "input_types": [
        "a multiresolution cooler file (.mcool)",
        "track file",
        "expected file",
        "(optional) view, a bed-style file with region coordinates and names to use for analysis"
      ],
      "output_types": [
        "Saves a binary .npz file with saddles and extra information about it, and a track file with digitized values. Can also save saddle plots using extra --fig argument. All output files have the same prefix, taken from the first output argument (i.e. enough to give one output argument). Can have a {resolution} wildcard that specifies the resolution for the analysis, then it doesn't need to be specified as a parameter.\n"
      ],
      "rule": "rule cooltools_saddle:\n    input:\n        cooler=\"CN.mm9.1000kb.mcool\",  ## Multiresolution cooler file\n        track=\"CN_1000000.eigs.tsv\",  ## Track file\n        expected=\"CN_1000000.cis.expected.tsv\",  ## Expected file\n        view=\"mm9_view.txt\",  ## File with the region names and coordinates\n    output:\n        saddle=\"CN_{resolution,[0-9]+}.saddledump.npz\",\n        digitized_track=\"CN_{resolution,[0-9]+}.digitized.tsv\",\n        fig=\"CN_{resolution,[0-9]+}.saddle.pdf\",\n    params:\n        ## Add optional parameters\n        range=\"--qrange 0.01 0.99\",\n        extra=\"\",\n    log:\n        \"logs/CN_{resolution}_saddle.log\",\n    wrapper:\n        \"master/bio/cooltools/saddle\"\n\n\n# Note that in this test files are edited to remove\n"
    },
    {
      "name": "correction",
      "input": {
        "query": "fasta/{query}.fasta",
        "ref": "fasta/{reference}.fasta"
      },
      "output": {
        "fasta": "{query}_corrected_{reference}/ragtag.correct.fasta",
        "agp": "{query}_corrected_{reference}/ragtag.correct.agp"
      },
      "log": {
        "default": "logs/ragtag/{query}_{reference}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/ragtag/correction"
      },
      "input_types": [
        {
          "ref": "reference fasta file (uncompressed or bgzipped)"
        },
        {
          "query": "query fasta file (uncompressed or bgzipped)"
        }
      ],
      "output_types": [
        {
          "fasta": "The corrected query assembly in FASTA format."
        },
        {
          "agp": "The AGP file defining the exact coordinates of query sequence breaks."
        }
      ],
      "rule": "rule correction:\n    input:\n        query=\"fasta/{query}.fasta\",\n        ref=\"fasta/{reference}.fasta\",\n    output:\n        fasta=\"{query}_corrected_{reference}/ragtag.correct.fasta\",\n        agp=\"{query}_corrected_{reference}/ragtag.correct.agp\",\n    params:\n        extra=\"\",\n    threads: 16\n    log:\n        \"logs/ragtag/{query}_{reference}.log\",\n    wrapper:\n        \"master/bio/ragtag/correction\"\n"
    },
    {
      "name": "coverageBed",
      "input": {
        "a": "bed/{sample}.bed",
        "b": "mapped/{sample}.bam"
      },
      "output": {
        "default": "stats/{sample}.cov"
      },
      "log": {
        "default": "logs/coveragebed/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bedtools/coveragebed"
      },
      "input_types": [
        {
          "a": "Path to the feature file (BAM/BED/GFF/VCF). This file is compared to `b` (see below)"
        },
        {
          "b": "Path or list of paths to file(s) (BAM/BED/GFF/VCF)."
        }
      ],
      "output_types": [
        "Path to the coverage file."
      ],
      "rule": "rule coverageBed:\n    input:\n        a=\"bed/{sample}.bed\",\n        b=\"mapped/{sample}.bam\"\n    output:\n        \"stats/{sample}.cov\"\n    log:\n        \"logs/coveragebed/{sample}.log\"\n    params:\n        extra=\"\"  # optional parameters\n    threads: 8\n    wrapper:\n        \"master/bio/bedtools/coveragebed\"\n"
    },
    {
      "name": "create_dict",
      "input": {
        "default": "genome.fasta"
      },
      "output": {
        "default": "genome.dict"
      },
      "log": {
        "default": "logs/picard/create_dict.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/picard/createsequencedictionary"
      },
      "input_types": [
        "FASTA file"
      ],
      "output_types": [
        ".dict file"
      ],
      "rule": "rule create_dict:\n    input:\n        \"genome.fasta\",\n    output:\n        \"genome.dict\",\n    log:\n        \"logs/picard/create_dict.log\",\n    params:\n        extra=\"\",  # optional: extra arguments for picard.\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/createsequencedictionary\"\n"
    },
    {
      "name": "create_repeat_annotations",
      "input": {},
      "output": {
        "table": "resources/ensembl_repeat_annotations.tsv.gz"
      },
      "log": {
        "default": "logs/create_repeat_annotations.log"
      },
      "params": {
        "species": "homo_sapiens",
        "build": "GRCh37",
        "release": "105",
        "main_tables": {
          "repeat_feature": {
            "database": "core"
          }
        },
        "join_tables": {
          "seq_region": {
            "database": "core",
            "join_column": "seq_region_id"
          },
          "repeat_consensus": {
            "database": "core",
            "join_column": "repeat_consensus_id"
          }
        }
      },
      "wrapper": {
        "default": "master/bio/reference/ensembl-mysql-table"
      },
      "input_types": "undefined",
      "output_types": [
        "tab-separated values (``.tsv``); for supported compression extensions, see `the write_tsv documentation page <https://readr.tidyverse.org/reference/write_delim.html#output>`_\n",
        "parquet (``.parquet``) file; for supported compression algorithms, see `the write_parquet documentation page <https://r-lib.github.io/nanoparquet/reference/write_parquet.html#arguments>`_\n"
      ],
      "rule": "rule create_repeat_annotations:\n    output:\n        table=\"resources/ensembl_repeat_annotations.tsv.gz\",  # .gz extension is optional, but recommended\n    params:\n        species=\"homo_sapiens\",\n        build=\"GRCh37\",\n        release=\"105\",\n        main_tables={\n            \"repeat_feature\": {\n                \"database\": \"core\",\n            },\n        },  # choose the main table to retrieve, specifying { table : database }\n        join_tables={\n            \"seq_region\": {\n                \"database\": \"core\",\n                \"join_column\": \"seq_region_id\",\n            },\n            \"repeat_consensus\": {\n                \"database\": \"core\",\n                \"join_column\": \"repeat_consensus_id\",\n            },\n        },\n        # optional: add tables to join in for further annotations, specifying { table : { \"database\": database, \"join_column\": join-column } }\n    log:\n        \"logs/create_repeat_annotations.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-mysql-table\"\n\n\nrule create_regulatory_annotations_parquet:\n    output:\n        table=\"resources/ensembl_regulatory_annotations.parquet.gz\",  # .gz extension is optional, but recommended\n    params:\n        species=\"mus_musculus\",\n        build=\"GRCm39\",\n        release=\"112\",\n        main_tables={\n            \"regulatory_feature\": {\n                \"database\": \"funcgen\",\n            },\n            \"mirna_target_feature\": {\n                \"database\": \"funcgen\",\n            },\n        },\n        # choose the main table to retrieve, specifying { table : database }\n        join_tables={\n            \"seq_region\": {\n                \"database\": \"core\",\n                \"join_column\": \"seq_region_id\"\n            },\n            \"feature_type\": {\n                \"database\": \"funcgen\",\n                \"join_column\": \"feature_type_id\"\n            },\n        },\n        # optional: add tables to join in for further annotations, specifying { table : { \"database\": database, \"join_column\": join-column } }\n    log:\n        \"logs/create_regulatory_annotations_parquet.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-mysql-table\"\n"
    },
    {
      "name": "create_transcripts_to_genes_mapping",
      "input": {},
      "output": {
        "table": "resources/ensembl_transcripts_to_genes_mapping.tsv.gz"
      },
      "log": {
        "default": "logs/create_transcripts_to_genes_mapping.log"
      },
      "params": {
        "biomart": "genes",
        "species": "homo_sapiens",
        "build": "GRCh38",
        "release": "114",
        "attributes": [
          "ensembl_transcript_id",
          "ensembl_gene_id",
          "external_gene_name",
          "genecards",
          "chromosome_name"
        ],
        "filters": {
          "chromosome_name": [
            "22",
            "X"
          ]
        }
      },
      "wrapper": {
        "default": "master/bio/reference/ensembl-biomart-table"
      },
      "input_types": "undefined",
      "output_types": [
        "tab-separated values (``.tsv``); for supported compression extensions, see `the write_tsv documentation page <https://readr.tidyverse.org/reference/write_delim.html#output>`_\n",
        "parquet (``.parquet``) file; for supported compression algorithms, see `the write_parquet documentation page <https://r-lib.github.io/nanoparquet/reference/write_parquet.html#arguments>`_\n"
      ],
      "rule": "rule create_transcripts_to_genes_mapping:\n    output:\n        table=\"resources/ensembl_transcripts_to_genes_mapping.tsv.gz\",  # .gz extension is optional, but recommended\n    params:\n        biomart=\"genes\",\n        species=\"homo_sapiens\",\n        build=\"GRCh38\",\n        release=\"114\",\n        attributes=[\n            \"ensembl_transcript_id\",\n            \"ensembl_gene_id\",\n            \"external_gene_name\",\n            \"genecards\",\n            \"chromosome_name\",\n        ],\n        filters={ \"chromosome_name\": [\"22\", \"X\"] }, # optional: restrict output by using filters\n    log:\n        \"logs/create_transcripts_to_genes_mapping.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-biomart-table\"\n\n\nrule create_transcripts_to_genes_mapping_parquet:\n    output:\n        table=\"resources/ensembl_transcripts_to_genes_mapping.parquet.gz\",  # .gz extension is optional, but recommended\n    params:\n        biomart=\"genes\",\n        species=\"mus_musculus\",\n        build=\"GRCm39\",\n        release=\"114\",\n        attributes=[\"ensembl_transcript_id\", \"ensembl_gene_id\"],\n        # filters={ \"chromosome_name\": \"19\"}, # optional: restrict output by using filters\n    log:\n        \"logs/create_transcripts_to_genes_mapping_parquet.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-biomart-table\"\n"
    },
    {
      "name": "csv_report",
      "input": {
        "default": "report.csv"
      },
      "output": {
        "default": "directory('qc_data')"
      },
      "log": {
        "default": "logs/rbt-csv-report"
      },
      "params": {
        "extra": "--sort-column 'contig length'"
      },
      "wrapper": {
        "default": "master/bio/rbt/csvreport"
      },
      "input_types": [
        "A csv file containing the qc report"
      ],
      "output_types": [
        "QC report folder including html document and .xlsx file"
      ],
      "rule": "rule csv_report:\n    input:\n        # a csv formatted file containing the data for the report\n        \"report.csv\",\n    output:\n        # path to the resulting report directory\n        directory(\"qc_data\"),\n    params:\n        extra=\"--sort-column 'contig length'\",\n    log:\n        \"logs/rbt-csv-report\",\n    wrapper:\n        \"master/bio/rbt/csvreport\"\n"
    },
    {
      "name": "cutadapt",
      "input": {
        "default": "reads/{sample}.fastq"
      },
      "output": {
        "fastq": "trimmed/{sample}.fastq",
        "qc": "trimmed/{sample}.qc.txt"
      },
      "log": {
        "default": "logs/cutadapt/{sample}.log"
      },
      "params": {
        "adapters": "-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC",
        "extra": "-q 20"
      },
      "wrapper": {
        "default": "master/bio/cutadapt/se"
      },
      "input_types": [
        "fastq file"
      ],
      "output_types": [
        "trimmed fastq file",
        "text file containing trimming statistics"
      ],
      "rule": "rule cutadapt:\n    input:\n        \"reads/{sample}.fastq\",\n    output:\n        fastq=\"trimmed/{sample}.fastq\",\n        qc=\"trimmed/{sample}.qc.txt\",\n    params:\n        adapters=\"-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\",\n        extra=\"-q 20\",\n    log:\n        \"logs/cutadapt/{sample}.log\",\n    threads: 4  # set desired number of threads here\n    wrapper:\n        \"master/bio/cutadapt/se\"\n"
    },
    {
      "name": "dada2_add_species",
      "input": {
        "taxtab": "results/dada2/taxa.RDS",
        "refFasta": "resources/example_species_assignment.fa.gz"
      },
      "output": {
        "default": "results/dada2/taxa-sp.RDS"
      },
      "log": {
        "default": "logs/dada2/add-species/add-species.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/add-species"
      },
      "input_types": [
        {
          "taxa": "RDS file containing the taxonomic assignments"
        },
        {
          "refFasta": "A string with the path to the FASTA reference database"
        }
      ],
      "output_types": [
        "The input RDS file augmented by the species-level annotation"
      ],
      "rule": "rule dada2_add_species:\n    input:\n        taxtab=\"results/dada2/taxa.RDS\", # Taxonomic assignments\n        refFasta=\"resources/example_species_assignment.fa.gz\" # Reference FASTA \n    output:\n        \"results/dada2/taxa-sp.RDS\", # Taxonomic + Species assignments\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    verbose=True\n    log:\n        \"logs/dada2/add-species/add-species.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/add-species\"\n"
    },
    {
      "name": "dada2_assign_species",
      "input": {
        "seqs": "results/dada2/seqTab.nochim.RDS",
        "refFasta": "resources/species.fasta"
      },
      "output": {
        "default": "results/dada2/genus-species-taxa.RDS"
      },
      "log": {
        "default": "logs/dada2/assign-species/assign-species.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/assign-species"
      },
      "input_types": [
        {
          "seqs": "RDS file with the chimera-free sequence table"
        },
        {
          "refFasta": "A string with the path to the genus-species FASTA reference database"
        }
      ],
      "output_types": [
        "RDS file containing the genus and species taxonomic assignments"
      ],
      "rule": "rule dada2_assign_species:\n    input:\n        seqs=\"results/dada2/seqTab.nochim.RDS\", # Chimera-free sequence table\n        refFasta=\"resources/species.fasta\" # Reference FASTA for Genus-Species taxonomy\n    output:\n        \"results/dada2/genus-species-taxa.RDS\" # Genus-Species taxonomic assignments\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    allowMultiple=True\n    log:\n        \"logs/dada2/assign-species/assign-species.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/assign-species\"\n"
    },
    {
      "name": "dada2_assign_taxonomy",
      "input": {
        "seqs": "results/dada2/seqTab.nochim.RDS",
        "refFasta": "resources/example_train_set.fa.gz"
      },
      "output": {
        "default": "results/dada2/taxa.RDS"
      },
      "log": {
        "default": "logs/dada2/assign-taxonomy/assign-taxonomy.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/assign-taxonomy"
      },
      "input_types": [
        {
          "seqs": "RDS file with the chimera-free sequence table"
        },
        {
          "refFasta": "A string with the path to the FASTA reference database"
        }
      ],
      "output_types": [
        "RDS file containing the taxonomic assignments"
      ],
      "rule": "rule dada2_assign_taxonomy:\n    input:\n        seqs=\"results/dada2/seqTab.nochim.RDS\", # Chimera-free sequence table\n        refFasta=\"resources/example_train_set.fa.gz\" # Reference FASTA for taxonomy\n    output:\n        \"results/dada2/taxa.RDS\" # Taxonomic assignments\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    verbose=True\n    log:\n        \"logs/dada2/assign-taxonomy/assign-taxonomy.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/assign-taxonomy\"\n"
    },
    {
      "name": "dada2_collapse_nomismatch",
      "input": {
        "default": "results/dada2/seqTab.nochimeras.RDS"
      },
      "output": {
        "default": "results/dada2/seqTab.collapsed.RDS"
      },
      "log": {
        "default": "logs/dada2/collapse-nomismatch/collapse-nomismatch.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/collapse-nomismatch"
      },
      "input_types": [
        "RDS file with the chimera-free sequence table"
      ],
      "output_types": [
        "RDS file with the sequence table where the needed sequences were collapsed"
      ],
      "rule": "rule dada2_collapse_nomismatch:\n    input:\n        \"results/dada2/seqTab.nochimeras.RDS\" # Chimera-free sequence table\n    output:\n        \"results/dada2/seqTab.collapsed.RDS\"\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    verbose=True\n    log:\n        \"logs/dada2/collapse-nomismatch/collapse-nomismatch.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/collapse-nomismatch\"\n"
    },
    {
      "name": "dada2_dereplicate_fastq",
      "input": {
        "default": "filtered/{fastq}.fastq"
      },
      "output": {
        "default": "uniques/{fastq}.RDS"
      },
      "log": {
        "default": "logs/dada2/dereplicate-fastq/{fastq}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/dereplicate-fastq"
      },
      "input_types": [
        "a FASTQ file"
      ],
      "output_types": [
        "RDS file containing a ``derep-class`` object"
      ],
      "rule": "rule dada2_dereplicate_fastq:\n    input:\n    # Quality filtered FASTQ file\n        \"filtered/{fastq}.fastq\"\n    output:\n    # Dereplicated sequences stored as `derep-class` object in a RDS file \n        \"uniques/{fastq}.RDS\"\n    log:\n        \"logs/dada2/dereplicate-fastq/{fastq}.log\"\n    wrapper:\n        \"master/bio/dada2/dereplicate-fastq\"\n\n"
    },
    {
      "name": "dada2_filter_trim_se",
      "input": {
        "fwd": "trimmed/{sample}.1.fastq.gz"
      },
      "output": {
        "filt": "filtered-se/{sample}.1.fastq.gz",
        "stats": "reports/dada2/filter-trim-se/{sample}.tsv"
      },
      "log": {
        "default": "logs/dada2/filter-trim-se/{sample}.log"
      },
      "params": {
        "maxEE": 1,
        "truncLen": 7,
        "minLen": 1
      },
      "wrapper": {
        "default": "master/bio/dada2/filter-trim"
      },
      "input_types": [
        {
          "fwd": "a forward FASTQ file (potentially compressed) without primer sequences"
        },
        {
          "rev": "an (optional) reverse FASTQ file (potentially compressed) without primer sequences"
        }
      ],
      "output_types": [
        {
          "filt": "a compressed filtered forward FASTQ file"
        },
        {
          "filt_rev": "an (optional) compressed filtered reverse FASTQ file"
        },
        {
          "stats": "a .tsv file with the number of processed and filtered reads per sample"
        }
      ],
      "rule": "rule dada2_filter_trim_se:\n    input:\n        # Single-end files without primers sequences\n        fwd=\"trimmed/{sample}.1.fastq.gz\"\n    output:\n        filt=\"filtered-se/{sample}.1.fastq.gz\",\n        stats=\"reports/dada2/filter-trim-se/{sample}.tsv\"\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    params:\n        # Set the maximum expected errors tolerated in filtered reads\n        maxEE=1,\n        # Set the number of kept bases to 7 for the toy example\n        truncLen=7,\n        # Set minLen to 1 for the toy example but default is 20\n        minLen=1\n    log:\n        \"logs/dada2/filter-trim-se/{sample}.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/filter-trim\"\n\nrule dada2_filter_trim_pe:\n    input:\n        # Paired-end files without primers sequences\n        fwd=\"trimmed/{sample}.1.fastq\",\n        rev=\"trimmed/{sample}.2.fastq\"\n    output:\n        filt=\"filtered-pe/{sample}.1.fastq.gz\",\n        filt_rev=\"filtered-pe/{sample}.2.fastq.gz\",\n        stats=\"reports/dada2/filter-trim-pe/{sample}.tsv\"\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    params:\n        # Set the maximum expected errors tolerated in filtered reads\n        maxEE=1,\n        # Set the number of kept bases in forward and reverse reads\n        # respectively to 7 for the toy example\n        truncLen=[7,6],\n        # Set minLen to 1 for the toy example but default is 20\n        minLen=1\n    log:\n        \"logs/dada2/filter-trim-pe/{sample}.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/filter-trim\"\n"
    },
    {
      "name": "dada2_make_table_se",
      "input": {
        "default": "expand('denoised/{sample}.1.RDS', sample=['a', 'b'])"
      },
      "output": {
        "default": "results/dada2/seqTab-se.RDS"
      },
      "log": {
        "default": "logs/dada2/make-table/make-table-se.log"
      },
      "params": {
        "names": [
          "a",
          "b"
        ]
      },
      "wrapper": {
        "default": "master/bio/dada2/make-table"
      },
      "input_types": [
        "A list of RDS files with denoised samples (se), or denoised and merged samples (pe)"
      ],
      "output_types": [
        "RDS file with the table"
      ],
      "rule": "rule dada2_make_table_se:\n    input:\n    # Inferred composition \n        expand(\"denoised/{sample}.1.RDS\", sample=['a','b']) \n    output:\n        \"results/dada2/seqTab-se.RDS\"\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    params:\n        names=['a','b'] # Sample names instead of paths\n    log:\n        \"logs/dada2/make-table/make-table-se.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/make-table\"\n\nrule dada2_make_table_pe:\n    input:\n    # Merged composition\n        expand(\"merged/{sample}.RDS\", sample=['a','b'])\n    output:\n        \"results/dada2/seqTab-pe.RDS\"\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    params:\n        names=['a','b'], # Sample names instead of paths\n        orderBy=\"nsamples\" # Change the ordering of samples\n    log:\n        \"logs/dada2/make-table/make-table-pe.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/make-table\"\n"
    },
    {
      "name": "dada2_merge_pairs",
      "input": {
        "dadaF": "denoised/{sample}.1.RDS",
        "dadaR": "denoised/{sample}.2.RDS",
        "derepF": "uniques/{sample}.1.RDS",
        "derepR": "uniques/{sample}.2.RDS"
      },
      "output": {
        "default": "merged/{sample}.RDS"
      },
      "log": {
        "default": "logs/dada2/merge-pairs/{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/merge-pairs"
      },
      "input_types": [
        {
          "dadaF": "RDS file with the inferred sample composition from forward reads"
        },
        {
          "dadaR": "reverse"
        },
        {
          "derepF": "RDS file with the dereplicated forward reads"
        },
        {
          "derepR": "reverse"
        }
      ],
      "output_types": [
        "RDS file with the merged pairs"
      ],
      "rule": "rule dada2_merge_pairs:\n    input:\n      dadaF=\"denoised/{sample}.1.RDS\",# Inferred composition\n      dadaR=\"denoised/{sample}.2.RDS\",\n      derepF=\"uniques/{sample}.1.RDS\",# Dereplicated sequences\n      derepR=\"uniques/{sample}.2.RDS\"\n    output:\n        \"merged/{sample}.RDS\"\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    verbose=True\n    log:\n        \"logs/dada2/merge-pairs/{sample}.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/merge-pairs\"\n"
    },
    {
      "name": "dada2_quality_profile_se",
      "input": {
        "default": "trimmed/{sample}.{orientation}.fastq"
      },
      "output": {
        "default": "reports/dada2/quality-profile/{sample}.{orientation}-quality-profile.png"
      },
      "log": {
        "default": "logs/dada2/quality-profile/{sample}.{orientation}-quality-profile-se.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/quality-profile"
      },
      "input_types": [
        "a FASTQ file (potentially compressed) without primers sequences"
      ],
      "output_types": [
        "A PNG file of the quality plot"
      ],
      "rule": "rule dada2_quality_profile_se:\n    input:\n        # FASTQ file without primers sequences\n        \"trimmed/{sample}.{orientation}.fastq\"\n    output:\n        \"reports/dada2/quality-profile/{sample}.{orientation}-quality-profile.png\"\n    log:\n        \"logs/dada2/quality-profile/{sample}.{orientation}-quality-profile-se.log\"\n    wrapper:\n        \"master/bio/dada2/quality-profile\"\n\nrule dada2_quality_profile_pe:\n    input:\n        # FASTQ file without primers sequences\n        expand(\"trimmed/{{sample}}.{orientation}.fastq\",orientation=[1,2])\n    output:\n        \"reports/dada2/quality-profile/{sample}-quality-profile.png\"\n    log:\n        \"logs/dada2/quality-profile/{sample}-quality-profile-pe.log\"\n    wrapper:\n        \"master/bio/dada2/quality-profile\"\n"
    },
    {
      "name": "dada2_remove_chimeras",
      "input": {
        "default": "results/dada2/seqTab.RDS"
      },
      "output": {
        "default": "results/dada2/seqTab.nochim.RDS"
      },
      "log": {
        "default": "logs/dada2/remove-chimeras/remove-chimeras.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/remove-chimeras"
      },
      "input_types": [
        "RDS file with the sequence table"
      ],
      "output_types": [
        "RDS file with the chimera-free sequence table"
      ],
      "rule": "rule dada2_remove_chimeras:\n    input:\n        \"results/dada2/seqTab.RDS\" # Sequence table\n    output:\n        \"results/dada2/seqTab.nochim.RDS\" # Chimera-free sequence table\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    verbose=True\n    log:\n        \"logs/dada2/remove-chimeras/remove-chimeras.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/remove-chimeras\"\n"
    },
    {
      "name": "dada2_sample_inference",
      "input": {
        "derep": "uniques/{fastq}.RDS",
        "err": "results/dada2/model_1.RDS"
      },
      "output": {
        "default": "denoised/{fastq}.RDS"
      },
      "log": {
        "default": "logs/dada2/sample-inference/{fastq}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/dada2/sample-inference"
      },
      "input_types": [
        {
          "derep": "RDS file with the dereplicated sequences"
        },
        {
          "err": "RDS file with the error model"
        }
      ],
      "output_types": [
        "RDS file with the stored inferred sample composition"
      ],
      "rule": "rule dada2_sample_inference:\n    input:\n    # Dereplicated (aka unique) sequences of the sample\n        derep=\"uniques/{fastq}.RDS\",\n        err=\"results/dada2/model_1.RDS\" # Error model\n    output:\n        \"denoised/{fastq}.RDS\" # Inferred sample composition\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    verbose=True\n    log:\n        \"logs/dada2/sample-inference/{fastq}.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/sample-inference\"\n"
    },
    {
      "name": "deduplicate_bismark",
      "input": {
        "default": "bams/{sample}.bam"
      },
      "output": {
        "bam": "bams/{sample}.deduplicated.bam",
        "report": "bams/{sample}.deduplication_report.txt"
      },
      "log": {
        "default": "logs/bams/{sample}.deduplicated.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bismark/deduplicate_bismark"
      },
      "input_types": [
        "path to one or multiple \\*.bam files aligned by Bismark, if multiple passed '--multiple' argument will be added automatically."
      ],
      "output_types": [
        {
          "bam": "Result bam file path. The file will be renamed if differs from `NAME.deduplicated.bam` for given 'NAME.bam' input."
        },
        {
          "report": "Result report path. The file will be renamed if differs from `NAME.deduplication_report.txt` for given 'NAME.bam' input."
        }
      ],
      "rule": "rule deduplicate_bismark:\n    input: \"bams/{sample}.bam\"\n    output:\n        bam=\"bams/{sample}.deduplicated.bam\",\n        report=\"bams/{sample}.deduplication_report.txt\",\n    log:\n        \"logs/bams/{sample}.deduplicated.log\",\n    params:\n        extra=\"\"  # optional params string\n    wrapper:\n        \"master/bio/bismark/deduplicate_bismark\"\n"
    },
    {
      "name": "deeptools_bampe_fragmentsize",
      "input": {
        "bams": [
          "a.bam",
          "b.bam"
        ]
      },
      "output": {
        "hist": "results/histogram.png",
        "raw": "results/raw.tab"
      },
      "log": {
        "default": "logs/deeptools/bampe_fragmentsize.log"
      },
      "params": {
        "labels": "",
        "extra": "--logScale"
      },
      "wrapper": {
        "default": "master/bio/deeptools/bampefragmentsize"
      },
      "input_types": [
        {
          "bams": "List of BAM files (.bam)"
        },
        {
          "blacklist": "Optional BED file with regions to skip (.bed)"
        }
      ],
      "output_types": [
        {
          "hist": "Fragment size histogram (.png)"
        },
        {
          "raw": "Raw fragment lengths (.tab) (optional)"
        }
      ],
      "rule": "rule deeptools_bampe_fragmentsize:\n    input:\n        # Input BAM file(s)\n        bams=[\"a.bam\", \"b.bam\"],\n        # Optional blacklist file in BED format to exclude specific regions from analysis\n        # blacklist=\"\",\n    output:\n        # Please note that -o/hist/--histogram and --outRawFragmentLengths are exclusively defined via output files.\n        # Usable output variables, their extensions and which option they implicitly call are listed here:\n        # https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/deeptools/bamPEFragmentSize.html.\n        # Required\n        hist=\"results/histogram.png\",\n        # Optional output files\n        raw=\"results/raw.tab\",\n    log:\n        \"logs/deeptools/bampe_fragmentsize.log\",\n    threads: 4\n    params:\n        # Labels can be changed to anything\n        # If left empty, the sample name will be used \n        # (without path and .bam extension)\n        # Format: list matching the number of input BAMs\n        # Example: [\"sample1\", \"sample2\"] or \"\" for automatic labels\n        labels=\"\",\n        # Additional parameters for deeptools bamPEFragmentSize\n        # Example: --maxFragmentLength 1000 --binSize 10\n        extra=\"--logScale\",\n    wrapper:\n        \"master/bio/deeptools/bampefragmentsize\"\n"
    },
    {
      "name": "deepvariant",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome/genome.fasta"
      },
      "output": {
        "vcf": "calls/{sample}.vcf.gz"
      },
      "log": {
        "default": "logs/deepvariant/{sample}/stdout.log"
      },
      "params": {
        "model": "wgs",
        "sample_name": "lambda w: w.sample",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/deepvariant"
      },
      "input_types": [
        "fasta",
        "bam"
      ],
      "output_types": [
        "vcf",
        "visual report html"
      ],
      "rule": "rule deepvariant:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome/genome.fasta\"\n    output:\n        vcf=\"calls/{sample}.vcf.gz\"\n    params:\n        model=\"wgs\",   # {wgs, wes, pacbio, hybrid}\n        sample_name=lambda w: w.sample, # optional\n        extra=\"\"\n    threads: 2\n    log:\n        \"logs/deepvariant/{sample}/stdout.log\"\n    wrapper:\n        \"master/bio/deepvariant\"\n\n\nrule deepvariant_gvcf:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome/genome.fasta\"\n    output:\n        vcf=\"gvcf_calls/{sample}.vcf.gz\",\n        gvcf=\"gvcf_calls/{sample}.g.vcf.gz\"\n    params:\n        model=\"wgs\",   # {wgs, wes, pacbio, hybrid}\n        extra=\"\"\n    threads: 2\n    log:\n        \"logs/deepvariant/{sample}/stdout.log\"\n    wrapper:\n        \"master/bio/deepvariant\"\n"
    },
    {
      "name": "delly_bcf",
      "input": {
        "ref": "genome.fasta",
        "alns": [
          "mapped/a.bam"
        ],
        "exclude": "human.hg19.excl.tsv"
      },
      "output": {
        "default": "sv/calls.bcf"
      },
      "log": {
        "default": "logs/delly.log"
      },
      "params": {
        "uncompressed_bcf": true,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/delly"
      },
      "input_types": [
        "BAM/CRAM file(s)",
        "reference genome",
        "BED file (optional)"
      ],
      "output_types": [
        "VCF/BCF with SVs."
      ],
      "rule": "rule delly_bcf:\n    input:\n        ref=\"genome.fasta\",\n        alns=[\"mapped/a.bam\"],\n        # optional\n        exclude=\"human.hg19.excl.tsv\",\n    output:\n        \"sv/calls.bcf\",\n    params:\n        uncompressed_bcf=True,\n        extra=\"\",  # optional parameters for delly (except -g, -x)\n    log:\n        \"logs/delly.log\",\n    threads: 2  # It is best to use as many threads as samples\n    wrapper:\n        \"master/bio/delly\"\n\n\nrule delly_vcfgz:\n    input:\n        ref=\"genome.fasta\",\n        alns=[\"mapped/a.bam\"],\n        # optional\n        exclude=\"human.hg19.excl.tsv\",\n    output:\n        \"sv/calls.vcf.gz\",\n    params:\n        extra=\"\",  # optional parameters for delly (except -g, -x)\n    log:\n        \"logs/delly.log\",\n    threads: 2  # It is best to use as many threads as samples\n    wrapper:\n        \"master/bio/delly\"\n"
    },
    {
      "name": "denoisereadcounts",
      "input": {
        "hdf5": [
          "a.counts.hdf5"
        ]
      },
      "output": {
        "std_copy_ratio": "a.standardizedCR.tsv",
        "denoised_copy_ratio": "a.denoisedCR.tsv"
      },
      "log": {
        "default": "logs/gatk/denoisereadcounts.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/denoisereadcounts"
      },
      "input_types": [
        {
          "hdf5": "TSV or HDF5 file with counts from CollectReadCounts."
        },
        {
          "pon": "Panel-of-normals from CreateReadCountPanelOfNormals (optional)"
        },
        {
          "gc_interval": "GC-content annotated-intervals from {@link AnnotateIntervals (optional)"
        }
      ],
      "output_types": [
        {
          "std_copy_ratio": "Standardized-copy-ratios file"
        },
        {
          "denoised_copy_ratio": "Denoised-copy-ratios file"
        }
      ],
      "rule": "rule denoisereadcounts:\n    input:\n        hdf5=[\"a.counts.hdf5\"],\n    output:\n        std_copy_ratio=\"a.standardizedCR.tsv\",\n        denoised_copy_ratio=\"a.denoisedCR.tsv\",\n    log:\n        \"logs/gatk/denoisereadcounts.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/denoisereadcounts\"\n"
    },
    {
      "name": "diamond_blastp",
      "input": {
        "fname_fasta": "{sample}.fasta",
        "fname_db": "db.dmnd"
      },
      "output": {
        "fname": "{sample}.tsv.gz"
      },
      "log": {
        "default": "logs/diamond_blastp/{sample}.log"
      },
      "params": {
        "extra": "--header --compress 1"
      },
      "wrapper": {
        "default": "master/bio/diamond/blastp"
      },
      "input_types": [
        {
          "fname_fasta": "Path to query file (Fasta formatted)"
        },
        {
          "fname_db": "Path to diamon database"
        }
      ],
      "output_types": [
        {
          "fname": "Path to query results"
        }
      ],
      "rule": "rule diamond_blastp:\n    input:\n        fname_fasta=\"{sample}.fasta\",  # Query fasta file\n        fname_db=\"db.dmnd\",  # Diamond db\n    output:\n        fname=\"{sample}.tsv.gz\",  # Output file\n    log:\n        \"logs/diamond_blastp/{sample}.log\",\n    params:\n        extra=\"--header --compress 1\",  # Additional arguments\n    threads: 8\n    wrapper:\n        \"master/bio/diamond/blastp\"\n"
    },
    {
      "name": "diamond_blastx",
      "input": {
        "fname_fastq": "{sample}.fastq",
        "fname_db": "db.dmnd"
      },
      "output": {
        "fname": "{sample}.tsv.gz"
      },
      "log": {
        "default": "logs/diamond_blastx/{sample}.log"
      },
      "params": {
        "extra": "--header --compress 1"
      },
      "wrapper": {
        "default": "master/bio/diamond/blastx"
      },
      "input_types": [
        {
          "fname_fastq": "Fastq query file"
        },
        {
          "fname_db": "Path to diamon database"
        }
      ],
      "output_types": [
        {
          "fname": "Path to query result"
        }
      ],
      "rule": "rule diamond_blastx:\n    input:\n        fname_fastq = \"{sample}.fastq\",\n        fname_db = \"db.dmnd\"\n    output:\n        fname = \"{sample}.tsv.gz\"\n    log:\n        \"logs/diamond_blastx/{sample}.log\"\n    params:\n        extra=\"--header --compress 1\"\n    threads: 8\n    wrapper:\n        \"master/bio/diamond/blastx\"\n"
    },
    {
      "name": "diamond_makedb",
      "input": {
        "fname": "{reference}.fasta"
      },
      "output": {
        "fname": "{reference}.dmnd"
      },
      "log": {
        "default": "logs/diamond_makedb/{reference}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/diamond/makedb"
      },
      "input_types": [
        {
          "fname": "Path to reference genome sequence (Fasta formatted)"
        }
      ],
      "output_types": [
        {
          "fname": "Path to diamon database"
        }
      ],
      "rule": "rule diamond_makedb:\n    input:\n        fname = \"{reference}.fasta\",\n    output:\n        fname = \"{reference}.dmnd\"\n    log:\n        \"logs/diamond_makedb/{reference}.log\"\n    params:\n        extra=\"\"\n    threads: 8\n    wrapper:\n        \"master/bio/diamond/makedb\"\n"
    },
    {
      "name": "disambiguate",
      "input": {
        "a": "mapped/{sample}.a.bam",
        "b": "mapped/{sample}.b.bam"
      },
      "output": {
        "a_ambiguous": "disambiguate/{sample}.graft.ambiguous.bam",
        "b_ambiguous": "disambiguate/{sample}.host.ambiguous.bam",
        "a_disambiguated": "disambiguate/{sample}.graft.bam",
        "b_disambiguated": "disambiguate/{sample}.host.bam",
        "summary": "qc/disambiguate/{sample}.txt"
      },
      "log": {},
      "params": {
        "algorithm": "bwa",
        "prefix": "{sample}",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/ngs-disambiguate"
      },
      "input_types": [
        "species a bam file (name sorted)",
        "species b bam file (name sorted)"
      ],
      "output_types": [
        "bam file with ambiguous alignments for species a",
        "bam file with ambiguous alignments for species b",
        "bam file with unambiguous alignments for species a",
        "bam file with unambiguous alignments for species b"
      ],
      "rule": "rule disambiguate:\n    input:\n        a=\"mapped/{sample}.a.bam\",\n        b=\"mapped/{sample}.b.bam\"\n    output:\n        a_ambiguous='disambiguate/{sample}.graft.ambiguous.bam',\n        b_ambiguous='disambiguate/{sample}.host.ambiguous.bam',\n        a_disambiguated='disambiguate/{sample}.graft.bam',\n        b_disambiguated='disambiguate/{sample}.host.bam',\n        summary='qc/disambiguate/{sample}.txt'\n    params:\n        algorithm=\"bwa\",\n        # optional: Prefix to use for output. If omitted, a\n        # suitable value is guessed from the output paths. Prefix\n        # is used for the intermediate output paths, as well as\n        # sample name in summary file.\n        prefix=\"{sample}\",\n        extra=\"\"\n    wrapper:\n        \"master/bio/ngs-disambiguate\"\n"
    },
    {
      "name": "download_file",
      "input": {},
      "output": {
        "default": "data/{egafile}.cram"
      },
      "log": {
        "default": "logs/ega/fetch/{egafile}.log"
      },
      "params": {
        "fileid": "lambda wildcards: wildcards.egafile",
        "extra_pyega3": "-t",
        "extra_fetch": ""
      },
      "wrapper": {
        "default": "master/bio/ega/fetch"
      },
      "input_types": "undefined",
      "output_types": [
        "File formats supported by EGA (BAM, CRAM, VCF, BCF)"
      ],
      "rule": "rule download_file:\n    output:\n        \"data/{egafile}.cram\",\n    log:\n        \"logs/ega/fetch/{egafile}.log\",\n    params:\n        fileid=lambda wildcards: wildcards.egafile,\n        extra_pyega3=\"-t\", # optional extra args for pyega3\n        extra_fetch=\"\",  # optional extra args for the fetch subcommand\n    wrapper:\n        \"master/bio/ega/fetch\"\n"
    },
    {
      "name": "download_mehari_clinvar_db_sv",
      "input": {},
      "output": {
        "default": "directory('resources/mehari/dbs/clinvar/sv')"
      },
      "log": {
        "default": "logs/mehari/download_mehari_clinvar_db.log"
      },
      "params": {
        "version": "20250609+0.42.4",
        "build": "GRCh38",
        "flavour": "sv"
      },
      "wrapper": {
        "default": "master/bio/mehari/download-clinvar-db"
      },
      "input_types": "undefined",
      "output_types": [
        "path to the clinvar DB storage directory"
      ],
      "rule": "rule download_mehari_clinvar_db_sv:\n    output:\n        directory(\"resources/mehari/dbs/clinvar/sv\"),\n    params:\n        version=\"20250609+0.42.4\",  # check https://github.com/varfish-org/annonars-data-clinvar/releases for available versions\n        build=\"GRCh38\",  # GRCh37 or GRCh38\n        flavour=\"sv\",  # genes, minimal or sv\n    log:\n        \"logs/mehari/download_mehari_clinvar_db.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/mehari/download-clinvar-db\"\n"
    },
    {
      "name": "download_mehari_transcript_db",
      "input": {},
      "output": {
        "default": "resources/mehari/dbs/transcripts.bin.zst"
      },
      "log": {
        "default": "logs/mehari/download_mehari_transcript_db.log"
      },
      "params": {
        "version": "0.10.3",
        "build": "GRCh38",
        "source": "ensembl"
      },
      "wrapper": {
        "default": "master/bio/mehari/download-transcript-db"
      },
      "input_types": "undefined",
      "output_types": [
        "path to the transcript DB storage location"
      ],
      "rule": "rule download_mehari_transcript_db:\n    output:\n        \"resources/mehari/dbs/transcripts.bin.zst\",\n    params:\n        version=\"0.10.3\",  # check https://github.com/varfish-org/mehari-data-tx/releases for available versions\n        build=\"GRCh38\",  # GRCh37 or GRCh38\n        source=\"ensembl\",  # ensembl, refseq or ensembl-and-refseq\n    log:\n        \"logs/mehari/download_mehari_transcript_db.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/mehari/download-transcript-db\"\n"
    },
    {
      "name": "download_vep_plugins",
      "input": {},
      "output": {
        "default": "directory('resources/vep/plugins')"
      },
      "log": {},
      "params": {
        "release": 100
      },
      "wrapper": {
        "default": "master/bio/vep/plugins"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule download_vep_plugins:\n    output:\n        directory(\"resources/vep/plugins\")\n    params:\n        release=100\n    wrapper:\n        \"master/bio/vep/plugins\"\n        \n"
    },
    {
      "name": "dragmap_align",
      "input": {
        "reads": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "idx": "genome"
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/dragmap/{sample}.align.log"
      },
      "params": {
        "extra": "",
        "sorting": "none",
        "sort_order": "queryname",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/dragmap/align"
      },
      "input_types": [
        {
          "reads": "FASTQ file(s)"
        },
        {
          "idx": "reference hash table"
        }
      ],
      "output_types": [
        "SAM/BAM/CRAM file"
      ],
      "rule": "rule dragmap_align:\n    input:\n        reads=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        idx=\"genome\",\n    output:\n        \"mapped/{sample}.bam\",\n    log:\n        \"logs/dragmap/{sample}.align.log\",\n    params:\n        extra=\"\",\n        sorting=\"none\",  # Can be 'none', 'samtools' or 'picard'.\n        sort_order=\"queryname\",  # Can be 'queryname' or 'coordinate'.\n        sort_extra=\"\",  # Extra args for samtools/picard.\n    threads: 8\n    wrapper:\n        \"master/bio/dragmap/align\"\n"
    },
    {
      "name": "dragmap_build",
      "input": {
        "ref": "{genome}.fasta"
      },
      "output": {
        "idx": "multiext('{genome}/', 'hash_table.cfg', 'hash_table.cfg.bin', 'hash_table.cmp', 'hash_table_stats.txt', 'reference.bin', 'ref_index.bin', 'repeat_mask.bin', 'str_table.bin')"
      },
      "log": {
        "default": "logs/dragmap/{genome}.build.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/dragmap/build"
      },
      "input_types": [
        {
          "ref": "Path to reference genome sequence (Fasta formatted)"
        }
      ],
      "output_types": [
        {
          "idx": "Path to reference hash table"
        }
      ],
      "rule": "rule dragmap_build:\n    input:\n        ref=\"{genome}.fasta\",\n    output:\n        idx=multiext(\n            \"{genome}/\",\n            \"hash_table.cfg\",\n            \"hash_table.cfg.bin\",\n            \"hash_table.cmp\",\n            \"hash_table_stats.txt\",\n            \"reference.bin\",\n            \"ref_index.bin\",\n            \"repeat_mask.bin\",\n            \"str_table.bin\",\n        ),\n    log:\n        \"logs/dragmap/{genome}.build.log\",\n    params:\n        extra=\"\",\n    threads: 2\n    wrapper:\n        \"master/bio/dragmap/build\"\n"
    },
    {
      "name": "encode_fastq_download_PE",
      "input": {},
      "output": {
        "r1": "{accession}_R1.fastq.gz",
        "r2": "{accession}_R2.fastq.gz"
      },
      "log": {
        "default": "logs/download_fastq_encode/PE_{accession}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/encode_fastq_downloader"
      },
      "input_types": "undefined",
      "output_types": "A single fastq.gz file for single-ended data and two for paired-ended data.\n",
      "rule": "rule encode_fastq_download_PE:\n    output:\n        r1=\"{accession}_R1.fastq.gz\",\n        r2=\"{accession}_R2.fastq.gz\"\n    wildcard_constraints:\n        accession=\"ENC(SR|FF).+\"\n    log:\n        \"logs/download_fastq_encode/PE_{accession}.log\",\n    wrapper:\n        \"master/bio/encode_fastq_downloader\"\n\n\nrule encode_fastq_download_SE:\n    output:\n        r1=\"{accession}.fastq.gz\"\n    wildcard_constraints:\n        accession=\"ENC(SR|FF)((?!_R{1,2}).)+\"\n    log:\n        \"logs/download_fastq_encode/SE_{accession}.log\",\n    wrapper:\n        \"master/bio/encode_fastq_downloader\"\n"
    },
    {
      "name": "epic",
      "input": {
        "treatment": "bed/test.bed",
        "background": "bed/control.bed"
      },
      "output": {
        "enriched_regions": "epic/enriched_regions.csv",
        "bed": "epic/enriched_regions.bed",
        "matrix": "epic/matrix.gz"
      },
      "log": {
        "default": "logs/epic/epic.log"
      },
      "params": {
        "genome": "hg19",
        "extra": "-g 3 -w 200"
      },
      "wrapper": {
        "default": "master/bio/epic/peaks"
      },
      "input_types": [
        {
          "treatment": "chip .bed(.gz/.bz) files"
        },
        {
          "background": "input .bed(.gz/.bz) files"
        }
      ],
      "output_types": [
        {
          "enriched_regions": "main output file with enriched peaks"
        },
        {
          "bed": "(optional) contains much of the same info as enriched_regions but in a bed format, suitable for viewing in the UCSC genome browser or downstream use with bedtools"
        },
        {
          "matrix": "(optional) a gzipped matrix of read counts"
        }
      ],
      "rule": "rule epic:\n    input:\n      treatment = \"bed/test.bed\",\n      background = \"bed/control.bed\"\n    output:\n      enriched_regions = \"epic/enriched_regions.csv\", # required\n      bed = \"epic/enriched_regions.bed\", # optional\n      matrix = \"epic/matrix.gz\" # optional\n    log:\n        \"logs/epic/epic.log\"\n    params:\n      genome = \"hg19\", # optional, default hg19\n      extra=\"-g 3 -w 200\" # \"--bigwig epic/bigwigs\"\n    threads: 1 # optional, defaults to 1\n    wrapper:\n        \"master/bio/epic/peaks\"\n"
    },
    {
      "name": "faToTwoBit_fa",
      "input": {
        "default": "{sample}.fa"
      },
      "output": {
        "default": "{sample}.2bit"
      },
      "log": {
        "default": "logs/{sample}.fa_to_2bit.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/ucsc/faToTwoBit"
      },
      "input_types": [
        "Path(s) to genome \\*.fa or \\*.fa.gz files"
      ],
      "output_types": [
        "Path to output '\\*.2bit' file"
      ],
      "rule": "# Example: from *.fa file\nrule faToTwoBit_fa:\n    input:\n        \"{sample}.fa\"\n    output:\n        \"{sample}.2bit\"\n    log:\n        \"logs/{sample}.fa_to_2bit.log\"\n    params:\n        \"\" # optional params string\n    wrapper:\n        \"master/bio/ucsc/faToTwoBit\"\n\n# Example: from *.fa.gz file\nrule faToTwoBit_fa_gz:\n    input:\n        \"{sample}.fa.gz\"\n    output:\n        \"{sample}.2bit\"\n    log:\n        \"logs/{sample}.fa-gz_to_2bit.log\"\n    params:\n        \"\" # optional params string\n    wrapper:\n        \"master/bio/ucsc/faToTwoBit\"\n"
    },
    {
      "name": "fastp_se",
      "input": {
        "sample": [
          "reads/se/{sample}.fastq"
        ]
      },
      "output": {
        "trimmed": "trimmed/se/{sample}.fastq",
        "failed": "trimmed/se/{sample}.failed.fastq",
        "html": "report/se/{sample}.html",
        "json": "report/se/{sample}.json"
      },
      "log": {
        "default": "logs/fastp/se/{sample}.log"
      },
      "params": {
        "adapters": "--adapter_sequence ACGGCTAGCTA",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/fastp"
      },
      "input_types": [
        "fastq file(s)"
      ],
      "output_types": [
        "trimmed fastq file(s)",
        "unpaired reads (optional; eihter in a single file or separate)",
        "merged reads (optional)",
        "failed reads (optional)",
        "json file containing trimming statistics",
        "html file containing trimming statistics"
      ],
      "rule": "rule fastp_se:\n    input:\n        sample=[\"reads/se/{sample}.fastq\"]\n    output:\n        trimmed=\"trimmed/se/{sample}.fastq\",\n        failed=\"trimmed/se/{sample}.failed.fastq\",\n        html=\"report/se/{sample}.html\",\n        json=\"report/se/{sample}.json\"\n    log:\n        \"logs/fastp/se/{sample}.log\"\n    params:\n        adapters=\"--adapter_sequence ACGGCTAGCTA\",\n        extra=\"\"\n    threads: 1\n    wrapper:\n        \"master/bio/fastp\"\n\n\nrule fastp_pe:\n    input:\n        sample=[\"reads/pe/{sample}.1.fastq\", \"reads/pe/{sample}.2.fastq\"] \n    output:\n        trimmed=[\"trimmed/pe/{sample}.1.fastq\", \"trimmed/pe/{sample}.2.fastq\"],\n        # Unpaired reads separately\n        unpaired1=\"trimmed/pe/{sample}.u1.fastq\",\n        unpaired2=\"trimmed/pe/{sample}.u2.fastq\",\n        # or in a single file\n#        unpaired=\"trimmed/pe/{sample}.singletons.fastq\",\n        merged=\"trimmed/pe/{sample}.merged.fastq\",\n        failed=\"trimmed/pe/{sample}.failed.fastq\",\n        html=\"report/pe/{sample}.html\",\n        json=\"report/pe/{sample}.json\"\n    log:\n        \"logs/fastp/pe/{sample}.log\"\n    params:\n        adapters=\"--adapter_sequence ACGGCTAGCTA --adapter_sequence_r2 AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\",\n        extra=\"--merge\"\n    threads: 2\n    wrapper:\n        \"master/bio/fastp\"\n\nrule fastp_pe_wo_trimming:\n    input:\n        sample=[\"reads/pe/{sample}.1.fastq\", \"reads/pe/{sample}.2.fastq\"]\n    output:\n        html=\"report/pe_wo_trimming/{sample}.html\",\n        json=\"report/pe_wo_trimming/{sample}.json\"\n    log:\n        \"logs/fastp/pe_wo_trimming/{sample}.log\"\n    params:\n        extra=\"\"\n    threads: 2\n    wrapper:\n        \"master/bio/fastp\"\n"
    },
    {
      "name": "fastq_screen",
      "input": {
        "default": "samples/{sample}.fastq"
      },
      "output": {
        "txt": "qc/{sample}.fastq_screen.txt",
        "png": "qc/{sample}.fastq_screen.png"
      },
      "log": {
        "default": "logs/fastq_screen/{sample}.log"
      },
      "params": {
        "fastq_screen_config": "fastq_screen.conf",
        "subset": 100000,
        "aligner": "bowtie2"
      },
      "wrapper": {
        "default": "master/bio/fastq_screen"
      },
      "input_types": [
        "A FASTQ file, gzipped or not."
      ],
      "output_types": [
        {
          "txt": "Fraction of reads mapping to each provided index (optional)"
        },
        {
          "png": "Barplot of the contents of ``txt``, saved as a PNG file (optional)"
        },
        {
          "conf": "Configuration used by fastq screen (optional)"
        }
      ],
      "rule": "rule fastq_screen:\n    input:\n        \"samples/{sample}.fastq\",\n    output:\n        txt=\"qc/{sample}.fastq_screen.txt\",\n        png=\"qc/{sample}.fastq_screen.png\",\n    params:\n        fastq_screen_config=\"fastq_screen.conf\",\n        subset=100000,\n        aligner=\"bowtie2\",\n    log:\n        \"logs/fastq_screen/{sample}.log\",\n    threads: 8\n    wrapper:\n        \"master/bio/fastq_screen\"\n\n\nrule fastq_screen_with_config:\n    input:\n        \"samples/{sample}.fastq\",\n    output:\n        txt=\"qc/{sample}.fastq_screen_conf.txt\",\n        png=\"qc/{sample}.fastq_screen_conf.png\",\n        conf=\"qc/{sample}.config.txt\",\n    params:\n        fastq_screen_config={\n            \"aligner_paths\": {\"bowtie2\": \"bowtie2\"},\n            \"database\": {\"test\": {\"bowtie2\": \"genome\"}},\n        },\n        subset=100000,\n        aligner=\"bowtie2\",\n    log:\n        \"logs/fastq_screen/{sample}_conf.log\",\n    threads: 8\n    wrapper:\n        \"master/bio/fastq_screen\"\n\n\nrule fastq_screen_without_png:\n    input:\n        \"samples/{sample}.fastq\",\n    output:\n        txt=\"qc/{sample}.fastq_screen_nopng.txt\",\n    params:\n        fastq_screen_config={\n            \"aligner_paths\": {\"bowtie2\": \"bowtie2\"},\n            \"database\": {\"test\": {\"bowtie2\": \"genome\"}},\n        },\n        subset=100000,\n        aligner=\"bowtie2\",\n    log:\n        \"logs/fastq_screen/{sample}_nopng.log\",\n    threads: 8\n    wrapper:\n        \"master/bio/fastq_screen\"\n"
    },
    {
      "name": "fastqc",
      "input": {
        "default": "reads/{sample}.fastq"
      },
      "output": {
        "html": "qc/fastqc/{sample}.html",
        "zip": "qc/fastqc/{sample}_fastqc.zip"
      },
      "log": {
        "default": "logs/fastqc/{sample}.log"
      },
      "params": {
        "extra": "--quiet",
        "mem_overhead_factor": 0.1
      },
      "wrapper": {
        "default": "master/bio/fastqc"
      },
      "input_types": [
        "fastq file"
      ],
      "output_types": [
        {
          "html": "statistics file in HTML format"
        },
        {
          "zip": "statistics in text format (zip'ed)"
        }
      ],
      "rule": "rule fastqc:\n    input:\n        \"reads/{sample}.fastq\",\n    output:\n        html=\"qc/fastqc/{sample}.html\",\n        zip=\"qc/fastqc/{sample}_fastqc.zip\", # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename\n    params:\n        extra=\"--quiet\",\n        mem_overhead_factor=0.1,\n    log:\n        \"logs/fastqc/{sample}.log\",\n    threads: 1\n    resources:\n        mem_mb = 1024,\n    wrapper:\n        \"master/bio/fastqc\"\n"
    },
    {
      "name": "fasttree",
      "input": {
        "alignment": "{sample}.fa"
      },
      "output": {
        "tree": "{sample}.nwk"
      },
      "log": {
        "default": "logs/muscle/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/fasttree"
      },
      "input_types": [
        "Alignment FASTA or interleaved phylip file"
      ],
      "output_types": [
        "Newick formatted tree file"
      ],
      "rule": "rule fasttree:\n    input:\n        alignment=\"{sample}.fa\",  # Input alignment file\n    output:\n        tree=\"{sample}.nwk\",  # Output tree file\n    log:\n        \"logs/muscle/{sample}.log\",\n    params:\n        extra=\"\",  # Additional arguments\n    wrapper:\n        \"master/bio/fasttree\"\n"
    },
    {
      "name": "feature_counts",
      "input": {
        "samples": "{sample}.bam",
        "annotation": "annotation.gtf"
      },
      "output": {
        "default": "multiext('results/{sample}', '.featureCounts', '.featureCounts.summary', '.featureCounts.jcounts')"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "strand": 0,
        "r_path": "",
        "extra": "-O --fracOverlap 0.2 -J -p"
      },
      "wrapper": {
        "default": "master/bio/subread/featurecounts"
      },
      "input_types": [
        "a list of .sam or .bam files",
        "GTF, GFF or SAF annotation file",
        "optional a tab separating file that determines the sorting order and contains the chromosome names in the first column",
        "optional a fasta index file"
      ],
      "output_types": [
        "Feature counts file including read counts (tab separated)",
        "Summary file including summary statistics (tab separated)",
        "Junction counts file including count number of reads supporting each exon-exon junction (tab separated)"
      ],
      "rule": "rule feature_counts:\n    input:\n        # list of sam or bam files\n        samples=\"{sample}.bam\",\n        annotation=\"annotation.gtf\",\n        # optional input\n        #chr_names=\"\",           # implicitly sets the -A flag\n        #fasta=\"genome.fasta\"    # implicitly sets the -G flag\n    output:\n        multiext(\n            \"results/{sample}\",\n            \".featureCounts\",\n            \".featureCounts.summary\",\n            \".featureCounts.jcounts\",\n        ),\n    threads: 2\n    params:\n        strand=0,  # optional; strandness of the library (0: unstranded [default], 1: stranded, and 2: reversely stranded)\n        r_path=\"\",  # implicitly sets the --Rpath flag\n        extra=\"-O --fracOverlap 0.2 -J -p\",\n    log:\n        \"logs/{sample}.log\",\n    wrapper:\n        \"master/bio/subread/featurecounts\"\n"
    },
    {
      "name": "filter_vcf",
      "input": {
        "default": "{sample}.vcf"
      },
      "output": {
        "default": "{sample}.filtered.vcf"
      },
      "log": {},
      "params": {
        "extra": "--chr 1 --recode-INFO-all"
      },
      "wrapper": {
        "default": "master/bio/vcftools/filter"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule filter_vcf:\n    input:\n        \"{sample}.vcf\"\n    output:\n        \"{sample}.filtered.vcf\"\n    params:\n        extra=\"--chr 1 --recode-INFO-all\"\n    wrapper:\n        \"master/bio/vcftools/filter\"\n"
    },
    {
      "name": "filtlong",
      "input": {
        "reads": "{sample}.fastq"
      },
      "output": {
        "default": "{sample}.filtered.fastq"
      },
      "log": {
        "default": "logs/filtlong/test/{sample}.log"
      },
      "params": {
        "extra": " --mean_q_weight 5.0",
        "target_bases": 10
      },
      "wrapper": {
        "default": "master/bio/filtlong"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule filtlong:\n    input:\n        reads = \"{sample}.fastq\"\n    output:\n        \"{sample}.filtered.fastq\"\n    params:\n        extra=\" --mean_q_weight 5.0\",\n        target_bases = 10\n    log:\n        \"logs/filtlong/test/{sample}.log\"\n    wrapper:\n        \"master/bio/filtlong\"\n"
    },
    {
      "name": "freebayes",
      "input": {
        "alns": "mapped/{sample}.bam",
        "idxs": "mapped/{sample}.bam.bai",
        "ref": "genome.fasta"
      },
      "output": {
        "vcf": "calls/{sample}.vcf"
      },
      "log": {
        "default": "logs/freebayes/{sample}.log"
      },
      "params": {
        "normalize": "-a"
      },
      "wrapper": {
        "default": "master/bio/freebayes"
      },
      "input_types": [
        "SAM/BAM/CRAM file(s)",
        "reference genome"
      ],
      "output_types": [
        "VCF/VCF.gz/BCF file"
      ],
      "rule": "rule freebayes:\n    input:\n        alns=\"mapped/{sample}.bam\",\n        idxs=\"mapped/{sample}.bam.bai\",\n        ref=\"genome.fasta\",\n    output:\n        vcf = \"calls/{sample}.vcf\",\n    log:\n        \"logs/freebayes/{sample}.log\",\n    params:\n        normalize=\"-a\",\n    threads: 2\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/freebayes\"\n\n\nrule freebayes_bcf:\n    input:\n        alns=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n    output:\n        bcf=\"calls/{sample}.bcf\",\n    log:\n        \"logs/freebayes/{sample}.bcf.log\",\n    threads: 2\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/freebayes\"\n\n\nrule freebayes_bed:\n    input:\n        alns=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n        regions=\"regions.bed\",\n    output:\n        vcf=\"calls/{sample}.vcf.gz\",\n    log:\n        \"logs/freebayes/{sample}.bed.log\",\n    params:\n        chunksize=50000,\n    threads: 2\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/freebayes\"\n"
    },
    {
      "name": "galah_fas",
      "input": {
        "fas": [
          "fas/a.fa",
          "fas/b.fas.bz2",
          "fas/c.fasta.gz"
        ]
      },
      "output": {
        "clusters": "results.fas.tsv",
        "repres": "results.fas.list"
      },
      "log": {
        "default": "logs/out.fas.log"
      },
      "params": {
        "extra": "--precluster-ani 0.9 --ani 0.95"
      },
      "wrapper": {
        "default": "master/bio/galah"
      },
      "input_types": [
        "FASTA files"
      ],
      "output_types": [
        {
          "clusters": "representative FASTA<TAB>member lines"
        },
        {
          "repres": "paths to representative FAS files"
        }
      ],
      "rule": "rule galah_fas:\n    input:\n        fas=[\"fas/a.fa\", \"fas/b.fas.bz2\", \"fas/c.fasta.gz\"],\n    output:\n        clusters=\"results.fas.tsv\",\n        repres=\"results.fas.list\",\n    log:\n        \"logs/out.fas.log\",\n    params:\n        extra=\"--precluster-ani 0.9 --ani 0.95\",\n    threads: 2\n    resources:\n        mem_mb=50,\n    wrapper:\n        \"master/bio/galah\"\n\n\nuse rule galah_fas as galah_fas_list with:\n    input:\n        fas_list=\"fas/a.fas_list\",\n    output:\n        clusters=\"results.fas_list.tsv\",\n        repres=\"results.fas_list.list\",\n    log:\n        \"logs/out.fas_list.log\",\n"
    },
    {
      "name": "gatk_annotator",
      "input": {
        "vcf": "calls/snvs.vcf.gz",
        "aln": "mapped/a.bam",
        "bai": "mapped/a.bam.bai",
        "ref": "genome.fasta",
        "db": "calls/snvs.vcf.gz"
      },
      "output": {
        "vcf": "snvs.annot.vcf"
      },
      "log": {
        "default": "logs/gatk/annotator/snvs.log"
      },
      "params": {
        "extra": "--resource-allele-concordance -A Coverage --expression db.END",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/variantannotator"
      },
      "input_types": [
        "VCF file",
        "BAM file",
        "reference genome",
        "VCF of known variation"
      ],
      "output_types": [
        "annotated VCF file"
      ],
      "rule": "rule gatk_annotator:\n    input:\n        vcf=\"calls/snvs.vcf.gz\",\n        aln=\"mapped/a.bam\",\n        bai=\"mapped/a.bam.bai\",\n        ref=\"genome.fasta\",\n        db=\"calls/snvs.vcf.gz\",\n#        intervals=\"targets.bed\",\n    output:\n        vcf=\"snvs.annot.vcf\",\n    log:\n        \"logs/gatk/annotator/snvs.log\",\n    params:\n        extra=\"--resource-allele-concordance -A Coverage --expression db.END\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/variantannotator\"\n"
    },
    {
      "name": "gatk_applybqsr",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta",
        "dict": "genome.dict",
        "recal_table": "recal/{sample}.grp"
      },
      "output": {
        "bam": "recal/{sample}.bam"
      },
      "log": {
        "default": "logs/gatk/gatk_applybqsr/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": "",
        "embed_ref": true
      },
      "wrapper": {
        "default": "master/bio/gatk/applybqsr"
      },
      "input_types": [
        "BAM file",
        "FASTA reference",
        "recalibration table for the bam"
      ],
      "output_types": [
        "recalibrated bam file"
      ],
      "rule": "rule gatk_applybqsr:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n        dict=\"genome.dict\",\n        recal_table=\"recal/{sample}.grp\",\n    output:\n        bam=\"recal/{sample}.bam\",\n    log:\n        \"logs/gatk/gatk_applybqsr/{sample}.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n        embed_ref=True,  # embed the reference in cram output\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/applybqsr\"\n"
    },
    {
      "name": "gatk_applybqsr_spark",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta",
        "dict": "genome.dict",
        "recal_table": "recal/{sample}.grp"
      },
      "output": {
        "bam": "recal/{sample}.bam"
      },
      "log": {
        "default": "logs/gatk/gatk_applybqsr_spark/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": "",
        "embed_ref": true,
        "exceed_thread_limit": true
      },
      "wrapper": {
        "default": "master/bio/gatk/applybqsrspark"
      },
      "input_types": [
        "bam file",
        "fasta reference",
        "recalibration table for the bam"
      ],
      "output_types": [
        "recalibrated bam file"
      ],
      "rule": "rule gatk_applybqsr_spark:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n        dict=\"genome.dict\",\n        recal_table=\"recal/{sample}.grp\",\n    output:\n        bam=\"recal/{sample}.bam\",\n    log:\n        \"logs/gatk/gatk_applybqsr_spark/{sample}.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n        #spark_runner=\"\",  # optional, local by default\n        #spark_master=\"\",  # optional\n        #spark_extra=\"\", # optional\n        embed_ref=True,  # embed reference in cram output\n        exceed_thread_limit=True,  # samtools is also parallized and thread limit is not guaranteed anymore\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/applybqsrspark\"\n"
    },
    {
      "name": "gatk_baserecalibrator",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta",
        "dict": "genome.dict",
        "known": "dbsnp.vcf.gz"
      },
      "output": {
        "recal_table": "recal/{sample}.grp"
      },
      "log": {
        "default": "logs/gatk/baserecalibrator/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/baserecalibrator"
      },
      "input_types": [
        "bam file",
        "fasta reference",
        "vcf.gz of known variants"
      ],
      "output_types": [
        "recalibration table for the bam"
      ],
      "rule": "rule gatk_baserecalibrator:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n        dict=\"genome.dict\",\n        known=\"dbsnp.vcf.gz\",  # optional known sites - single or a list\n    output:\n        recal_table=\"recal/{sample}.grp\",\n    log:\n        \"logs/gatk/baserecalibrator/{sample}.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/baserecalibrator\"\n"
    },
    {
      "name": "gatk_baserecalibratorspark",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta",
        "dict": "genome.dict",
        "known": "dbsnp.vcf.gz"
      },
      "output": {
        "recal_table": "recal/{sample}.grp"
      },
      "log": {
        "default": "logs/gatk/baserecalibrator/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/baserecalibratorspark"
      },
      "input_types": [
        "bam file",
        "fasta reference",
        "vcf.gz of known variants"
      ],
      "output_types": [
        "recalibration table for the bam"
      ],
      "rule": "rule gatk_baserecalibratorspark:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n        dict=\"genome.dict\",\n        known=\"dbsnp.vcf.gz\",  # optional known sites\n    output:\n        recal_table=\"recal/{sample}.grp\",\n    log:\n        \"logs/gatk/baserecalibrator/{sample}.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n        #spark_runner=\"\",  # optional, local by default\n        #spark_master=\"\",  # optional\n        #spark_extra=\"\", # optional\n    resources:\n        mem_mb=1024,\n    threads: 8\n    wrapper:\n        \"master/bio/gatk/baserecalibratorspark\"\n"
    },
    {
      "name": "gatk_clean_sam",
      "input": {
        "bam": "{sample}.bam"
      },
      "output": {
        "clean": "{sample}.clean.bam"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/cleansam"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "clean and validates SAM/BAM/CRAM file"
      ],
      "rule": "rule gatk_clean_sam:\n    input:\n        bam=\"{sample}.bam\",\n    output:\n        clean=\"{sample}.clean.bam\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/cleansam\"\n"
    },
    {
      "name": "gatk_depth_of_coverage",
      "input": {
        "bam": "mapped/a.bam",
        "fasta": "genome.fasta",
        "intervals": "regions.interval_list"
      },
      "output": {
        "default": "multiext('depth/a', '', '.sample_interval_summary', '.sample_cumulative_coverage_counts', '.sample_cumulative_coverage_proportions', '.sample_interval_statistics', '.sample_statistics', '.sample_summary')"
      },
      "log": {
        "default": "logs/gatk/depthofcoverage.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/depthofcoverage"
      },
      "input_types": [
        "one bam file to be analyzed for coverage statistics",
        "one or more genomic intervals over which to operate",
        "reference genome"
      ],
      "output_types": [
        "base file location to which to write coverage summary information"
      ],
      "rule": "rule gatk_depth_of_coverage:\n    input:\n        bam=\"mapped/a.bam\",  # File containing reads\n        fasta=\"genome.fasta\",\n        intervals=\"regions.interval_list\",  # Regions where the coverage is computed\n    output:\n        multiext(\n            \"depth/a\",\n            \"\",\n            \".sample_interval_summary\",\n            \".sample_cumulative_coverage_counts\",\n            \".sample_cumulative_coverage_proportions\",\n            \".sample_interval_statistics\",\n            \".sample_statistics\",\n            \".sample_summary\",\n        ),\n    log:\n        \"logs/gatk/depthofcoverage.log\",\n    params:\n        extra=\"\",\n        java_opts=\"\",\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/depthofcoverage\"\n"
    },
    {
      "name": "gatk_estimate_library_complexity",
      "input": {
        "bam": "{sample}.bam"
      },
      "output": {
        "metrics": "{sample}.metrics"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/estimatelibrarycomplexity"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "metrics file"
      ],
      "rule": "rule gatk_estimate_library_complexity:\n    input:\n        bam=\"{sample}.bam\",\n    output:\n        metrics=\"{sample}.metrics\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/estimatelibrarycomplexity\"\n"
    },
    {
      "name": "gatk_filter",
      "input": {
        "vcf": "calls/snvs.vcf",
        "ref": "genome.fasta"
      },
      "output": {
        "vcf": "calls/snvs.filtered.vcf"
      },
      "log": {
        "default": "logs/gatk/filter/snvs.log"
      },
      "params": {
        "filters": {
          "myfilter": "AB < 0.2 || MQ0 > 50"
        },
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/variantfiltration"
      },
      "input_types": [
        "vcf file",
        "reference genome"
      ],
      "output_types": [
        "filtered vcf file"
      ],
      "rule": "rule gatk_filter:\n    input:\n        vcf=\"calls/snvs.vcf\",\n        ref=\"genome.fasta\",\n#        intervals=\"targets.bed\",\n    output:\n        vcf=\"calls/snvs.filtered.vcf\",\n    log:\n        \"logs/gatk/filter/snvs.log\",\n    params:\n        filters={\"myfilter\": \"AB < 0.2 || MQ0 > 50\"},\n        extra=\"\",  # optional arguments, see GATK docs\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/variantfiltration\"\n"
    },
    {
      "name": "gatk_filtermutectcalls",
      "input": {
        "vcf": "calls/snvs.vcf",
        "ref": "genome.fasta"
      },
      "output": {
        "vcf": "calls/snvs.mutect.filtered.vcf"
      },
      "log": {
        "default": "logs/gatk/filter/snvs.log"
      },
      "params": {
        "extra": "--max-alt-allele-count 3",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/filtermutectcalls"
      },
      "input_types": [
        {
          "vcf": "Path to vcf file (pbgzipped, indexed)"
        },
        {
          "ref": "Path to reference genome (with .dict file alongside)"
        },
        {
          "aln": "Optional path to SAM/BAM/CRAM files"
        },
        {
          "contamination": "Optional path to contamination table"
        },
        {
          "segmentation": "Optional path to tumor segments"
        },
        {
          "f1r2": "Optional path to prior artefact (tar.gz2)"
        },
        {
          "intervels": "Optional file to BED intervals"
        }
      ],
      "output_types": [
        {
          "vcf": "filtered vcf file"
        },
        {
          "stats": "Optional stats from Mutect2"
        }
      ],
      "rule": "rule gatk_filtermutectcalls:\n    input:\n        vcf=\"calls/snvs.vcf\",\n        ref=\"genome.fasta\",\n    output:\n        vcf=\"calls/snvs.mutect.filtered.vcf\",\n    log:\n        \"logs/gatk/filter/snvs.log\",\n    params:\n        extra=\"--max-alt-allele-count 3\",  # optional arguments, see GATK docs\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/filtermutectcalls\"\n\n\nrule gatk_filtermutectcalls_complete:\n    input:\n        vcf=\"calls/snvs.vcf\",\n        ref=\"genome.fasta\",\n        bam=\"mapped/a.bam\",\n        intervals=\"intervals.bed\",\n        # contamination=\"\", # from gatk CalculateContamination\n        # segmentation=\"\", # from gatk CalculateContamination\n        # f1r2=\"\", # from gatk LearnReadOrientationBias\n    output:\n        vcf=\"calls/snvs.mutect.filtered.b.vcf\",\n    log:\n        \"logs/gatk/filter/snvs.log\",\n    params:\n        extra=\"--max-alt-allele-count 3\",  # optional arguments, see GATK docs\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/filtermutectcalls\"\n"
    },
    {
      "name": "gatk_interval_list_to_bed",
      "input": {
        "intervals": "genome.intervals"
      },
      "output": {
        "bed": "genome.bed"
      },
      "log": {
        "default": "logs/genome.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/intervallisttobed"
      },
      "input_types": [
        "interval list"
      ],
      "output_types": [
        "bed file"
      ],
      "rule": "rule gatk_interval_list_to_bed:\n    input:\n        intervals=\"genome.intervals\",\n    output:\n        bed=\"genome.bed\",\n    log:\n        \"logs/genome.log\",\n    params:\n        extra=\"\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/intervallisttobed\"\n"
    },
    {
      "name": "gatk_leftalignandtrimvariants",
      "input": {
        "vcf": "calls/test_split_with_AS_filters.vcf",
        "ref": "Homo_sapiens_assembly38.chrM.fasta",
        "fai": "Homo_sapiens_assembly38.chrM.fasta.fai",
        "dict": "Homo_sapiens_assembly38.chrM.dict"
      },
      "output": {
        "vcf": "calls/split_multiallelics.vcf"
      },
      "log": {
        "default": "logs/gatk/leftalignandtrimvariants.log"
      },
      "params": {
        "extra": "--split-multi-allelics",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/leftalignandtrimvariants"
      },
      "input_types": [
        "A variant call set to left-align and trim"
      ],
      "output_types": [
        "A left-aligned VCF"
      ],
      "rule": "rule gatk_leftalignandtrimvariants:\n    input:\n        vcf=\"calls/test_split_with_AS_filters.vcf\",\n        ref=\"Homo_sapiens_assembly38.chrM.fasta\",\n        fai=\"Homo_sapiens_assembly38.chrM.fasta.fai\",\n        dict=\"Homo_sapiens_assembly38.chrM.dict\",\n#       intervals=\"intervals.bed\", # optional\n    output:\n        vcf=\"calls/split_multiallelics.vcf\",\n    log:\n        \"logs/gatk/leftalignandtrimvariants.log\",\n    params:\n        extra=\"--split-multi-allelics\", # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/leftalignandtrimvariants\"\n"
    },
    {
      "name": "gatk_printreadsspark",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta",
        "dict": "genome.dict"
      },
      "output": {
        "bam": "{sample}.bam"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/printreadsspark"
      },
      "input_types": [
        "bam file",
        "reference file",
        "reference dict"
      ],
      "output_types": [
        "filtered bam file"
      ],
      "rule": "rule gatk_printreadsspark:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n        dict=\"genome.dict\",\n    output:\n        bam=\"{sample}.bam\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n        #spark_runner=\"\",  # optional, local by default\n        #spark_master=\"\",  # optional\n        #spark_extra=\"\", # optional\n    resources:\n        mem_mb=1024,\n    threads: 8\n    wrapper:\n        \"master/bio/gatk/printreadsspark\"\n"
    },
    {
      "name": "gatk_scatter_interval_by_ns",
      "input": {
        "ref": "genome.fasta",
        "fai": "genome.fasta.fai",
        "dict": "genome.dict"
      },
      "output": {
        "intervals": "genome.intervals"
      },
      "log": {
        "default": "logs/genome.log"
      },
      "params": {
        "extra": "--MAX_TO_MERGE 10 --OUTPUT_TYPE ACGT",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/scatterintervalsbyns"
      },
      "input_types": [
        "reference genome"
      ],
      "output_types": [
        "interval list"
      ],
      "rule": "rule gatk_scatter_interval_by_ns:\n    input:\n        ref=\"genome.fasta\",\n        fai=\"genome.fasta.fai\",\n        dict=\"genome.dict\",\n    output:\n        intervals=\"genome.intervals\",\n    log:\n        \"logs/genome.log\",\n    params:\n        extra=\"--MAX_TO_MERGE 10 --OUTPUT_TYPE ACGT\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/scatterintervalsbyns\"\n"
    },
    {
      "name": "gatk_select",
      "input": {
        "vcf": "calls/all.vcf",
        "ref": "genome.fasta"
      },
      "output": {
        "vcf": "calls/snvs.vcf"
      },
      "log": {
        "default": "logs/gatk/select/snvs.log"
      },
      "params": {
        "extra": "--select-type-to-include SNP",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/selectvariants"
      },
      "input_types": [
        "vcf file",
        "reference genome"
      ],
      "output_types": [
        "filtered vcf file"
      ],
      "rule": "rule gatk_select:\n    input:\n        vcf=\"calls/all.vcf\",\n        ref=\"genome.fasta\",\n    output:\n        vcf=\"calls/snvs.vcf\",\n    log:\n        \"logs/gatk/select/snvs.log\",\n    params:\n        extra=\"--select-type-to-include SNP\",  # optional filter arguments, see GATK docs\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/selectvariants\"\n"
    },
    {
      "name": "gatk_split_interval_list",
      "input": {
        "intervals": "genome.interval_list",
        "ref": "genome.fasta"
      },
      "output": {
        "bed": "multiext('out/genome', '.00.bed', '.01.bed', '.02.bed')"
      },
      "log": {
        "default": "logs/genome.log"
      },
      "params": {
        "extra": "--subdivision-mode BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/splitintervals"
      },
      "input_types": [
        "Intervals/BED file"
      ],
      "output_types": [
        "Several Intervals/BED files"
      ],
      "rule": "rule gatk_split_interval_list:\n    input:\n        intervals=\"genome.interval_list\",\n        ref=\"genome.fasta\",\n    output:\n        bed=multiext(\"out/genome\", \".00.bed\", \".01.bed\", \".02.bed\"),\n    log:\n        \"logs/genome.log\",\n    params:\n        extra=\"--subdivision-mode BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/splitintervals\"\n"
    },
    {
      "name": "gatk_varianteval",
      "input": {
        "vcf": "calls/snvs.vcf",
        "ref": "genome.fasta",
        "dict": "genome.dict"
      },
      "output": {
        "vcf": "snvs.varianteval.grp"
      },
      "log": {
        "default": "logs/gatk/varianteval/snvs.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/varianteval"
      },
      "input_types": [
        "vcf files",
        "BAM/CRAM files (optional)",
        "reference genome (optional)",
        "reference dictionary (optional)",
        "vcf.gz of known variants (optional)",
        "PED (pedigree) file (optional)"
      ],
      "output_types": [
        "Evaluation tables detailing the results of the eval modules on VCF file"
      ],
      "rule": "rule gatk_varianteval:\n    input:\n        vcf=\"calls/snvs.vcf\",\n        ref=\"genome.fasta\",\n        dict=\"genome.dict\",\n        # comp=\"calls/comp.vcf\", # optional comparison VCF\n    output:\n        vcf=\"snvs.varianteval.grp\",\n    log:\n        \"logs/gatk/varianteval/snvs.log\",\n    params:\n        extra=\"\",  # optional arguments, see GATK docs\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/varianteval\"\n"
    },
    {
      "name": "gatk_variantstotable",
      "input": {
        "vcf": "calls/snvs.vcf"
      },
      "output": {
        "tab": "calls/snvs.tab"
      },
      "log": {
        "default": "logs/gatk/varintstotable.log"
      },
      "params": {
        "extra": "-F CHROM -F POS -F TYPE -GF AD",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/variantstotable"
      },
      "input_types": [
        "A VCF file to convert to a table"
      ],
      "output_types": [
        "A tab-delimited file containing the values of the requested fields in the VCF file"
      ],
      "rule": "rule gatk_variantstotable:\n    input:\n        vcf=\"calls/snvs.vcf\",\n#        intervals=\"intervals.bed\",\n    output:\n        tab=\"calls/snvs.tab\",\n    log:\n        \"logs/gatk/varintstotable.log\",\n    params:\n        extra=\"-F CHROM -F POS -F TYPE -GF AD\",\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/variantstotable\"\n"
    },
    {
      "name": "gcsa",
      "input": {
        "vgs": [
          "x.vg",
          "c.vg"
        ]
      },
      "output": {
        "gcsa": "index/wg.gcsa"
      },
      "log": {
        "default": "logs/vg/index/gcsa/wg.log"
      },
      "params": {
        "default": "-Z 3000 -X 3"
      },
      "wrapper": {
        "default": "master/bio/vg/index/gcsa"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule gcsa:\n    input:\n        vgs=[\"x.vg\", \"c.vg\"]\n    output:\n        gcsa=\"index/wg.gcsa\"\n    params:\n        \"-Z 3000 -X 3\"\n    log:\n        \"logs/vg/index/gcsa/wg.log\"\n    threads:\n        4\n    wrapper:\n        \"master/bio/vg/index/gcsa\"\n"
    },
    {
      "name": "gdc_api_bam_slice_download",
      "input": {},
      "output": {
        "bam": "raw/{sample}.bam"
      },
      "log": {
        "default": "logs/gdc-api/bam-slicing/{sample}.log"
      },
      "params": {
        "uuid": "092c8a6d-aad5-41bf-b186-e68e613c0e89",
        "gdc_token": "gdc/gdc-user-token.2020-05-07T10_00_00.555Z.txt",
        "slices": "region=chr22&region=chr5:1000-2000&region=unmapped&gencode=BRCA2",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gdc-api/bam-slicing"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule gdc_api_bam_slice_download:\n    output:\n        bam=\"raw/{sample}.bam\",\n    log:\n        \"logs/gdc-api/bam-slicing/{sample}.log\"\n    params:\n        # to use this rule flexibly, make uuid a function that maps your\n        # sample names of choice to the UUIDs they correspond to (they are\n        # the column `id` in the GDC manifest files, which can be used to\n        # systematically construct sample sheets)\n        uuid=\"092c8a6d-aad5-41bf-b186-e68e613c0e89\",\n        # a gdc_token is required for controlled access and all BAM files\n        # on GDC seem to be controlled access (adjust if this changes)\n        gdc_token=\"gdc/gdc-user-token.2020-05-07T10_00_00.555Z.txt\",\n        # provide wanted `region=` or `gencode=` slices joined with `&`\n        slices=\"region=chr22&region=chr5:1000-2000&region=unmapped&gencode=BRCA2\",\n        # extra command line arguments passed to curl\n        extra=\"\"\n    wrapper:\n        \"master/bio/gdc-api/bam-slicing\"\n"
    },
    {
      "name": "gdc_download",
      "input": {},
      "output": {
        "default": "raw/{sample}.maf.gz"
      },
      "log": {
        "default": "logs/gdc-client/download/{sample}.log"
      },
      "params": {
        "uuid": "173e67fb-917c-43e1-b07c-f2b7d1ca6998",
        "gdc_token": "gdc/gdc-user-token.2020-05-07T10_00_00.555Z.txt",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gdc-client/download"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule gdc_download:\n    output:\n        # the file extension (up to two components, here .maf.gz), has\n        # to uniquely map to one of the files downloaded for that UUID\n        \"raw/{sample}.maf.gz\",\n    log:\n        \"logs/gdc-client/download/{sample}.log\",\n    params:\n        # to use this rule flexibly, make uuid a function that maps your\n        # sample names of choice to the UUIDs they correspond to (they are\n        # the column `id` in the GDC manifest files, which can be used to\n        # systematically construct sample sheets)\n        uuid=\"173e67fb-917c-43e1-b07c-f2b7d1ca6998\",\n        # a gdc_token is only required for controlled access samples,\n        # leave blank otherwise (`gdc_token=\"\"`) or skip this param entirely\n        gdc_token=\"gdc/gdc-user-token.2020-05-07T10_00_00.555Z.txt\",\n        # for valid extra command line arguments, check command line help or:\n        # https://docs.gdc.cancer.gov/Data_Transfer_Tool/Users_Guide/Data_Download_and_Upload/\n        extra=\"\",\n    threads: 4\n    wrapper:\n        \"master/bio/gdc-client/download\"\n\n\nrule gdc_download_bam:\n    output:\n        # specify all the downloaded files you want to keep, as all other\n        # downloaded files will be removed automatically e.g. for\n        # BAM data this could be\n        \"raw/{sample}.bam\",\n        \"raw/{sample}.bam.bai\",\n        \"raw/{sample}.annotations.txt\",\n        directory(\"raw/{sample}/logs\"),\n    log:\n        \"logs/gdc-client/download/{sample}.log\",\n    params:\n        # to use this rule flexibly, make uuid a function that maps your\n        # sample names of choice to the UUIDs they correspond to (they are\n        # the column `id` in the GDC manifest files, which can be used to\n        # systematically construct sample sheets)\n        uuid=\"72a72637-284e-4f1c-8c5e-0a657136c3c3\",\n        # a gdc_token is only required for controlled access samples,\n        # leave blank otherwise (`gdc_token=\"\"`) or skip this param entirely\n        gdc_token=\"gdc/gdc-user-token.2020-05-07T10_00_00.555Z.txt\",\n        # for valid extra command line arguments, check command line help or:\n        # https://docs.gdc.cancer.gov/Data_Transfer_Tool/Users_Guide/Data_Download_and_Upload/\n        extra=\"\",\n    threads: 4\n    wrapper:\n        \"master/bio/gdc-client/download\"\n"
    },
    {
      "name": "genefuse",
      "input": {
        "fastq1": "reads/{sample}_R1.fastq",
        "fastq2": "reads/{sample}_R2.fastq",
        "config": "genes.csv",
        "reference": "genome.fasta"
      },
      "output": {
        "html": "{sample}_genefuse_report.html",
        "json": "{sample}_genefuse_report.json",
        "fusions": "{sample}_fusions.txt"
      },
      "log": {
        "default": "logs/{sample}_genefuse.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/genefuse"
      },
      "input_types": [
        "fastq files",
        "gene fuse settings files",
        "refeference genome"
      ],
      "output_types": [
        "txt file with fusions",
        "html report",
        "json report"
      ],
      "rule": "rule genefuse:\n    input:\n        fastq1=\"reads/{sample}_R1.fastq\",\n        fastq2=\"reads/{sample}_R2.fastq\",\n        config=\"genes.csv\",\n        reference=\"genome.fasta\",\n    output:\n        html=\"{sample}_genefuse_report.html\",\n        json=\"{sample}_genefuse_report.json\",\n        fusions=\"{sample}_fusions.txt\",\n    log:\n        \"logs/{sample}_genefuse.log\",\n    params:\n        # optional parameters\n        extra=\"\",\n    threads:1\n    wrapper:\n        \"master/bio/genefuse\"\n"
    },
    {
      "name": "genomecov_bam",
      "input": {
        "default": "bam_input/{sample}.sorted.bam"
      },
      "output": {
        "default": "genomecov_bam/{sample}.genomecov"
      },
      "log": {
        "default": "logs/genomecov_bam/{sample}.log"
      },
      "params": {
        "default": "-bg"
      },
      "wrapper": {
        "default": "master/bio/bedtools/genomecov"
      },
      "input_types": [
        "BED/GFF/VCF files grouped by chromosome and genome file (`genome file format <https://bedtools.readthedocs.io/en/latest/content/general-usage.html#genome-file-format>`_) OR",
        "BAM files sorted by position.",
        {
          "ref": "Path to genome file, this must come after the other files"
        }
      ],
      "output_types": [
        "genomecov (.genomecov)"
      ],
      "rule": "rule genomecov_bam:\n    input:\n        \"bam_input/{sample}.sorted.bam\"\n    output:\n        \"genomecov_bam/{sample}.genomecov\"\n    log:\n        \"logs/genomecov_bam/{sample}.log\"\n    params:\n        \"-bg\"  # optional parameters\n    wrapper:\n        \"master/bio/bedtools/genomecov\"\n\nrule genomecov_bed:\n    input:\n        # for genome file format please see:\n        # https://bedtools.readthedocs.io/en/latest/content/general-usage.html#genome-file-format\n        bed=\"bed_input/{sample}.sorted.bed\",\n        ref=\"bed_input/genome_file\"\n    output:\n        \"genomecov_bed/{sample}.genomecov\"\n    log:\n        \"logs/genomecov_bed/{sample}.log\"\n    params:\n        \"-bg\"  # optional parameters\n    wrapper:\n        \"master/bio/bedtools/genomecov\"\n"
    },
    {
      "name": "genomepy",
      "input": {},
      "output": {
        "default": "multiext('{assembly}/{assembly}', '.fa', '.fa.fai', '.fa.sizes', '.gaps.bed', '.annotation.gtf', '.blacklist.bed')"
      },
      "log": {
        "default": "logs/genomepy_{assembly}.log"
      },
      "params": {
        "provider": "ucsc"
      },
      "wrapper": {
        "default": "master/bio/genomepy"
      },
      "input_types": "undefined",
      "output_types": "Always outputs {assembly}/{assembly}.fa, {assembly}/{assembly}.fa.fai, {assembly}/{assembly}.gaps.bed and {assembly}/{assembly}.fa.sizes.\nCan output annotation: {assembly}/{assembly}.annotation.gtf or blacklist: {assembly}/{assembly}.blacklist.bed, depending on the assembly,\nand whether or not it is specified as output.\n",
      "rule": "rule genomepy:\n    output:\n        multiext(\n            \"{assembly}/{assembly}\",\n            \".fa\",\n            \".fa.fai\",\n            \".fa.sizes\",\n            \".gaps.bed\",\n            \".annotation.gtf\",\n            \".blacklist.bed\",\n        ),\n    log:\n        \"logs/genomepy_{assembly}.log\",\n    params:\n        provider=\"ucsc\",  # optional, defaults to ucsc. Choose from ucsc, ensembl, and ncbi\n    cache: \"omit-software\"  # mark as eligible for between workflow caching\n    wrapper:\n        \"master/bio/genomepy\"\n"
    },
    {
      "name": "genomescope",
      "input": {
        "hist": "{sample}.hist"
      },
      "output": {
        "default": "multiext('{sample}/', 'linear_plot.png', 'log_plot.png', 'model.txt', 'progress.txt', 'SIMULATED_testing.tsv', 'summary.txt', 'transformed_linear_plot.png', 'transformed_log_plot.png')"
      },
      "log": {
        "default": "logs/genomescope/{sample}.log"
      },
      "params": {
        "extra": "--kmer_length 32 --testing"
      },
      "wrapper": {
        "default": "master/bio/genomescope"
      },
      "input_types": [
        "kmer histogram"
      ],
      "output_types": [
        "inferred genome characteristics and plots"
      ],
      "rule": "rule genomescope:\n    input:\n        hist=\"{sample}.hist\",\n    output:\n        multiext(\n            \"{sample}/\",\n            \"linear_plot.png\",\n            \"log_plot.png\",\n            \"model.txt\",\n            \"progress.txt\",\n            \"SIMULATED_testing.tsv\",\n            \"summary.txt\",\n            \"transformed_linear_plot.png\",\n            \"transformed_log_plot.png\",\n        ),\n    log:\n        \"logs/genomescope/{sample}.log\",\n    params:\n        extra=\"--kmer_length 32 --testing\",\n    wrapper:\n        \"master/bio/genomescope\"\n"
    },
    {
      "name": "genomics_db_import",
      "input": {
        "gvcfs": [
          "calls/a.g.vcf.gz",
          "calls/b.g.vcf.gz"
        ]
      },
      "output": {
        "db": "directory('db')"
      },
      "log": {
        "default": "logs/gatk/genomicsdbimport.log"
      },
      "params": {
        "intervals": "ref",
        "db_action": "create",
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/genomicsdbimport"
      },
      "input_types": [
        "GVCF files of multiple samples"
      ],
      "output_types": [
        "A GenomicsDB workspace"
      ],
      "rule": "rule genomics_db_import:\n    input:\n        gvcfs=[\"calls/a.g.vcf.gz\", \"calls/b.g.vcf.gz\"],\n    output:\n        db=directory(\"db\"),\n    log:\n        \"logs/gatk/genomicsdbimport.log\",\n    params:\n        intervals=\"ref\",\n        db_action=\"create\",  # optional\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    threads: 2\n    resources:\n        mem_mb=lambda wildcards, input: max([input.size_mb * 1.6, 200]),\n    wrapper:\n        \"master/bio/gatk/genomicsdbimport\"\n"
    },
    {
      "name": "genotype_gvcfs",
      "input": {
        "gvcfs": [
          "calls/a.g.vcf",
          "calls/b.g.vcf"
        ],
        "ref": "genome.fasta"
      },
      "output": {
        "gvcf": "calls/all.g.vcf"
      },
      "log": {
        "default": "logs/gatk/combinegvcfs.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/combinegvcfs"
      },
      "input_types": [
        "GVCF files of multiple samples"
      ],
      "output_types": [
        "Combined GVCF"
      ],
      "rule": "rule genotype_gvcfs:\n    input:\n        gvcfs=[\"calls/a.g.vcf\", \"calls/b.g.vcf\"],\n        ref=\"genome.fasta\",\n    output:\n        gvcf=\"calls/all.g.vcf\",\n    log:\n        \"logs/gatk/combinegvcfs.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/combinegvcfs\"\n"
    },
    {
      "name": "get_annotation",
      "input": {},
      "output": {
        "default": "refs/annotation.gtf"
      },
      "log": {
        "default": "logs/get_annotation.log"
      },
      "params": {
        "species": "homo_sapiens",
        "release": "105",
        "build": "GRCh37",
        "flavor": ""
      },
      "wrapper": {
        "default": "master/bio/reference/ensembl-annotation"
      },
      "input_types": "undefined",
      "output_types": [
        "Ensemble GTF or GFF3 anotation file"
      ],
      "rule": "rule get_annotation:\n    output:\n        \"refs/annotation.gtf\",\n    params:\n        species=\"homo_sapiens\",\n        release=\"105\",\n        build=\"GRCh37\",\n        flavor=\"\",  # optional, e.g. chr_patch_hapl_scaff, see Ensembl FTP.\n        # branch=\"plants\",  # optional: specify branch\n    log:\n        \"logs/get_annotation.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-annotation\"\n\n\nrule get_annotation_gz:\n    output:\n        \"refs/annotation.gtf.gz\",\n    params:\n        species=\"homo_sapiens\",\n        release=\"105\",\n        build=\"GRCh37\",\n        flavor=\"\",  # optional, e.g. chr_patch_hapl_scaff, see Ensembl FTP.\n        # branch=\"plants\",  # optional: specify branch\n    log:\n        \"logs/get_annotation.log\",\n    params:\n        url=\"http://ftp.ensembl.org/pub\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-annotation\"\n"
    },
    {
      "name": "get_fasta",
      "input": {},
      "output": {
        "default": "test.fasta"
      },
      "log": {
        "default": "logs/get_fasta.log"
      },
      "params": {
        "id": "KY785484",
        "db": "nuccore",
        "format": "fasta",
        "mode": null
      },
      "wrapper": {
        "default": "master/bio/entrez/efetch"
      },
      "input_types": "undefined",
      "output_types": [
        "Any format supported by efetch"
      ],
      "rule": "rule get_fasta:\n    output:\n        \"test.fasta\",\n    log:\n        \"logs/get_fasta.log\",\n    params:\n        id=\"KY785484\",\n        db=\"nuccore\",\n        format=\"fasta\",\n        # optional mode\n        mode=None,\n    wrapper:\n        \"master/bio/entrez/efetch\"\n"
    },
    {
      "name": "get_fastq_pe",
      "input": {},
      "output": {
        "default": "data/pe/{accession}_1.fastq"
      },
      "log": {
        "default": "logs/pe/{accession}.log"
      },
      "params": {
        "extra": "--skip-technical"
      },
      "wrapper": {
        "default": "master/bio/sra-tools/fasterq-dump"
      },
      "input_types": "undefined",
      "output_types": [
        "fastq files for R1 and R2 reads"
      ],
      "rule": "rule get_fastq_pe:\n    output:\n        # the wildcard name must be accession, pointing to an SRA number\n        \"data/pe/{accession}_1.fastq\",\n        \"data/pe/{accession}_2.fastq\",\n    log:\n        \"logs/pe/{accession}.log\"\n    params:\n        extra=\"--skip-technical\"\n    threads: 6  # defaults to 6\n    wrapper:\n        \"master/bio/sra-tools/fasterq-dump\"\n\n\nrule get_fastq_pe_gz:\n    output:\n        # the wildcard name must be accession, pointing to an SRA number\n        \"data/pe/{accession}_1.fastq.gz\",\n        \"data/pe/{accession}_2.fastq.gz\",\n    log:\n        \"logs/pe/{accession}.gz.log\"\n    params:\n        extra=\"--skip-technical\"\n    threads: 6  # defaults to 6\n    wrapper:\n        \"master/bio/sra-tools/fasterq-dump\"\n\n\nrule get_fastq_pe_bz2:\n    output:\n        # the wildcard name must be accession, pointing to an SRA number\n        \"data/pe/{accession}_1.fastq.bz2\",\n        \"data/pe/{accession}_2.fastq.bz2\",\n    log:\n        \"logs/pe/{accession}.bz2.log\"\n    params:\n        extra=\"--skip-technical\"\n    threads: 6  # defaults to 6\n    wrapper:\n        \"master/bio/sra-tools/fasterq-dump\"\n\n\nrule get_fastq_se:\n    output:\n        \"data/se/{accession}.fastq\"\n    log:\n        \"logs/se/{accession}.log\"\n    params:\n        extra=\"--skip-technical\"\n    threads: 6\n    wrapper:\n        \"master/bio/sra-tools/fasterq-dump\"\n\n\nrule get_fastq_se_gz:\n    output:\n        \"data/se/{accession}.fastq.gz\"\n    log:\n        \"logs/se/{accession}.gz.log\"\n    params:\n        extra=\"--skip-technical\"\n    threads: 6\n    wrapper:\n        \"master/bio/sra-tools/fasterq-dump\"\n\n\nrule get_fastq_se_bz2:\n    output:\n        \"data/se/{accession}.fastq.bz2\"\n    log:\n        \"logs/se/{accession}.bz2.log\"\n    params:\n        extra=\"--skip-technical\"\n    threads: 6\n    wrapper:\n        \"master/bio/sra-tools/fasterq-dump\"\n"
    },
    {
      "name": "get_genome",
      "input": {},
      "output": {
        "default": "refs/genome.fasta"
      },
      "log": {
        "default": "logs/get_genome.log"
      },
      "params": {
        "species": "saccharomyces_cerevisiae",
        "datatype": "dna",
        "build": "R64-1-1",
        "release": "98"
      },
      "wrapper": {
        "default": "master/bio/reference/ensembl-sequence"
      },
      "input_types": "undefined",
      "output_types": [
        "fasta file"
      ],
      "rule": "rule get_genome:\n    output:\n        \"refs/genome.fasta\",\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        datatype=\"dna\",\n        build=\"R64-1-1\",\n        release=\"98\",\n    log:\n        \"logs/get_genome.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-sequence\"\n\n\nrule get_genome_gzipped:\n    output:\n        \"refs/genome.fa.gz\",\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        datatype=\"dna\",\n        build=\"R64-1-1\",\n        release=\"98\",\n    log:\n        \"logs/get_genome.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-sequence\"\n\n\nrule get_single_chromosome:\n    output:\n        \"refs/chr2.fasta\",\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        datatype=\"dna\",\n        build=\"R64-1-1\",\n        release=\"101\",\n        chromosome=[\"II\"],  # optional: restrict to one or multiple chromosomes, for multiple see below\n        # branch=\"plants\",  # optional: specify branch\n    log:\n        \"logs/get_genome.log\",\n    params:\n        url=\"http://ftp.ensembl.org/pub\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-sequence\"\n\nrule get_multiple_chromosome:\n    output:\n        \"refs/chr6_and_chr1.fasta\",\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        datatype=\"dna\",\n        build=\"R64-1-1\",\n        release=\"113\",\n        chromosome=[\"VI\", \"I\"],  # optional: restrict to one or multiple chromosomes\n        # branch=\"plants\",  # optional: specify branch\n    log:\n        \"logs/get_genome.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-sequence\"\n\n\nrule get_multiple_chromosomes_gzipped:\n    output:\n        \"refs/chr6_and_chr1.fa.gz\",\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        datatype=\"dna\",\n        build=\"R64-1-1\",\n        release=\"113\",\n        chromosome=[\"VI\", \"I\"],  # optional: restrict to one or multiple chromosomes\n        # branch=\"plants\",  # optional: specify branch\n    log:\n        \"logs/get_genome.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-sequence\"\n"
    },
    {
      "name": "get_regulatory_features_gff3_gz",
      "input": {},
      "output": {
        "default": "resources/regulatory_features.gff3.gz"
      },
      "log": {
        "default": "logs/get_regulatory_features.log"
      },
      "params": {
        "species": "homo_sapiens",
        "release": "112",
        "build": "GRCh38"
      },
      "wrapper": {
        "default": "master/bio/reference/ensembl-regulation"
      },
      "input_types": "undefined",
      "output_types": [
        "Ensembl GFF anotation file for regulatory features."
      ],
      "rule": "rule get_regulatory_features_gff3_gz:\n    output:\n        \"resources/regulatory_features.gff3.gz\", # presence of .gz determines if downloaded is kept compressed\n    params:\n        species=\"homo_sapiens\", # for available species, release and build, search via \"Regulation (GFF)\" column at: https://www.ensembl.org/info/data/ftp/index.html\n        release=\"112\",\n        build=\"GRCh38\",\n    log:\n        \"logs/get_regulatory_features.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs); for data downloads, software does not affect the resulting data\n    wrapper:\n        \"master/bio/reference/ensembl-regulation\"\n\n\nrule get_regulatory_features_grch37_gff:\n    output:\n        \"resources/regulatory_features.gff\",\n    params:\n        species=\"homo_sapiens\",\n        release=\"112\",\n        build=\"GRCh37\",\n    log:\n        \"logs/get_regulatory_features.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs); for data downloads, software does not affect the resulting data\n    wrapper:\n        \"master/bio/reference/ensembl-regulation\"\n\n\nrule get_regulatory_features_mouse_gff_gz:\n    output:\n        \"resources/regulatory_features.mouse.gff.gz\",\n    params:\n        species=\"mus_musculus\",\n        release=\"98\",\n        build=\"GRCm39\",\n    log:\n        \"logs/get_regulatory_features.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs); for data downloads, software does not affect the resulting data\n    wrapper:\n        \"master/bio/reference/ensembl-regulation\"\n"
    },
    {
      "name": "get_variation",
      "input": {},
      "output": {
        "vcf": "refs/variation.vcf.gz"
      },
      "log": {
        "default": "logs/get_variation.log"
      },
      "params": {
        "species": "saccharomyces_cerevisiae",
        "release": "98",
        "build": "R64-1-1",
        "type": "all",
        "url": "http://ftp.ensembl.org/pub"
      },
      "wrapper": {
        "default": "master/bio/reference/ensembl-variation"
      },
      "input_types": "undefined",
      "output_types": [
        "VCF file"
      ],
      "rule": "rule get_variation:\n    # Optional: add fai as input to get VCF with annotated contig lengths (as required by GATK)\n    # and properly sorted VCFs.\n    # input:\n    #     fai=\"refs/genome.fasta.fai\"\n    output:\n        vcf=\"refs/variation.vcf.gz\",\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        release=\"98\",  # releases <98 are unsupported\n        build=\"R64-1-1\",\n        type=\"all\",  # one of \"all\", \"somatic\", \"structural_variation\"\n        # chromosome=\"21\", # optionally constrain to chromosome, only supported for homo_sapiens\n        # branch=\"plants\",  # optional: specify branch\n    params:\n        url=\"http://ftp.ensembl.org/pub\",\n    log:\n        \"logs/get_variation.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/reference/ensembl-variation\"\n"
    },
    {
      "name": "get_vep_cache",
      "input": {},
      "output": {
        "default": "directory('resources/vep/cache')"
      },
      "log": {
        "default": "logs/vep/cache.log"
      },
      "params": {
        "species": "saccharomyces_cerevisiae",
        "build": "R64-1-1",
        "release": "98"
      },
      "wrapper": {
        "default": "master/bio/vep/cache"
      },
      "input_types": "undefined",
      "output_types": [
        "directory to store the VEP cache"
      ],
      "rule": "rule get_vep_cache:\n    output:\n        directory(\"resources/vep/cache\"),\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        build=\"R64-1-1\",\n        release=\"98\",\n    log:\n        \"logs/vep/cache.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/vep/cache\"\n\n\nrule get_indexed_vep_cache:\n    output:\n        directory(\"resources/vep/indexed_cache\"),\n    params:\n        species=\"saccharomyces_cerevisiae\",\n        build=\"R64-1-1\",\n        release=\"98\",\n        indexed=True,\n    log:\n        \"logs/vep/indexed_cache.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/vep/cache\"\n\n\nrule get_vep_cache_ebi:\n    output:\n        directory(\"resources/vep/cache_ebi\"),\n    params:\n        url=\"ftp://ftp.ebi.ac.uk/ensemblgenomes/pub/plants\",\n        species=\"cyanidioschyzon_merolae\",\n        build=\"ASM9120v1\",\n        release=\"58\",\n    log:\n        \"logs/vep/cache_ebi.log\",\n    cache: \"omit-software\"  # save space and time with between workflow caching (see docs)\n    wrapper:\n        \"master/bio/vep/cache\"\n"
    },
    {
      "name": "gfatools_stat",
      "input": {
        "default": "{sample}.gfa"
      },
      "output": {
        "default": "{sample}.stat"
      },
      "log": {
        "default": "logs/{sample}.stat.log"
      },
      "params": {
        "command": "stat"
      },
      "wrapper": {
        "default": "master/bio/gfatools"
      },
      "input_types": [
        "GFA file"
      ],
      "output_types": [
        "GFA/stats/FAS/BED/ASM/SQL/TXT (depends on command)"
      ],
      "rule": "rule gfatools_stat:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.stat\",\n    log:\n        \"logs/{sample}.stat.log\",\n    params:\n        command=\"stat\",\n    wrapper:\n        \"master/bio/gfatools\"\n\n\nrule gfatools_gfa2fa:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.fas\",\n    log:\n        \"logs/{sample}.gfa2fa.log\",\n    params:\n        command=\"gfa2fa\",\n        extra=\"-l 90\",\n    wrapper:\n        \"master/bio/gfatools\"\n\n\nrule gfatools_gfa2bed:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.bed\",\n    log:\n        \"logs/{sample}.gfa2bed.log\",\n    params:\n        command=\"gfa2bed\",\n    wrapper:\n        \"master/bio/gfatools\"\n\n\nrule gfatools_blacklist:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.blacklist\",\n    log:\n        \"logs/{sample}.blacklist.log\",\n    params:\n        command=\"blacklist\",\n        extra=\"-l 100\",\n    wrapper:\n        \"master/bio/gfatools\"\n\n\nrule gfatools_bubble:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.bubble\",\n    log:\n        \"logs/{sample}.bubble.log\",\n    params:\n        command=\"bubble\",\n    wrapper:\n        \"master/bio/gfatools\"\n\n\nrule gfatools_asm:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.asm\",\n    log:\n        \"logs/{sample}.asm.log\",\n    params:\n        command=\"asm\",\n        extra=\"-u\",\n    wrapper:\n        \"master/bio/gfatools\"\n\n\nrule gfatools_sql:\n    input:\n        \"{sample}.gfa\",\n    output:\n        \"{sample}.sql\",\n    log:\n        \"logs/{sample}.sql.log\",\n    params:\n        command=\"sql\",\n    wrapper:\n        \"master/bio/gfatools\"\n"
    },
    {
      "name": "gridss_setupreference",
      "input": {
        "reference": "reference/genome.fasta"
      },
      "output": {
        "idx": "multiext('reference/genome.fasta', '.amb', '.ann', '.bwt', '.dict', '.fai', '.pac', '.sa')"
      },
      "log": {
        "default": "log/gridss/setupreference.log"
      },
      "params": {
        "extra": "--jvmheap 1g"
      },
      "wrapper": {
        "default": "master/bio/gridss/setupreference"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule gridss_setupreference:\n    input:\n        reference=\"reference/genome.fasta\",\n    output:\n        idx=multiext(\"reference/genome.fasta\", \".amb\", \".ann\", \".bwt\", \".dict\", \".fai\", \".pac\", \".sa\")\n    params:\n        extra=\"--jvmheap 1g\"\n    log:\n        \"log/gridss/setupreference.log\"\n    wrapper:\n        \"master/bio/gridss/setupreference\""
    },
    {
      "name": "gtfToGenePred",
      "input": {
        "default": "annotation.gtf"
      },
      "output": {
        "default": "annotation.genePred"
      },
      "log": {
        "default": "logs/gtfToGenePred.log"
      },
      "params": {
        "extra": "-genePredExt"
      },
      "wrapper": {
        "default": "master/bio/ucsc/gtfToGenePred"
      },
      "input_types": [
        "GTF file"
      ],
      "output_types": [
        "genePred table"
      ],
      "rule": "rule gtfToGenePred:\n    input:\n        # annotations containing gene, transcript, exon, etc. data in GTF format\n        \"annotation.gtf\",\n    output:\n        \"annotation.genePred\",\n    log:\n        \"logs/gtfToGenePred.log\",\n    params:\n        extra=\"-genePredExt\",  # optional parameters to pass to gtfToGenePred\n    wrapper:\n        \"master/bio/ucsc/gtfToGenePred\"\n\n\nrule gtfToGenePred_CollectRnaSeqMetrics:\n    input:\n        # annotations containing gene, transcript, exon, etc. data in GTF format\n        \"annotation.gtf\",\n    output:\n        \"annotation.PicardCollectRnaSeqMetrics.genePred\",\n    log:\n        \"logs/gtfToGenePred.PicardCollectRnaSeqMetrics.log\",\n    params:\n        convert_out=\"PicardCollectRnaSeqMetrics\",\n        extra=\"-genePredExt -geneNameAsName2\",  # optional parameters to pass to gtfToGenePred\n    wrapper:\n        \"master/bio/ucsc/gtfToGenePred\"\n"
    },
    {
      "name": "haplotype_caller",
      "input": {
        "vcf": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf')",
        "ref": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/human_g1k_v37.20.21.fasta')",
        "fai": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/human_g1k_v37.20.21.fasta.fai')",
        "dict": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/human_g1k_v37.20.21.dict')",
        "mills": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf')",
        "mills_idx": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx')",
        "omni": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf')",
        "omni_idx": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx')",
        "g1k": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf')",
        "g1k_idx": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx')",
        "dbsnp": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf')",
        "dbsnp_idx": "storage.http('https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx')"
      },
      "output": {
        "vcf": "calls/all.recal.vcf",
        "idx": "calls/all.recal.vcf.idx",
        "tranches": "calls/all.tranches"
      },
      "log": {
        "default": "logs/gatk/variantrecalibrator.log"
      },
      "params": {
        "mode": "SNP",
        "resources": {
          "mills": {
            "known": false,
            "training": true,
            "truth": true,
            "prior": 15.0
          },
          "omni": {
            "known": false,
            "training": true,
            "truth": false,
            "prior": 12.0
          },
          "g1k": {
            "known": false,
            "training": true,
            "truth": false,
            "prior": 10.0
          },
          "dbsnp": {
            "known": true,
            "training": false,
            "truth": false,
            "prior": 2.0
          }
        },
        "annotation": [
          "MQ",
          "QD",
          "SB"
        ],
        "extra": "--max-gaussians 2"
      },
      "wrapper": {
        "default": "master/bio/gatk/variantrecalibrator"
      },
      "input_types": [
        "VCF file"
      ],
      "output_types": [
        ".recal file",
        ".tranches file"
      ],
      "rule": "\nrule haplotype_caller:\n    input:\n        vcf=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf\"\n        ),\n        ref=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/human_g1k_v37.20.21.fasta\"\n        ),\n        fai=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/human_g1k_v37.20.21.fasta.fai\"\n        ),\n        dict=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/human_g1k_v37.20.21.dict\"\n        ),\n        mills=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf\"\n        ),\n        mills_idx=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx\"\n        ),\n        omni=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf\"\n        ),\n        omni_idx=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx\"\n        ),\n        g1k=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf\"\n        ),\n        g1k_idx=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx\"\n        ),\n        dbsnp=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf\"\n        ),\n        dbsnp_idx=storage.http(\n            \"https://github.com/broadinstitute/gatk/raw/4.2.5.0/src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx\"\n        ),\n    output:\n        vcf=\"calls/all.recal.vcf\",\n        idx=\"calls/all.recal.vcf.idx\",\n        tranches=\"calls/all.tranches\",\n    log:\n        \"logs/gatk/variantrecalibrator.log\",\n    params:\n        mode=\"SNP\",  # set mode, must be either SNP, INDEL or BOTH\n        resources={\n            \"mills\": {\"known\": False, \"training\": True, \"truth\": True, \"prior\": 15.0},\n            \"omni\": {\"known\": False, \"training\": True, \"truth\": False, \"prior\": 12.0},\n            \"g1k\": {\"known\": False, \"training\": True, \"truth\": False, \"prior\": 10.0},\n            \"dbsnp\": {\"known\": True, \"training\": False, \"truth\": False, \"prior\": 2.0},\n        },\n        annotation=[\"MQ\", \"QD\", \"SB\"],\n        extra=\"--max-gaussians 2\",  # optional\n    threads: 1\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/variantrecalibrator\"\n"
    },
    {
      "name": "hifiasm",
      "input": {
        "fasta": [
          "reads/HiFi_dataset_01.fasta.gz",
          "reads/HiFi_dataset_02.fasta.gz"
        ]
      },
      "output": {
        "default": "multiext('hifiasm/{sample}.', 'a_ctg.gfa', 'a_ctg.lowQ.bed', 'a_ctg.noseq.gfa', 'p_ctg.gfa', 'p_ctg.lowQ.bed', 'p_ctg.noseq.gfa', 'p_utg.gfa', 'p_utg.lowQ.bed', 'p_utg.noseq.gfa', 'r_utg.gfa', 'r_utg.lowQ.bed', 'r_utg.noseq.gfa')"
      },
      "log": {
        "default": "logs/hifiasm/{sample}.log"
      },
      "params": {
        "extra": "--primary -f 37 -l 1 -s 0.75 -O 1"
      },
      "wrapper": {
        "default": "master/bio/hifiasm"
      },
      "input_types": [
        "PacBio HiFi reads (fasta)",
        "Hi-C reads (fastq; optional)"
      ],
      "output_types": [
        "assembly graphs (GFA)"
      ],
      "rule": "rule hifiasm:\n    input:\n        fasta=[\n            \"reads/HiFi_dataset_01.fasta.gz\",\n            \"reads/HiFi_dataset_02.fasta.gz\",\n        ],\n    # optional\n    # hic1=\"reads/Hi-C_dataset_R1.fastq.gz\",\n    # hic2=\"reads/Hi-C_dataset_R2.fastq.gz\",\n    output:\n        multiext(\n            \"hifiasm/{sample}.\",\n            \"a_ctg.gfa\",\n            \"a_ctg.lowQ.bed\",\n            \"a_ctg.noseq.gfa\",\n            \"p_ctg.gfa\",\n            \"p_ctg.lowQ.bed\",\n            \"p_ctg.noseq.gfa\",\n            \"p_utg.gfa\",\n            \"p_utg.lowQ.bed\",\n            \"p_utg.noseq.gfa\",\n            \"r_utg.gfa\",\n            \"r_utg.lowQ.bed\",\n            \"r_utg.noseq.gfa\",\n        ),\n    log:\n        \"logs/hifiasm/{sample}.log\",\n    params:\n        extra=\"--primary -f 37 -l 1 -s 0.75 -O 1\",\n    threads: 2\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/hifiasm\"\n"
    },
    {
      "name": "hisat2_align",
      "input": {
        "reads": [
          "reads/{sample}_R1.fastq",
          "reads/{sample}_R2.fastq"
        ],
        "idx": "multiext('index/ref', '.1.ht2', '.2.ht2', '.3.ht2', '.4.ht2', '.5.ht2', '.6.ht2', '.7.ht2', '.8.ht2')"
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/hisat2_align_{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/hisat2/align"
      },
      "input_types": [
        {
          "reads": "either 1 or 2 FASTQ files with reads"
        },
        {
          "idx": "index files"
        }
      ],
      "output_types": [
        "bam file with mapped reads"
      ],
      "rule": "rule hisat2_align:\n    input:\n        reads=[\"reads/{sample}_R1.fastq\", \"reads/{sample}_R2.fastq\"],\n        idx=multiext(\n            \"index/ref\",\n            \".1.ht2\",\n            \".2.ht2\",\n            \".3.ht2\",\n            \".4.ht2\",\n            \".5.ht2\",\n            \".6.ht2\",\n            \".7.ht2\",\n            \".8.ht2\",\n        ),\n    output:\n        \"mapped/{sample}.bam\",\n    log:\n        \"logs/hisat2_align_{sample}.log\",\n    params:\n        extra=\"\",\n    threads: 2\n    wrapper:\n        \"master/bio/hisat2/align\"\n\n\nrule hisat2_alignL:\n    input:\n        reads=[\"reads/{sample}_R1.fastq\", \"reads/{sample}_R2.fastq\"],\n        idx=multiext(\n            \"index/ref\",\n            \".1.ht2l\",\n            \".2.ht2l\",\n            \".3.ht2l\",\n            \".4.ht2l\",\n            \".5.ht2l\",\n            \".6.ht2l\",\n            \".7.ht2l\",\n            \".8.ht2l\",\n        ),\n    output:\n        \"mappedL/{sample}.bam\",\n    log:\n        \"logs/hisat2_alignL_{sample}.log\",\n    params:\n        extra=\"\",\n    threads: 2\n    wrapper:\n        \"master/bio/hisat2/align\"\n"
    },
    {
      "name": "hisat2_index",
      "input": {
        "fasta": "{genome}.fasta"
      },
      "output": {
        "default": "multiext('hisat2_index/{genome}', '.1.ht2', '.2.ht2', '.3.ht2', '.4.ht2', '.5.ht2', '.6.ht2', '.7.ht2', '.8.ht2')"
      },
      "log": {
        "default": "logs/hisat2_index_{genome}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/hisat2/index"
      },
      "input_types": [
        {
          "sequence": "list of FASTA files to index"
        }
      ],
      "output_types": [
        "List of output index file paths. The `hisat2-build` command generates 8 files with `.ht2` extension for small genomes and `.ht2l` for large genomes (greater than ~4 Gbp). This is usually handled automatically, but you must use the correct output file extension (`.ht2` or `.ht2l`) to match your genome size. If needed, you can force the creation of a large index by adding the parameter `extra = \"--large-index\"`, and use `.ht2l` as the output file extension."
      ],
      "rule": "rule hisat2_index:\n    input:\n        fasta=\"{genome}.fasta\",\n    output:\n        multiext(\n            \"hisat2_index/{genome}\",\n            \".1.ht2\",\n            \".2.ht2\",\n            \".3.ht2\",\n            \".4.ht2\",\n            \".5.ht2\",\n            \".6.ht2\",\n            \".7.ht2\",\n            \".8.ht2\",\n        ),\n    params:\n        extra=\"\",\n    log:\n        \"logs/hisat2_index_{genome}.log\",\n    threads: 2\n    wrapper:\n        \"master/bio/hisat2/index\"\n\n\nrule hisat2_indexL:\n    input:\n        fasta=\"{genome}.fasta\",\n    output:\n        multiext(\n            \"hisat2_index/{genome}\",\n            \".1.ht2l\",\n            \".2.ht2l\",\n            \".3.ht2l\",\n            \".4.ht2l\",\n            \".5.ht2l\",\n            \".6.ht2l\",\n            \".7.ht2l\",\n            \".8.ht2l\",\n        ),\n    params:\n        extra=\"--large-index\",\n    log:\n        \"logs/hisat2_indexL_{genome}.log\",\n    threads: 2\n    wrapper:\n        \"master/bio/hisat2/index\"\n"
    },
    {
      "name": "hmmbuild_profile",
      "input": {
        "default": "test-profile.sto"
      },
      "output": {
        "default": "test-profile.hmm"
      },
      "log": {
        "default": "logs/test-profile-hmmbuild.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/hmmer/hmmbuild"
      },
      "input_types": [
        "sequence alignment file"
      ],
      "output_types": [
        "profile hmm"
      ],
      "rule": "rule hmmbuild_profile:\n    input:\n        \"test-profile.sto\"\n    output:\n        \"test-profile.hmm\"\n    log:\n        \"logs/test-profile-hmmbuild.log\"\n    params:\n        extra=\"\",\n    threads: 4\n    wrapper:\n        \"master/bio/hmmer/hmmbuild\"\n"
    },
    {
      "name": "hmmpress_profile",
      "input": {
        "default": "test-profile.hmm"
      },
      "output": {
        "default": "test-profile.hmm.h3f"
      },
      "log": {
        "default": "logs/hmmpress.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/hmmer/hmmpress"
      },
      "input_types": [
        "hmm database"
      ],
      "output_types": [
        "binary format hmm database (for hmmscan)"
      ],
      "rule": "rule hmmpress_profile:\n    input:\n        \"test-profile.hmm\"\n    output:\n        \"test-profile.hmm.h3f\",\n        \"test-profile.hmm.h3i\",\n        \"test-profile.hmm.h3m\",\n        \"test-profile.hmm.h3p\"\n    log:\n        \"logs/hmmpress.log\"\n    params:\n        extra=\"\",\n    threads: 4\n    wrapper:\n        \"master/bio/hmmer/hmmpress\"\n"
    },
    {
      "name": "hmmscan_profile",
      "input": {
        "fasta": "test-protein.fa",
        "profile": "test-profile.hmm.h3f"
      },
      "output": {
        "tblout": "test-prot-tbl.txt",
        "domtblout": "test-prot-domtbl.txt",
        "pfamtblout": "test-prot-pfamtbl.txt",
        "outfile": "test-prot-out.txt"
      },
      "log": {
        "default": "logs/hmmscan.log"
      },
      "params": {
        "evalue_threshold": 1e-05,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/hmmer/hmmscan"
      },
      "input_types": [
        "protein sequence file (fasta)",
        "database hmm files"
      ],
      "output_types": [
        "matches to hmm files"
      ],
      "rule": "rule hmmscan_profile:\n    input:\n        fasta=\"test-protein.fa\",\n        profile=\"test-profile.hmm.h3f\",\n    output:\n        # only one of these is required\n        tblout=\"test-prot-tbl.txt\", # save parseable table of per-sequence hits to file <f>\n        domtblout=\"test-prot-domtbl.txt\", # save parseable table of per-domain hits to file <f>\n        pfamtblout=\"test-prot-pfamtbl.txt\", # save table of hits and domains to file, in Pfam format <f>\n        outfile=\"test-prot-out.txt\", # Direct the main human-readable output to a file <f> instead of the default stdout.\n    log:\n        \"logs/hmmscan.log\"\n    params:\n        evalue_threshold=0.00001,\n        # if bitscore threshold provided, hmmscan will use that instead\n        #score_threshold=50,\n        extra=\"\",\n    threads: 4\n    wrapper:\n        \"master/bio/hmmer/hmmscan\"\n"
    },
    {
      "name": "hmmsearch_profile",
      "input": {
        "fasta": "test-protein.fa",
        "profile": "test-profile.hmm.h3f"
      },
      "output": {
        "tblout": "test-prot-tbl.txt",
        "domtblout": "test-prot-domtbl.txt",
        "alignment_hits": "test-prot-alignment-hits.txt",
        "outfile": "test-prot-out.txt"
      },
      "log": {
        "default": "logs/hmmsearch.log"
      },
      "params": {
        "evalue_threshold": 1e-05,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/hmmer/hmmsearch"
      },
      "input_types": [
        "hmm profile(s)",
        "sequence database"
      ],
      "output_types": [
        "matches between sequences and hmm profiles"
      ],
      "rule": "rule hmmsearch_profile:\n    input:\n        fasta=\"test-protein.fa\",\n        profile=\"test-profile.hmm.h3f\",\n    output:\n        # only one of these is required\n        tblout=\"test-prot-tbl.txt\", # save parseable table of per-sequence hits to file <f>\n        domtblout=\"test-prot-domtbl.txt\", # save parseable table of per-domain hits to file <f>\n        alignment_hits=\"test-prot-alignment-hits.txt\", # Save a multiple alignment of all significant hits (those satisfying inclusion thresholds) to the file <f>\n        outfile=\"test-prot-out.txt\", # Direct the main human-readable output to a file <f> instead of the default stdout. \n    log:\n        \"logs/hmmsearch.log\"\n    params:\n        evalue_threshold=0.00001,\n        # if bitscore threshold provided, hmmsearch will use that instead\n        #score_threshold=50,\n        extra=\"\",\n    threads: 4\n    wrapper:\n        \"master/bio/hmmer/hmmsearch\"\n"
    },
    {
      "name": "homer_annotatepeaks",
      "input": {
        "peaks": "peaks_refs/{sample}.peaks",
        "genome": "peaks_refs/gene.fasta",
        "motif_files": "peaks_refs/motives.txt",
        "nearest_peak": "peaks_refs/b.peaks"
      },
      "output": {
        "annotations": "{sample}_annot.txt",
        "matrix": "multiext('{sample}', '.count.matrix.txt', '.ratio.matrix.txt', '.logPvalue.matrix.txt', '.stats.txt')",
        "mfasta": "{sample}_motif.fasta",
        "mbed": "{sample}_motif.bed",
        "mlogic": "{sample}_motif.logic"
      },
      "log": {
        "default": "logs/annotatePeaks/{sample}.log"
      },
      "params": {
        "mode": "",
        "extra": "-gid"
      },
      "wrapper": {
        "default": "master/bio/homer/annotatePeaks"
      },
      "input_types": [
        "peak or BED file",
        "various optional input files, i.e. gtf, bedGraph, wiggle"
      ],
      "output_types": [
        "annotation file (.txt)",
        "various optional output files"
      ],
      "rule": "rule homer_annotatepeaks:\n    input:\n        peaks=\"peaks_refs/{sample}.peaks\",\n        genome=\"peaks_refs/gene.fasta\",\n        # optional input files\n        # gtf=\"\", # implicitly sets the -gtf flag\n        # gene=\"\", # implicitly sets the -gene flag for gene data file to add gene expression or other data types\n        motif_files=\"peaks_refs/motives.txt\", # implicitly sets the -m flag\n        # filter_motiv=\"\", # implicitly sets the -fm flag\n        # center=\"\",  # implicitly sets the -center flag\n        nearest_peak=\"peaks_refs/b.peaks\", # implicitly sets the -p flag\n        # tag=\"\",  # implicitly sets the -d flag for tagDirectories\n        # vcf=\"\", # implicitly sets the -vcf flag\n        # bed_graph=\"\", # implicitly sets the -bedGraph flag\n        # wig=\"\", # implicitly sets the -wig flag\n        # map=\"\", # implicitly sets the -map flag\n        # cmp_genome=\"\", # implicitly sets the -cmpGenome flag\n        # cmp_Liftover=\"\", # implicitly sets the -cmpLiftover flag\n        # advanced_annotation=\"\"  # optional, implicitly sets the -ann flag, see http://homer.ucsd.edu/homer/ngs/advancedAnnotation.html\n    output:\n        annotations=\"{sample}_annot.txt\",\n        # optional output, implicitly sets the -matrix flag, requires motif_files as input\n        matrix=multiext(\"{sample}\",\n                        \".count.matrix.txt\",\n                        \".ratio.matrix.txt\",\n                        \".logPvalue.matrix.txt\",\n                        \".stats.txt\"\n                        ),\n        # optional output, implicitly sets the -mfasta flag, requires motif_files as input\n        mfasta=\"{sample}_motif.fasta\",\n        # # optional output, implicitly sets the -mbed flag, requires motif_files as input\n        mbed=\"{sample}_motif.bed\",\n        # # optional output, implicitly sets the -mlogic flag, requires motif_files as input\n        mlogic=\"{sample}_motif.logic\"\n    threads:\n        2\n    params:\n        mode=\"\", # add tss, tts or rna mode and options here, i.e. \"tss mm8\"\n        extra=\"-gid\"  # optional params, see http://homer.ucsd.edu/homer/ngs/annotation.html\n    log:\n        \"logs/annotatePeaks/{sample}.log\"\n    wrapper:\n        \"master/bio/homer/annotatePeaks\"\n"
    },
    {
      "name": "homer_findPeaks",
      "input": {
        "tag": "tagDir/{sample}",
        "control": "tagDir/control"
      },
      "output": {
        "default": "{sample}_peaks.txt"
      },
      "log": {
        "default": "logs/findPeaks/{sample}.log"
      },
      "params": {
        "style": "histone",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/homer/findPeaks"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule homer_findPeaks:\n    input:\n        # tagDirectory of sample\n        tag=\"tagDir/{sample}\",\n        # tagDirectory of control background sample - optional\n        control=\"tagDir/control\"\n    output:\n        \"{sample}_peaks.txt\"\n    params:\n        # one of 7 basic modes of operation, see homer manual\n        style=\"histone\",\n        extra=\"\"  # optional params, see homer manual\n    log:\n        \"logs/findPeaks/{sample}.log\"\n    wrapper:\n        \"master/bio/homer/findPeaks\"\n"
    },
    {
      "name": "homer_getDifferentialPeaks",
      "input": {
        "peaks": "{sample}.peaks.bed",
        "first": "tagDir/{sample}",
        "second": "tagDir/second"
      },
      "output": {
        "default": "{sample}_diffPeaks.txt"
      },
      "log": {
        "default": "logs/diffPeaks/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/homer/getDifferentialPeaks"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule homer_getDifferentialPeaks:\n    input:\n        # peak/bed file to be tested\n        peaks=\"{sample}.peaks.bed\",\n        # tagDirectory of first sample\n        first=\"tagDir/{sample}\",\n        # tagDirectory of sample to compare\n        second=\"tagDir/second\"\n    output:\n        \"{sample}_diffPeaks.txt\"\n    params:\n        extra=\"\"  # optional params, see homer manual\n    log:\n        \"logs/diffPeaks/{sample}.log\"\n    wrapper:\n        \"master/bio/homer/getDifferentialPeaks\"\n"
    },
    {
      "name": "homer_makeTagDir",
      "input": {
        "bam": "{sample}.bam"
      },
      "output": {
        "default": "directory('tagDir/{sample}')"
      },
      "log": {
        "default": "logs/makeTagDir/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/homer/makeTagDirectory"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule homer_makeTagDir:\n    input:\n        # input bam, can be one or a list of files\n        bam=\"{sample}.bam\",\n    output:\n        directory(\"tagDir/{sample}\")\n    params:\n        extra=\"\"  # optional params, see homer manual\n    log:\n        \"logs/makeTagDir/{sample}.log\"\n    wrapper:\n        \"master/bio/homer/makeTagDirectory\"\n"
    },
    {
      "name": "homer_mergePeaks",
      "input": {
        "default": "peaks/{sample1}.peaks"
      },
      "output": {
        "default": "merged/{sample1}_{sample2}.peaks"
      },
      "log": {
        "default": "logs/mergePeaks/{sample1}_{sample2}.log"
      },
      "params": {
        "extra": "-d given"
      },
      "wrapper": {
        "default": "master/bio/homer/mergePeaks"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule homer_mergePeaks:\n    input:\n        # input peak files\n        \"peaks/{sample1}.peaks\",\n        \"peaks/{sample2}.peaks\"\n    output:\n        \"merged/{sample1}_{sample2}.peaks\"\n    params:\n        extra=\"-d given\"  # optional params, see homer manual\n    log:\n        \"logs/mergePeaks/{sample1}_{sample2}.log\"\n    wrapper:\n        \"master/bio/homer/mergePeaks\"\n"
    },
    {
      "name": "ids",
      "input": {
        "vgs": "c.vg"
      },
      "output": {
        "mod": "graph/c_mod.vg"
      },
      "log": {
        "default": "logs/vg/ids/c.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/vg/ids"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule ids:\n    input:\n        vgs=\"c.vg\"\n    output:\n        mod=\"graph/c_mod.vg\"\n    log:\n        \"logs/vg/ids/c.log\"\n    wrapper:\n        \"master/bio/vg/ids\"\n"
    },
    {
      "name": "igv_report",
      "input": {
        "fasta": "minigenome.fa",
        "vcf": "variants.vcf",
        "tracks": [
          "alignments.bam"
        ]
      },
      "output": {
        "default": "igv-report.html"
      },
      "log": {
        "default": "logs/igv-report.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/igv-reports"
      },
      "input_types": [
        {
          "vcf": "Variants file in VCF/VCF.gz/BCF"
        },
        {
          "fasta": "Reference genome file in FASTA"
        },
        {
          "tracks": "additional tracks"
        }
      ],
      "output_types": [
        "IGV report in HTML format."
      ],
      "rule": "rule igv_report:\n    input:\n        fasta=\"minigenome.fa\",\n        vcf=\"variants.vcf\",\n        # any number of additional optional tracks, see igv-reports manual\n        tracks=[\"alignments.bam\"]\n    output:\n        \"igv-report.html\"\n    params:\n        extra=\"\"  # optional params, see igv-reports manual\n    log:\n        \"logs/igv-report.log\"\n    wrapper:\n        \"master/bio/igv-reports\"\n"
    },
    {
      "name": "indelrealigner",
      "input": {
        "bam": "{sample}.bam",
        "bai": "{sample}.bai",
        "ref": "genome.fasta",
        "fai": "genome.fasta.fai",
        "dict": "genome.dict",
        "known": "dbsnp.vcf.gz",
        "known_idx": "dbsnp.vcf.gz.tbi",
        "target_intervals": "{sample}.intervals"
      },
      "output": {
        "bam": "{sample}.realigned.bam",
        "bai": "{sample}.realigned.bai"
      },
      "log": {
        "default": "logs/gatk3/indelrealigner/{sample}.log"
      },
      "params": {
        "extra": "--defaultBaseQualities 20 --filter_reads_with_N_cigar"
      },
      "wrapper": {
        "default": "master/bio/gatk3/indelrealigner"
      },
      "input_types": [
        "bam file",
        "reference genome",
        "target intervals to realign",
        "bed file (optional)",
        "vcf files known variation (optional)"
      ],
      "output_types": [
        "indel realigned bam file",
        "indel realigned bai file (optional)",
        "temp dir (optional)"
      ],
      "rule": "rule indelrealigner:\n    input:\n        bam=\"{sample}.bam\",\n        bai=\"{sample}.bai\",\n        ref=\"genome.fasta\",\n        fai=\"genome.fasta.fai\",\n        dict=\"genome.dict\",\n        known=\"dbsnp.vcf.gz\",\n        known_idx=\"dbsnp.vcf.gz.tbi\",\n        target_intervals=\"{sample}.intervals\",\n    output:\n        bam=\"{sample}.realigned.bam\",\n        bai=\"{sample}.realigned.bai\",\n    log:\n        \"logs/gatk3/indelrealigner/{sample}.log\",\n    params:\n        extra=\"--defaultBaseQualities 20 --filter_reads_with_N_cigar\",  # optional\n    threads: 16\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk3/indelrealigner\"\n"
    },
    {
      "name": "infernal_cmpress",
      "input": {
        "default": "test-covariance-model.cm"
      },
      "output": {
        "default": "test-covariance-model.cm.i1i"
      },
      "log": {
        "default": "logs/cmpress.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/infernal/cmpress"
      },
      "input_types": [
        "RNA covariance models (CMs)"
      ],
      "output_types": [
        "CMs prepared for use with cmscan"
      ],
      "rule": "rule infernal_cmpress:\n    input:\n        \"test-covariance-model.cm\"\n    output:\n        \"test-covariance-model.cm.i1i\",\n        \"test-covariance-model.cm.i1f\",\n        \"test-covariance-model.cm.i1m\",\n        \"test-covariance-model.cm.i1p\"\n    log:\n        \"logs/cmpress.log\"\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/infernal/cmpress\"\n"
    },
    {
      "name": "insert_size",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "txt": "stats/{sample}.isize.txt",
        "pdf": "stats/{sample}.isize.pdf"
      },
      "log": {
        "default": "logs/picard/insert_size/{sample}.log"
      },
      "params": {
        "extra": "--VALIDATION_STRINGENCY LENIENT --METRIC_ACCUMULATION_LEVEL null --METRIC_ACCUMULATION_LEVEL SAMPLE"
      },
      "wrapper": {
        "default": "master/bio/picard/collectinsertsizemetrics"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        {
          "txt": "textual representation of metrics"
        },
        {
          "pdf": "insert size histogram"
        }
      ],
      "rule": "rule insert_size:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        txt=\"stats/{sample}.isize.txt\",\n        pdf=\"stats/{sample}.isize.pdf\",\n    log:\n        \"logs/picard/insert_size/{sample}.log\",\n    params:\n        # optional parameters (e.g. relax checks as below)\n        extra=\"--VALIDATION_STRINGENCY LENIENT --METRIC_ACCUMULATION_LEVEL null --METRIC_ACCUMULATION_LEVEL SAMPLE\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/collectinsertsizemetrics\"\n"
    },
    {
      "name": "jackhmmer",
      "input": {
        "db": "test-protein.fa",
        "query": "query.fa"
      },
      "output": {
        "hits_tbl": "test-prot-tbl.txt",
        "hits_aln": "test-prot-alignment-hits.sto",
        "dom_tbl": "test-prot-domtbl.txt",
        "summary": "test-prot-out1.txt"
      },
      "log": {
        "default": "logs/jackhmmer.log"
      },
      "params": {
        "extra": "-E 0.001 --F1=0.005"
      },
      "wrapper": {
        "default": "master/bio/hmmer/jackhmmer"
      },
      "input_types": [
        {
          "query": "query file in FASTA format"
        },
        {
          "db": "database file in FASTA format."
        }
      ],
      "output_types": [
        {
          "hits_tbl": "table of per-sequence hits (optional)"
        },
        {
          "hits_aln": "multiple sequence alignment (MSA) in Stockholm format of all significant hits (optional)"
        },
        {
          "dom_tbl": "table of per-domain hits (optional)"
        },
        {
          "summary": "human-readable output (optional)"
        }
      ],
      "rule": "rule jackhmmer:\n    input:\n        db=\"test-protein.fa\",\n        query=\"query.fa\"\n    output:\n        hits_tbl=\"test-prot-tbl.txt\",\n        hits_aln=\"test-prot-alignment-hits.sto\",\n        dom_tbl=\"test-prot-domtbl.txt\",\n        summary=\"test-prot-out1.txt\",\n    log:\n        \"logs/jackhmmer.log\"\n    params:\n       # Additional flags can be set using extra, for example:\n       extra=\"-E 0.001 --F1=0.005\"\n    threads: 4\n    wrapper:\n        \"master/bio/hmmer/jackhmmer\"\n"
    },
    {
      "name": "jannovar",
      "input": {
        "vcf": "{sample}.vcf",
        "pedigree": "pedigree_ar.ped"
      },
      "output": {
        "default": "jannovar/{sample}.vcf.gz"
      },
      "log": {
        "default": "logs/jannovar/{sample}.log"
      },
      "params": {
        "database": "hg19_small.ser",
        "extra": "--show-all"
      },
      "wrapper": {
        "default": "master/bio/jannovar"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule jannovar:\n    input:\n        vcf=\"{sample}.vcf\",\n        pedigree=\"pedigree_ar.ped\" # optional, contains familial relationships\n    output:\n        \"jannovar/{sample}.vcf.gz\"\n    log:\n        \"logs/jannovar/{sample}.log\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mg}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb = 1024,\n    params:\n        database=\"hg19_small.ser\", # path to jannovar reference dataset\n        extra=\"--show-all\"         # optional parameters\n    wrapper:\n        \"master/bio/jannovar\"\n"
    },
    {
      "name": "jellyfish_count",
      "input": {
        "default": "{prefix}.fasta"
      },
      "output": {
        "default": "{prefix}.jf"
      },
      "log": {
        "default": "{prefix}.jf.log"
      },
      "params": {
        "kmer_length": 21,
        "size": "1G",
        "extra": "--canonical"
      },
      "wrapper": {
        "default": "master/bio/jellyfish/count"
      },
      "input_types": [
        "sequence FASTA file"
      ],
      "output_types": [
        "kmer count jf file"
      ],
      "rule": "rule jellyfish_count:\n    input:\n        \"{prefix}.fasta\",\n    output:\n        \"{prefix}.jf\",\n    log:\n        \"{prefix}.jf.log\",\n    params:\n        kmer_length=21,\n        size=\"1G\",\n        extra=\"--canonical\",\n    threads: 2\n    wrapper:\n        \"master/bio/jellyfish/count\"\n"
    },
    {
      "name": "jellyfish_dump",
      "input": {
        "default": "{prefix}.jf"
      },
      "output": {
        "default": "{prefix}.dump"
      },
      "log": {
        "default": "{prefix}.log"
      },
      "params": {
        "extra": "-c -t"
      },
      "wrapper": {
        "default": "master/bio/jellyfish/dump"
      },
      "input_types": [
        "kmer count jf file"
      ],
      "output_types": [
        "dump of kmer counts"
      ],
      "rule": "rule jellyfish_dump:\n    input:\n        \"{prefix}.jf\",\n    output:\n        \"{prefix}.dump\",\n    log:\n        \"{prefix}.log\",\n    params:\n        extra=\"-c -t\",\n    wrapper:\n        \"master/bio/jellyfish/dump\"\n"
    },
    {
      "name": "jellyfish_histo",
      "input": {
        "default": "{prefix}.jf"
      },
      "output": {
        "default": "{prefix}.histo"
      },
      "log": {
        "default": "{prefix}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/jellyfish/histo"
      },
      "input_types": [
        "kmer count jf file"
      ],
      "output_types": [
        "kmer histogram file"
      ],
      "rule": "rule jellyfish_histo:\n    input:\n        \"{prefix}.jf\",\n    output:\n        \"{prefix}.histo\",\n    log:\n        \"{prefix}.log\",\n    threads: 2\n    wrapper:\n        \"master/bio/jellyfish/histo\"\n"
    },
    {
      "name": "jellyfish_merge",
      "input": {
        "default": "a.jf"
      },
      "output": {
        "default": "ab.jf"
      },
      "log": {
        "default": "ab.jf.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/jellyfish/merge"
      },
      "input_types": [
        "multiple jf kmer count files"
      ],
      "output_types": [
        "merged jf kmer count file"
      ],
      "rule": "rule jellyfish_merge:\n    input:\n        \"a.jf\",\n        \"b.jf\",\n    output:\n        \"ab.jf\",\n    log:\n        \"ab.jf.log\",\n    wrapper:\n        \"master/bio/jellyfish/merge\"\n"
    },
    {
      "name": "kallisto_index",
      "input": {
        "fasta": "{transcriptome}.fasta"
      },
      "output": {
        "index": "{transcriptome}.idx"
      },
      "log": {
        "default": "logs/kallisto_index_{transcriptome}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/kallisto/index"
      },
      "input_types": [
        {
          "fasta": "FASTA file to index"
        }
      ],
      "output_types": [
        {
          "index": "indexed file"
        }
      ],
      "rule": "rule kallisto_index:\n    input:\n        fasta=\"{transcriptome}.fasta\",\n    output:\n        index=\"{transcriptome}.idx\",\n    params:\n        extra=\"\",  # optional parameters\n    log:\n        \"logs/kallisto_index_{transcriptome}.log\",\n    threads: 1\n    wrapper:\n        \"master/bio/kallisto/index\"\n"
    },
    {
      "name": "kallisto_quant",
      "input": {
        "fastq": [
          "reads/{exp}_R1.fastq",
          "reads/{exp}_R2.fastq"
        ],
        "index": "index/transcriptome.idx"
      },
      "output": {
        "default": "directory('quant_results_{exp}')"
      },
      "log": {
        "default": "logs/kallisto_quant_{exp}.log"
      },
      "params": {
        "extra": "--verbose"
      },
      "wrapper": {
        "default": "master/bio/kallisto/quant"
      },
      "input_types": [
        {
          "fastq": "FASTQ file(s)"
        },
        {
          "index": "indexed file"
        }
      ],
      "output_types": [
        "directory with results"
      ],
      "rule": "rule kallisto_quant:\n    input:\n        fastq=[\"reads/{exp}_R1.fastq\", \"reads/{exp}_R2.fastq\"],\n        index=\"index/transcriptome.idx\",\n    output:\n        directory(\"quant_results_{exp}\"),\n    log:\n        \"logs/kallisto_quant_{exp}.log\",\n    params:\n        extra=\"--verbose\",\n    threads: 1\n    wrapper:\n        \"master/bio/kallisto/quant\"\n"
    },
    {
      "name": "kmers",
      "input": {
        "vgs": "c.vg"
      },
      "output": {
        "kmers": "kmers/c.kmers"
      },
      "log": {
        "default": "logs/vg/kmers/c.log"
      },
      "params": {
        "default": "-gBk 16 -H 1000000000 -T 1000000001"
      },
      "wrapper": {
        "default": "master/bio/vg/kmers"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule kmers:\n    input:\n        vgs=\"c.vg\"\n    output:\n        kmers=\"kmers/c.kmers\"\n    params:\n       \"-gBk 16 -H 1000000000 -T 1000000001\"\n    log:\n        \"logs/vg/kmers/c.log\"\n    threads:\n        4\n    wrapper:\n        \"master/bio/vg/kmers\"\n"
    },
    {
      "name": "lastal_nucl_x_nucl",
      "input": {
        "data": "test-transcript.fa",
        "lastdb": "test-transcript.fa.prj"
      },
      "output": {
        "maf": "test-transcript.maf"
      },
      "log": {
        "default": "logs/lastal/test.log"
      },
      "params": {
        "D_length": 1000000,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/last/lastal"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule lastal_nucl_x_nucl:\n    input:\n        data=\"test-transcript.fa\",\n        lastdb=\"test-transcript.fa.prj\"\n    output:\n        # only one of these outputs is allowed\n        maf=\"test-transcript.maf\",\n        #tab=\"test-transcript.tab\",\n        #blasttab=\"test-transcript.blasttab\",\n        #blasttabplus=\"test-transcript.blasttabplus\",\n    params:\n        #Report alignments that are expected by chance at most once per LENGTH query letters. By default, LAST reports alignments that are expected by chance at most once per million query letters (for a given database). http://last.cbrc.jp/doc/last-evalues.html\n        D_length=1000000,\n        extra=\"\"\n    log:\n        \"logs/lastal/test.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/last/lastal\"\n\nrule lastal_nucl_x_prot:\n    input:\n        data=\"test-transcript.fa\",\n        lastdb=\"test-protein.fa.prj\"\n    output:\n        # only one of these outputs is allowed\n        maf=\"test-tr-x-prot.maf\"\n        #tab=\"test-tr-x-prot.tab\",\n        #blasttab=\"test-tr-x-prot.blasttab\",\n        #blasttabplus=\"test-tr-x-prot.blasttabplus\",\n    params:\n        frameshift_cost=15, #Align DNA queries to protein reference sequences using specified frameshift cost. 15 is reasonable. Special case, -F0 means DNA-versus-protein alignment without frameshifts, which is faster.) \n        extra=\"\",\n    log:\n        \"logs/lastal/test.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/last/lastal\"\n"
    },
    {
      "name": "lastdb_transcript",
      "input": {
        "default": "test-transcript.fa"
      },
      "output": {
        "default": "test-transcript.fa.prj"
      },
      "log": {
        "default": "logs/lastdb/test-transcript.log"
      },
      "params": {
        "protein_input": false,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/last/lastdb"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule lastdb_transcript:\n    input:\n        \"test-transcript.fa\"\n    output:\n        \"test-transcript.fa.prj\",\n    params:\n        protein_input=False,\n        extra=\"\"\n    log:\n        \"logs/lastdb/test-transcript.log\"\n    wrapper:\n        \"master/bio/last/lastdb\"\n\nrule lastdb_protein:\n    input:\n        \"test-protein.fa\"\n    output:\n        \"test-protein.fa.prj\",\n    params:\n        protein_input=True,\n        extra=\"\"\n    log:\n        \"logs/lastdb/test-protein.log\"\n    wrapper:\n        \"master/bio/last/lastdb\"\n\n"
    },
    {
      "name": "learn_pe",
      "input": {
        "default": "expand('results/dada2/model_{orientation}.RDS', orientation=[1, 2])"
      },
      "output": {},
      "log": {},
      "params": {},
      "wrapper": {},
      "input_types": [
        "A list of quality filtered and trimmed forward FASTQ files (potentially compressed)"
      ],
      "output_types": [
        {
          "err": "RDS file with the stored error model"
        },
        {
          "plot": "plot observed vs estimated errors rates"
        }
      ],
      "rule": "rule learn_pe:\n    # Run twice dada2_learn_errors: on forward and on reverse reads\n    input: expand(\"results/dada2/model_{orientation}.RDS\", orientation=[1,2])\n\nrule dada2_learn_errors:\n    input:\n    # Quality filtered and trimmed forward FASTQ files (potentially compressed) \n        expand(\"filtered/{sample}.{{orientation}}.fastq.gz\", sample=[\"a\",\"b\"])\n    output:\n        err=\"results/dada2/model_{orientation}.RDS\",#\u00a0save the error model\n        plot=\"reports/dada2/errors_{orientation}.png\",# plot observed and estimated rates\n    # Even though this is an R wrapper, use named arguments in Python syntax\n    # here, to specify extra parameters. Python booleans (`arg1=True`, `arg2=False`)\n    # and lists (`list_arg=[]`) are automatically converted to R.\n    # For a named list as an extra named argument, use a python dict\n    #   (`named_list={name1=arg1}`).\n    #params:\n    #    randomize=True\n    log:\n        \"logs/dada2/learn-errors/learn-errors_{orientation}.log\"\n    threads: 1 # set desired number of threads here\n    wrapper:\n        \"master/bio/dada2/learn-errors\"\n"
    },
    {
      "name": "liftoff",
      "input": {
        "ref": "{ref}.fasta.gz",
        "tgt": "{tgt}.fasta.gz",
        "ann": "{ann}.gff.gz"
      },
      "output": {
        "main": "{ref}_{ann}_{tgt}.gff3",
        "unmapped": "{ref}_{ann}_{tgt}.unmapped.txt"
      },
      "log": {
        "default": "logs/liftoff_{ref}_{ann}_{tgt}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/liftoff"
      },
      "input_types": [
        "A fasta formatted reference genome file",
        "A fasta formatted target genome file",
        "A GFF/GTF formatted annotations file"
      ],
      "output_types": [
        "A GFF formatted file containing the mapped annotations",
        "A GFF formatted file containing the unmapped annotations"
      ],
      "rule": "rule liftoff:\n    input:\n        ref=\"{ref}.fasta.gz\",\n        tgt=\"{tgt}.fasta.gz\",\n        ann=\"{ann}.gff.gz\",\n    output:\n        main=\"{ref}_{ann}_{tgt}.gff3\",\n        unmapped=\"{ref}_{ann}_{tgt}.unmapped.txt\",\n    log:\n        \"logs/liftoff_{ref}_{ann}_{tgt}.log\",\n    params:\n        extra=\"\",\n    threads: 1\n    wrapper:\n        \"master/bio/liftoff\"\n"
    },
    {
      "name": "lofreq",
      "input": {
        "bam": "data/{sample}.bam",
        "bai": "data/{sample}.bai"
      },
      "output": {
        "default": "calls/{sample}.vcf"
      },
      "log": {
        "default": "logs/lofreq_call/{sample}.log"
      },
      "params": {
        "ref": "data/genome.fasta",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/lofreq/call"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule lofreq:\n    input:\n        bam=\"data/{sample}.bam\",\n        bai=\"data/{sample}.bai\"\n    output:\n        \"calls/{sample}.vcf\"\n    log:\n        \"logs/lofreq_call/{sample}.log\"\n    params:\n        ref=\"data/genome.fasta\",\n        extra=\"\"\n    threads: 8\n    wrapper:\n        \"master/bio/lofreq/call\"\n"
    },
    {
      "name": "lofreq_uniform_indelqual",
      "input": {
        "bam": "data/{sample}.bam"
      },
      "output": {
        "default": "out/indelqual/{sample}.uindel.bam"
      },
      "log": {
        "default": "logs/{sample}.uindel.log"
      },
      "params": {
        "extra": "-u 15"
      },
      "wrapper": {
        "default": "master/bio/lofreq/indelqual"
      },
      "input_types": [
        "bam file that will have variants called",
        "reference genome of bam (optional unless --dindel specified)"
      ],
      "output_types": [
        "bam file with indel qualities added"
      ],
      "rule": "rule lofreq_uniform_indelqual:\n    input:\n        bam=\"data/{sample}.bam\",\n    output:\n        \"out/indelqual/{sample}.uindel.bam\"\n    log:\n        \"logs/{sample}.uindel.log\"\n    params:\n        extra=\"-u 15\"\n    threads: 8\n    wrapper:\n        \"master/bio/lofreq/indelqual\"\n\nrule lofreq_dindel_indelqual:\n    input:\n        bam=\"data/{sample}.bam\",\n        ref=\"data/hg38_chr21.fa\"\n    output:\n        \"out/indelqual/{sample}.dindel.bam\"\n    log:\n        \"logs/{sample}.dindel.log\"\n    params:\n        extra=\"--dindel\"\n    threads: 8\n    wrapper:\n        \"master/bio/lofreq/indelqual\"\n"
    },
    {
      "name": "manta",
      "input": {
        "ref": "human_g1k_v37_decoy.small.fasta",
        "samples": [
          "mapped/a.bam"
        ],
        "index": [
          "mapped/a.bam.bai"
        ],
        "bed": "test.bed.gz"
      },
      "output": {
        "vcf": "results/out.bcf",
        "idx": "results/out.bcf.csi",
        "cand_indel_vcf": "results/small_indels.vcf.gz",
        "cand_indel_idx": "results/small_indels.vcf.gz.tbi",
        "cand_sv_vcf": "results/cand_sv.vcf.gz",
        "cand_sv_idx": "results/cand_sv.vcf.gz.tbi"
      },
      "log": {
        "default": "logs/manta.log"
      },
      "params": {
        "extra_cfg": "",
        "extra_run": ""
      },
      "wrapper": {
        "default": "master/bio/manta"
      },
      "input_types": [
        "BAM/CRAM file(s)",
        "reference genome",
        "BED file (optional)"
      ],
      "output_types": [
        "SVs and indels scored and genotyped under a diploid model (diploidSV.vcf.gz).",
        "Unfiltered SV and indel candidates (candidateSV.vcf.gz).",
        "Subset of the previous file containing only simple insertion and deletion variants less than the minimum scored variant size (candidateSmallIndels.vcf.gz)."
      ],
      "rule": "rule manta:\n    input:\n        ref=\"human_g1k_v37_decoy.small.fasta\",\n        samples=[\"mapped/a.bam\"],\n        index=[\"mapped/a.bam.bai\"],\n        bed=\"test.bed.gz\",  # optional\n    output:\n        vcf=\"results/out.bcf\",\n        idx=\"results/out.bcf.csi\",\n        cand_indel_vcf=\"results/small_indels.vcf.gz\",\n        cand_indel_idx=\"results/small_indels.vcf.gz.tbi\",\n        cand_sv_vcf=\"results/cand_sv.vcf.gz\",\n        cand_sv_idx=\"results/cand_sv.vcf.gz.tbi\",\n    params:\n        extra_cfg=\"\",  # optional\n        extra_run=\"\",  # optional\n    log:\n        \"logs/manta.log\",\n    threads: 2\n    resources:\n        mem_mb=4096,\n    wrapper:\n        \"master/bio/manta\"\n"
    },
    {
      "name": "mapdamage2",
      "input": {
        "ref": "genome.fasta",
        "bam": "mapped/{sample}.bam"
      },
      "output": {
        "log": "results/{sample}/Runtime_log.txt",
        "GtoA3p": "results/{sample}/3pGtoA_freq.txt",
        "CtoT5p": "results/{sample}/5pCtoT_freq.txt",
        "dnacomp": "results/{sample}/dnacomp.txt",
        "frag_misincorp": "results/{sample}/Fragmisincorporation_plot.pdf",
        "len": "results/{sample}/Length_plot.pdf",
        "lg_dist": "results/{sample}/lgdistribution.txt",
        "misincorp": "results/{sample}/misincorporation.txt"
      },
      "log": {
        "default": "logs/{sample}/mapdamage2.log"
      },
      "params": {
        "extra": "--no-stats"
      },
      "wrapper": {
        "default": "master/bio/mapdamage2"
      },
      "input_types": [
        "reference genome",
        "SAM/BAM/CRAM alignemnt"
      ],
      "output_types": [
        {
          "Runtime_log.txt": "log file with a summary of command lines used and timestamps."
        },
        "Fragmisincorporation_plot.pdf, a pdf file that displays both fragmentation and misincorporation patterns.",
        "Length_plot.pdf, a pdf file that displays length distribution of singleton reads per strand and cumulative frequencies of C->T at 5'-end and G->A at 3'-end are also displayed per strand.",
        "misincorporation.txt, contains a table with occurrences for each type of mutations and relative positions from the reads ends.",
        "5pCtoT_freq.txt, contains frequencies of Cytosine to Thymine mutations per position from the 5'-ends.",
        "3pGtoA_freq.txt, contains frequencies of Guanine to Adenine mutations per position from the 3'-ends.",
        "dnacomp.txt, contains a table of the reference genome base composition per position, inside reads and adjacent regions.",
        "lgdistribution.txt, contains a table with read length distributions per strand.",
        "Stats_out_MCMC_hist.pdf, MCMC histogram for the damage parameters and log likelihood.",
        "Stats_out_MCMC_iter.csv, values for the damage parameters and log likelihood in each MCMC iteration.",
        "Stats_out_MCMC_trace.pdf, a MCMC trace plot for the damage parameters and log likelihood.",
        "Stats_out_MCMC_iter_summ_stat.csv, summary statistics for the damage parameters estimated posterior distributions.",
        "Stats_out_post_pred.pdf, empirical misincorporation frequency and posterior predictive intervals from the fitted model.",
        "Stats_out_MCMC_correct_prob.csv, position specific probability of a C->T and G->A misincorporation is due to damage.",
        "dnacomp_genome.txt, contains the global reference genome base composition (computed by seqtk).",
        "Rescaled BAM file, where likely post-mortem damaged bases have downscaled quality scores."
      ],
      "rule": "rule mapdamage2:\n    input:\n        ref=\"genome.fasta\",\n        bam=\"mapped/{sample}.bam\",\n    output:\n        log=\"results/{sample}/Runtime_log.txt\",  # output folder is infered from this file, so it needs to be the same folder for all output files\n        GtoA3p=\"results/{sample}/3pGtoA_freq.txt\",\n        CtoT5p=\"results/{sample}/5pCtoT_freq.txt\",\n        dnacomp=\"results/{sample}/dnacomp.txt\",\n        frag_misincorp=\"results/{sample}/Fragmisincorporation_plot.pdf\",\n        len=\"results/{sample}/Length_plot.pdf\",\n        lg_dist=\"results/{sample}/lgdistribution.txt\",\n        misincorp=\"results/{sample}/misincorporation.txt\",\n    #   rescaled_bam=\"results/{sample}.rescaled.bam\", # uncomment if you want the rescaled BAM file\n    params:\n        extra=\"--no-stats\",  # optional parameters for mapdamage2 (except -i, -r, -d, --rescale)\n    log:\n        \"logs/{sample}/mapdamage2.log\",\n    threads: 1  # MapDamage2 is not threaded\n    wrapper:\n        \"master/bio/mapdamage2\"\n"
    },
    {
      "name": "mark_duplicates_bamsormadup",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "bam": "dedup/{sample}.bam",
        "index": "dedup/{sample}.bai",
        "metrics": "dedup/{sample}.metrics.txt"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "SO=coordinate"
      },
      "wrapper": {
        "default": "master/bio/biobambam2/bamsormadup"
      },
      "input_types": [
        "Path to SAM/BAM/CRAM file, this must be the first file in the input file list.",
        "Path to reference (for CRAM output)"
      ],
      "output_types": [
        "Path to SAM/BAM/CRAM file with marked duplicates. This must be the fist output file in the output file list.",
        {
          "index": "Path to BAM index file (optional)"
        },
        {
          "metrics": "Path to metrics file (optional)"
        }
      ],
      "rule": "rule mark_duplicates_bamsormadup:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        bam=\"dedup/{sample}.bam\",\n        index=\"dedup/{sample}.bai\",\n        metrics=\"dedup/{sample}.metrics.txt\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"SO=coordinate\",\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/biobambam2/bamsormadup\"\n"
    },
    {
      "name": "mark_duplicates_spark",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "bam": "dedup/{sample}.bam",
        "metrics": "dedup/{sample}.metrics.txt"
      },
      "log": {
        "default": "logs/dedup/{sample}.log"
      },
      "params": {
        "extra": "--remove-sequencing-duplicates",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/markduplicatesspark"
      },
      "input_types": [
        "bam file",
        "reference file"
      ],
      "output_types": [
        "bam file with marked or removed duplicates"
      ],
      "rule": "rule mark_duplicates_spark:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        bam=\"dedup/{sample}.bam\",\n        metrics=\"dedup/{sample}.metrics.txt\",\n    log:\n        \"logs/dedup/{sample}.log\",\n    params:\n        extra=\"--remove-sequencing-duplicates\",  # optional\n        java_opts=\"\",  # optional\n        #spark_runner=\"\",  # optional, local by default\n        #spark_master=\"\",  # optional\n        #spark_extra=\"\", # optional\n    resources:\n        # Memory needs to be at least 471859200 for Spark, so 589824000 when\n        # accounting for default JVM overhead of 20%. We round round to 650M.\n        mem_mb=lambda wildcards, input: max([input.size_mb * 0.25, 650]),\n    threads: 8\n    wrapper:\n        \"master/bio/gatk/markduplicatesspark\"\n"
    },
    {
      "name": "markduplicates_bam",
      "input": {
        "bams": "mapped/{sample}.bam"
      },
      "output": {
        "bam": "dedup/{sample}.bam",
        "metrics": "dedup/{sample}.metrics.txt"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "--REMOVE_DUPLICATES true"
      },
      "wrapper": {
        "default": "master/bio/picard/markduplicates"
      },
      "input_types": [
        "bam/cram file(s)"
      ],
      "output_types": [
        "bam/cram file with marked or removed duplicates"
      ],
      "rule": "rule markduplicates_bam:\n    input:\n        bams=\"mapped/{sample}.bam\",\n    # optional to specify a list of BAMs; this has the same effect\n    # of marking duplicates on separate read groups for a sample\n    # and then merging\n    output:\n        bam=\"dedup/{sample}.bam\",\n        metrics=\"dedup/{sample}.metrics.txt\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"--REMOVE_DUPLICATES true\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/markduplicates\"\n\n\nuse rule markduplicates_bam as markduplicateswithmatecigar_bam with:\n    output:\n        bam=\"dedup/{sample}.matecigar.bam\",\n        idx=\"dedup/{sample}.matecigar.bai\",\n        metrics=\"dedup/{sample}.matecigar.metrics.txt\",\n    log:\n        \"logs/{sample}.matecigar.log\",\n    params:\n        withmatecigar=True,\n        extra=\"--REMOVE_DUPLICATES true\",\n\n\nuse rule markduplicates_bam as markduplicates_sam with:\n    output:\n        bam=\"dedup/{sample}.sam\",\n        metrics=\"dedup/{sample}.metrics.txt\",\n    log:\n        \"logs/{sample}.sam.log\",\n    params:\n        extra=\"--REMOVE_DUPLICATES true\",\n\n\nuse rule markduplicates_bam as markduplicates_cram with:\n    input:\n        bams=\"mapped/{sample}.bam\",\n        ref=\"ref/genome.fasta\",\n    output:\n        bam=\"dedup/{sample}.cram\",\n        idx=\"dedup/{sample}.cram.crai\",\n        metrics=\"dedup/{sample}.metrics.txt\",\n    log:\n        \"logs/{sample}.cram.log\",\n    params:\n        extra=\"--REMOVE_DUPLICATES true\",\n        embed_ref=True,  # set true if the fasta reference should be embedded into the cram\n        withmatecigar=False,\n"
    },
    {
      "name": "mehari_annotate_seqvars_variants_MT",
      "input": {
        "calls": "{prefix}.vcf",
        "ref": "resources/MT.fasta",
        "fai": "resources/MT.fasta.fai",
        "transcript_db": "resources/MT-ND2-GRCh38-ensembl-0.10.3.bin.zst"
      },
      "output": {
        "calls": "{prefix}.annotated.bcf"
      },
      "log": {
        "default": "logs/mehari/mehari_annotate_variants.{prefix}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/mehari/annotate-seqvars"
      },
      "input_types": {
        "calls": "Path to variants (VCF / VCF.gz / BCF)",
        "ref": "Path to reference FASTA (uncompressed).",
        "fai": "Path to reference FAI file.",
        "transcript_db": "Path to mehari transcript database. Needed for annotating SO terms / consequences.",
        "clinvar_db": "Path to mehari clinvar database. Needed for annotating clinvar VCVs.",
        "frequency_db": "Path to mehari frequency database. Needed for annotating frequencies from gnomAD."
      },
      "output_types": {
        "calls": "Path to annotated variants (VCF / VCF.gz / BCF)."
      },
      "rule": "rule mehari_annotate_seqvars_variants_MT:\n    input:\n        calls=\"{prefix}.vcf\",  # .vcf, .vcf.gz or .bcf\n        ref=\"resources/MT.fasta\",  # has to be uncompressed\n        fai=\"resources/MT.fasta.fai\",\n        transcript_db=\"resources/MT-ND2-GRCh38-ensembl-0.10.3.bin.zst\",  # transcript database for SO term / consequence annotation\n        # clinvar_db=\"resources/clinvar.bin.zst\",  # clinvar database for clinvar VCV annotation\n        # frequency_db=\"resources/frequencies.bin.zst\"  # frequencies/gnomad database for frequency annotation\n    output:\n        calls=\"{prefix}.annotated.bcf\",  # .vcf, .vcf.gz or .bcf\n    params:\n        extra=\"\",\n    log:\n        \"logs/mehari/mehari_annotate_variants.{prefix}.log\",\n    wrapper:\n        \"master/bio/mehari/annotate-seqvars\"\n"
    },
    {
      "name": "merge",
      "input": {
        "vgs": [
          "c.vg",
          "x.vg"
        ]
      },
      "output": {
        "merged": "graph/wg.vg"
      },
      "log": {
        "default": "logs/vg/merge/wg.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/vg/merge"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule merge:\n    input:\n        vgs=[\"c.vg\", \"x.vg\"]\n    output:\n        merged=\"graph/wg.vg\"\n    log:\n        \"logs/vg/merge/wg.log\"\n    wrapper:\n        \"master/bio/vg/merge\"\n"
    },
    {
      "name": "merge_bams",
      "input": {
        "default": "expand('mapped/{sample}.bam', sample=['a', 'b'])"
      },
      "output": {
        "default": "merged.bam"
      },
      "log": {
        "default": "logs/picard_mergesamfiles.log"
      },
      "params": {
        "extra": "--VALIDATION_STRINGENCY LENIENT"
      },
      "wrapper": {
        "default": "master/bio/picard/mergesamfiles"
      },
      "input_types": [
        "sam/bam files"
      ],
      "output_types": [
        "merged sam/bam file"
      ],
      "rule": "rule merge_bams:\n    input:\n        expand(\"mapped/{sample}.bam\", sample=[\"a\", \"b\"]),\n    output:\n        \"merged.bam\",\n    log:\n        \"logs/picard_mergesamfiles.log\",\n    params:\n        extra=\"--VALIDATION_STRINGENCY LENIENT\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    threads: 2\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/mergesamfiles\"\n"
    },
    {
      "name": "merge_vcfs",
      "input": {
        "vcfs": [
          "snvs.chr1.vcf",
          "snvs.chr2.vcf"
        ]
      },
      "output": {
        "default": "snvs.vcf"
      },
      "log": {
        "default": "logs/picard/mergevcfs.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/picard/mergevcfs"
      },
      "input_types": [
        "vcf files"
      ],
      "output_types": [
        "merged vcf file"
      ],
      "rule": "rule merge_vcfs:\n    input:\n        vcfs=[\"snvs.chr1.vcf\", \"snvs.chr2.vcf\"],\n    output:\n        \"snvs.vcf\",\n    log:\n        \"logs/picard/mergevcfs.log\",\n    params:\n        extra=\"\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/mergevcfs\"\n"
    },
    {
      "name": "meryl_count",
      "input": {
        "fasta": "{genome}.fasta"
      },
      "output": {
        "default": "directory('{genome}/')"
      },
      "log": {
        "default": "logs/meryl_count/{genome}.log"
      },
      "params": {
        "command": "count",
        "extra": "k=32"
      },
      "wrapper": {
        "default": "master/bio/meryl/count"
      },
      "input_types": [
        "fasta file"
      ],
      "output_types": [
        "meryl database"
      ],
      "rule": "rule meryl_count:\n    input:\n        fasta=\"{genome}.fasta\",\n    output:\n        directory(\"{genome}/\"),\n    log:\n        \"logs/meryl_count/{genome}.log\",\n    params:\n        command=\"count\",\n        extra=\"k=32\",\n    threads: 2\n    resources:\n        mem_mb=2048,\n    wrapper:\n        \"master/bio/meryl/count\"\n"
    },
    {
      "name": "meryl_stats",
      "input": {
        "default": "{genome}"
      },
      "output": {
        "default": "{genome}.stats"
      },
      "log": {
        "default": "logs/meryl_stats/{genome}.log"
      },
      "params": {
        "command": "statistics"
      },
      "wrapper": {
        "default": "master/bio/meryl/stats"
      },
      "input_types": [
        "meryl database(s)"
      ],
      "output_types": [
        "meryl stats (either the kmers, statistics, or histogram)"
      ],
      "rule": "rule meryl_stats:\n    input:\n        \"{genome}\",\n    output:\n        \"{genome}.stats\",\n    log:\n        \"logs/meryl_stats/{genome}.log\",\n    params:\n        command=\"statistics\",\n    wrapper:\n        \"master/bio/meryl/stats\"\n"
    },
    {
      "name": "meryl_union",
      "input": {
        "default": "{genome}"
      },
      "output": {
        "default": "directory('{genome}_union/')"
      },
      "log": {
        "default": "logs/{genome}.union.log"
      },
      "params": {
        "command": "union-sum"
      },
      "wrapper": {
        "default": "master/bio/meryl/sets"
      },
      "input_types": [
        "meryl database(s)"
      ],
      "output_types": [
        "meryl database"
      ],
      "rule": "rule meryl_union:\n    input:\n        \"{genome}\",\n        \"{genome}\",\n    output:\n        directory(\"{genome}_union/\"),\n    log:\n        \"logs/{genome}.union.log\",\n    params:\n        command=\"union-sum\",\n    wrapper:\n        \"master/bio/meryl/sets\"\n\n\nrule meryl_intersect:\n    input:\n        \"{genome}\",\n        \"{genome}\",\n    output:\n        directory(\"{genome}_intersect/\"),\n    log:\n        \"logs/{genome}.intersect.log\",\n    params:\n        command=\"intersect-max\",\n    wrapper:\n        \"master/bio/meryl/sets\"\n\n\nrule meryl_subtract:\n    input:\n        \"{genome}\",\n        \"{genome}\",\n    output:\n        directory(\"{genome}_subtract/\"),\n    log:\n        \"logs/{genome}.subtract.log\",\n    params:\n        command=\"subtract\",\n    wrapper:\n        \"master/bio/meryl/sets\"\n\n\nrule meryl_difference:\n    input:\n        \"{genome}\",\n        \"{genome}\",\n    output:\n        directory(\"{genome}_difference/\"),\n    log:\n        \"logs/{genome}.difference.log\",\n    params:\n        command=\"difference\",\n    wrapper:\n        \"master/bio/meryl/sets\"\n"
    },
    {
      "name": "microphaser_build",
      "input": {
        "ref_peptides": "germline/peptides.fasta"
      },
      "output": {
        "bin": "out/peptides.bin",
        "peptides": "out/peptides.fasta"
      },
      "log": {
        "default": "logs/microphaser/build_reference.log"
      },
      "params": {
        "extra": "--peptide-length 9"
      },
      "wrapper": {
        "default": "master/bio/microphaser/build_reference"
      },
      "input_types": [
        "peptide reference (nucleotide sequences from microphaser germline)"
      ],
      "output_types": [
        "peptide reference in amino acid FASTA format",
        "binary peptide reference for filtering"
      ],
      "rule": "rule microphaser_build:\n    input:\n        # all normal peptides from the complete proteome as nucleotide sequences\n        ref_peptides=\"germline/peptides.fasta\",\n    output:\n        # a binary of the normal peptides amino acid sequences\n        bin=\"out/peptides.bin\",\n        # the amino acid sequences in FASTA format\n        peptides=\"out/peptides.fasta\",\n    log:\n        \"logs/microphaser/build_reference.log\"\n    params:\n        extra=\"--peptide-length 9\",  # optional, desired peptide length in amino acids.\n    wrapper:\n        \"master/bio/microphaser/build_reference\"\n"
    },
    {
      "name": "microphaser_filter",
      "input": {
        "tsv": "somatic/info.tsv",
        "ref_peptides": "germline/peptides.bin"
      },
      "output": {
        "tumor": "out/peptides.mt.fasta",
        "normal": "out/peptides.wt.fasta",
        "tsv": "out/peptides.info.tsv",
        "removed_tsv": "out/peptides.removed.tsv",
        "removed_fasta": "out/peptides.removed.fasta"
      },
      "log": {
        "default": "logs/microphaser/filter.log"
      },
      "params": {
        "extra": "--peptide-length 9"
      },
      "wrapper": {
        "default": "master/bio/microphaser/filter"
      },
      "input_types": [
        "neopeptides fasta (nucleotide sequences from microphaser somatic)",
        "information tsv (from microphaser somatic)",
        "sample-specific normal/wildtype pepetides (binary created using microphaser build)"
      ],
      "output_types": [
        "filtered neopeptides (removed self-identical peptides) in amino acid FASTA format",
        "corresponding normal peptides in amino acid FASTA format",
        "filtered information tsv",
        "self-identical peptides removed from the neopeptide set (tsv)"
      ],
      "rule": "rule microphaser_filter:\n    input:\n        # the info file of the tumor sample to filter\n        tsv=\"somatic/info.tsv\",\n        # All normal peptides to filter against\n        ref_peptides=\"germline/peptides.bin\",\n    output:\n        # the filtered neopeptides\n        tumor=\"out/peptides.mt.fasta\",\n        # the normal peptides matching the filtered neopeptides\n        normal=\"out/peptides.wt.fasta\",\n        # the info data of the filtered neopeptides\n        tsv=\"out/peptides.info.tsv\",\n        # the info data of the removed neopeptides\n        removed_tsv=\"out/peptides.removed.tsv\",\n        # the removed neopeptides\n        removed_fasta=\"out/peptides.removed.fasta\",\n    log:\n        \"logs/microphaser/filter.log\",\n    params:\n        extra=\"--peptide-length 9\",  # optional, desired peptide length in amino acids.\n    wrapper:\n        \"master/bio/microphaser/filter\"\n"
    },
    {
      "name": "microphaser_normal",
      "input": {
        "bam": "mapped/{sample}.sorted.bam",
        "index": "mapped/{sample}.sorted.bam.bai",
        "ref": "genome.fasta",
        "annotation": "genome.gtf",
        "variants": "calls/{sample}.bcf"
      },
      "output": {
        "peptides": "out/{sample}.fasta",
        "tsv": "out/{sample}.tsv"
      },
      "log": {
        "default": "logs/microphaser/somatic/{sample}.log"
      },
      "params": {
        "extra": "--window-len 9"
      },
      "wrapper": {
        "default": "master/bio/microphaser/normal"
      },
      "input_types": [
        "bam file",
        "bcf file",
        "fasta reference",
        "gtf annotation file"
      ],
      "output_types": [
        "sample-specific peptide fasta (nucleotide sequences)"
      ],
      "rule": "rule microphaser_normal:\n    input:\n        bam=\"mapped/{sample}.sorted.bam\",\n        index=\"mapped/{sample}.sorted.bam.bai\",\n        ref=\"genome.fasta\",\n        annotation=\"genome.gtf\",\n        variants=\"calls/{sample}.bcf\",\n    output:\n        # all peptides from the healthy proteome\n        peptides=\"out/{sample}.fasta\",\n        tsv=\"out/{sample}.tsv\",\n    log:\n        \"logs/microphaser/somatic/{sample}.log\",\n    params:\n        extra=\"--window-len 9\",  # optional, desired peptide length in nucleotide bases, e.g. 27 (9 AA) for MHC-I ligands.\n    wrapper:\n        \"master/bio/microphaser/normal\"\n"
    },
    {
      "name": "microphaser_somatic",
      "input": {
        "bam": "mapped/{sample}.sorted.bam",
        "index": "mapped/{sample}.sorted.bam.bai",
        "ref": "genome.fasta",
        "annotation": "genome.gtf",
        "variants": "calls/{sample}.bcf"
      },
      "output": {
        "tumor": "out/{sample}.mt.fasta",
        "normal": "out/{sample}.wt.fasta",
        "tsv": "out/{sample}.info.tsv"
      },
      "log": {
        "default": "logs/microphaser/somatic/{sample}.log"
      },
      "params": {
        "extra": "--window-len 9"
      },
      "wrapper": {
        "default": "master/bio/microphaser/somatic"
      },
      "input_types": [
        "bam file",
        "bcf file",
        "fasta reference",
        "gtf annotation file"
      ],
      "output_types": [
        "mutated peptide fasta (nucleotide sequences)",
        "wildtype peptide fasta (nucleotide sequences)",
        "information tsv"
      ],
      "rule": "rule microphaser_somatic:\n    input:\n        bam=\"mapped/{sample}.sorted.bam\",\n        index=\"mapped/{sample}.sorted.bam.bai\",\n        ref=\"genome.fasta\",\n        annotation=\"genome.gtf\",\n        variants=\"calls/{sample}.bcf\",\n    output:\n        # sequences neopeptides arisen from somatic variants\n        tumor=\"out/{sample}.mt.fasta\",\n        # sequences of the normal, unmutated counterpart to every neopeptide\n        normal=\"out/{sample}.wt.fasta\",\n        # info data of the somatic neopeptides\n        tsv=\"out/{sample}.info.tsv\",\n    log:\n        \"logs/microphaser/somatic/{sample}.log\",\n    params:\n        extra=\"--window-len 9\",  # optional, desired peptide length in nucleotide bases, e.g. 27 (9 AA) for MHC-I ligands.\n    wrapper:\n        \"master/bio/microphaser/somatic\"\n"
    },
    {
      "name": "minimap2_index",
      "input": {
        "target": "target/{input1}.fasta"
      },
      "output": {
        "default": "{input1}.mmi"
      },
      "log": {
        "default": "logs/minimap2_index/{input1}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/minimap2/index"
      },
      "input_types": [
        "reference genome in FASTA format"
      ],
      "output_types": [
        "indexed reference genome"
      ],
      "rule": "rule minimap2_index:\n    input:\n        target=\"target/{input1}.fasta\"\n    output:\n        \"{input1}.mmi\"\n    log:\n        \"logs/minimap2_index/{input1}.log\"\n    params:\n        extra=\"\"  # optional additional args\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/index\"\n"
    },
    {
      "name": "minimap2_paf",
      "input": {
        "target": "target/{input1}.mmi",
        "query": [
          "query/reads1.fasta",
          "query/reads2.fasta"
        ]
      },
      "output": {
        "default": "aligned/{input1}_aln.paf"
      },
      "log": {
        "default": "logs/minimap2/{input1}.log"
      },
      "params": {
        "extra": "-x map-pb",
        "sorting": "coordinate",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/minimap2/aligner"
      },
      "input_types": [
        "FASTQ file(s) or unaligned BAM file",
        "reference genome"
      ],
      "output_types": [
        "SAM/BAM/CRAM file"
      ],
      "rule": "rule minimap2_paf:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=[\"query/reads1.fasta\", \"query/reads2.fasta\"],\n    output:\n        \"aligned/{input1}_aln.paf\",\n    log:\n        \"logs/minimap2/{input1}.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"coordinate\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\n\nrule minimap2_sam:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=[\"query/reads1.fasta\", \"query/reads2.fasta\"],\n    output:\n        \"aligned/{input1}_aln.sam\",\n    log:\n        \"logs/minimap2/{input1}.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"none\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\n\nrule minimap2_sam_sorted:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=[\"query/reads1.fasta\", \"query/reads2.fasta\"],\n    output:\n        \"aligned/{input1}_aln.sorted.sam\",\n    log:\n        \"logs/minimap2/{input1}.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"queryname\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\n\nrule minimap2_bam_sorted:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=[\"query/reads1.fasta\", \"query/reads2.fasta\"],\n    output:\n        \"aligned/{input1}_aln.sorted.bam\",\n    log:\n        \"logs/minimap2/{input1}.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"coordinate\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\nrule minimap2_ubam_paf:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=\"query/reads.bam\",\n    output:\n        \"aligned/{input1}_aln.ubam.paf\",\n    log:\n        \"logs/minimap2/{input1}.ubam.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"coordinate\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\n\nrule minimap2_ubam_sam:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=\"query/reads.bam\",\n    output:\n        \"aligned/{input1}_aln.ubam.sam\",\n    log:\n        \"logs/minimap2/{input1}.ubam.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"none\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\n\nrule minimap2_ubam_sam_sorted:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=\"query/reads.bam\",\n    output:\n        \"aligned/{input1}_aln.sorted.ubam.sam\",\n    log:\n        \"logs/minimap2/{input1}.ubam.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"queryname\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n\n\nrule minimap2_ubam_bam_sorted:\n    input:\n        target=\"target/{input1}.mmi\",  # can be either genome index or genome fasta\n        query=\"query/reads.bam\",\n    output:\n        \"aligned/{input1}_aln.sorted.ubam.bam\",\n    log:\n        \"logs/minimap2/{input1}.ubam.log\",\n    params:\n        extra=\"-x map-pb\",  # optional\n        sorting=\"coordinate\",  # optional: Enable sorting. Possible values: 'none', 'queryname' or 'coordinate'\n        sort_extra=\"\",  # optional: extra arguments for samtools/picard\n    threads: 3\n    wrapper:\n        \"master/bio/minimap2/aligner\"\n"
    },
    {
      "name": "modelsegments_denoise_input",
      "input": {
        "denoised_copy_ratios": "a.denoisedCR.tsv"
      },
      "output": {
        "default": "a.den.modelFinal.seg"
      },
      "log": {
        "default": "logs/gatk/modelsegments_denoise.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/modelsegments"
      },
      "input_types": [
        {
          "denoised_copy_ratios": "denoised_copy_ratios file (optional)"
        },
        {
          "allelic_counts": "allelic_counts file (optional)"
        },
        {
          "normal_allelic_counts": "matched_normal allelic-counts (optional)"
        },
        {
          "segments": "segments Picard interval-list file containing a multisample segmentation output by a previous run (optional)"
        }
      ],
      "output_types": [
        "list of files ending with either '.modelFinal.seq', '.cr.seg', '.af.igv.seg', '.cr.igv.seg', '.hets.tsv', '.modelBegin.cr.param', '.modelBegin.af.param', '.modelBegin.seg', '.modelFinal.af.param' or '.modelFinal.cr.param'"
      ],
      "rule": "rule modelsegments_denoise_input:\n    input:\n        denoised_copy_ratios=\"a.denoisedCR.tsv\",\n    output:\n        \"a.den.modelFinal.seg\",\n        \"a.n.cr.seg\",\n    log:\n        \"logs/gatk/modelsegments_denoise.log\",\n    params:\n        #prefix=\"a.den.test\",\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/modelsegments\"\n\n"
    },
    {
      "name": "mosdepth",
      "input": {
        "bam": "aligned/{dataset}.bam",
        "bai": "aligned/{dataset}.bam.bai"
      },
      "output": {
        "summary": "mosdepth/{dataset}.mosdepth.summary.txt"
      },
      "log": {
        "default": "logs/mosdepth/{dataset}.log"
      },
      "params": {
        "extra": "--fast-mode"
      },
      "wrapper": {
        "default": "master/bio/mosdepth"
      },
      "input_types": [
        "BAM/CRAM files",
        "reference genome (optional)",
        "BED file (optional)"
      ],
      "output_types": [
        "Several coverage summary files."
      ],
      "rule": "rule mosdepth:\n    input:\n        bam=\"aligned/{dataset}.bam\",\n        bai=\"aligned/{dataset}.bam.bai\",\n    output:\n        \"mosdepth/{dataset}.mosdepth.global.dist.txt\",\n        \"mosdepth/{dataset}.per-base.bed.gz\",  # produced unless --no-per-base specified\n        summary=\"mosdepth/{dataset}.mosdepth.summary.txt\",  # this named output is required for prefix parsing\n    log:\n        \"logs/mosdepth/{dataset}.log\",\n    params:\n        extra=\"--fast-mode\",  # optional\n    # additional decompression threads through `--threads`\n    threads: 4  # This value - 1 will be sent to `--threads`\n    wrapper:\n        \"master/bio/mosdepth\"\n\n\nrule mosdepth_bed:\n    input:\n        bam=\"aligned/{dataset}.bam\",\n        bai=\"aligned/{dataset}.bam.bai\",\n        bed=\"test.bed\",\n    output:\n        \"mosdepth_bed/{dataset}.mosdepth.global.dist.txt\",\n        \"mosdepth_bed/{dataset}.mosdepth.region.dist.txt\",\n        \"mosdepth_bed/{dataset}.regions.bed.gz\",\n        summary=\"mosdepth_bed/{dataset}.mosdepth.summary.txt\",  # this named output is required for prefix parsing\n    log:\n        \"logs/mosdepth_bed/{dataset}.log\",\n    params:\n        extra=\"--no-per-base --use-median\",  # optional\n    # additional decompression threads through `--threads`\n    threads: 4  # This value - 1 will be sent to `--threads`\n    wrapper:\n        \"master/bio/mosdepth\"\n\n\nrule mosdepth_by_threshold:\n    input:\n        bam=\"aligned/{dataset}.bam\",\n        bai=\"aligned/{dataset}.bam.bai\",\n    output:\n        \"mosdepth_by_threshold/{dataset}.mosdepth.global.dist.txt\",\n        \"mosdepth_by_threshold/{dataset}.mosdepth.region.dist.txt\",\n        \"mosdepth_by_threshold/{dataset}.regions.bed.gz\",\n        \"mosdepth_by_threshold/{dataset}.thresholds.bed.gz\",  # needs to go with params.thresholds spec\n        summary=\"mosdepth_by_threshold/{dataset}.mosdepth.summary.txt\",  # this named output is required for prefix parsing\n    log:\n        \"logs/mosdepth_by/{dataset}.log\",\n    params:\n        by=\"500\",  # optional, window size,  specifies --by for mosdepth.region.dist.txt and regions.bed.gz\n        thresholds=\"1,5,10,30\",  # optional, specifies --thresholds for thresholds.bed.gz\n    # additional decompression threads through `--threads`\n    threads: 4  # This value - 1 will be sent to `--threads`\n    wrapper:\n        \"master/bio/mosdepth\"\n\n\nrule mosdepth_quantize_precision:\n    input:\n        bam=\"aligned/{dataset}.bam\",\n        bai=\"aligned/{dataset}.bam.bai\",\n    output:\n        \"mosdepth_quantize_precision/{dataset}.mosdepth.global.dist.txt\",\n        \"mosdepth_quantize_precision/{dataset}.quantized.bed.gz\",  # optional, needs to go with params.quantize spec\n        summary=\"mosdepth_quantize_precision/{dataset}.mosdepth.summary.txt\",  # this named output is required for prefix parsing\n    log:\n        \"logs/mosdepth_quantize_precision/{dataset}.log\",\n    params:\n        extra=\"--no-per-base\",  # optional\n        quantize=\"0:1:5:150\",  # optional, specifies --quantize for quantized.bed.gz\n        precision=\"5\",  # optional, set decimals of precision\n    # additional decompression threads through `--threads`\n    threads: 4  # This value - 1 will be sent to `--threads`\n    wrapper:\n        \"master/bio/mosdepth\"\n\n\nrule mosdepth_cram:\n    input:\n        bam=\"aligned/{dataset}.cram\",\n        bai=\"aligned/{dataset}.cram.crai\",\n        bed=\"test.bed\",\n        fasta=\"genome.fasta\",\n    output:\n        \"mosdepth_cram/{dataset}.mosdepth.global.dist.txt\",\n        \"mosdepth_cram/{dataset}.mosdepth.region.dist.txt\",\n        \"mosdepth_cram/{dataset}.regions.bed.gz\",\n        summary=\"mosdepth_cram/{dataset}.mosdepth.summary.txt\",  # this named output is required for prefix parsing\n    log:\n        \"logs/mosdepth_cram/{dataset}.log\",\n    params:\n        extra=\"--no-per-base --use-median\",  # optional\n    # additional decompression threads through `--threads`\n    threads: 4  # This value - 1 will be sent to `--threads`\n    wrapper:\n        \"master/bio/mosdepth\"\n"
    },
    {
      "name": "mpileup_to_vcf",
      "input": {
        "default": "mpileup/{sample}.mpileup.gz"
      },
      "output": {
        "default": "vcf/{sample}.vcf"
      },
      "log": {
        "default": "logs/varscan_{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/varscan/mpileup2snp"
      },
      "input_types": [
        "A mpileup file"
      ],
      "output_types": [
        "A VCF file"
      ],
      "rule": "rule mpileup_to_vcf:\n    input:\n        \"mpileup/{sample}.mpileup.gz\"\n    output:\n        \"vcf/{sample}.vcf\"\n    message:\n        \"Calling SNP with Varscan2\"\n    threads:  # Varscan does not take any threading information\n        1     # However, mpileup might have to be unzipped.\n              # Keep threading value to one for unzipped mpileup input\n              # Set it to two for zipped mipileup files\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    log:\n        \"logs/varscan_{sample}.log\"\n    wrapper:\n        \"master/bio/varscan/mpileup2snp\"\n"
    },
    {
      "name": "mpilup",
      "input": {
        "bam": "mapped/{sample}.bam",
        "reference_genome": "genome.fasta"
      },
      "output": {
        "default": "mpileup/{sample}.mpileup.gz"
      },
      "log": {
        "default": "logs/samtools/mpileup/{sample}.log"
      },
      "params": {
        "extra": "-d 10000"
      },
      "wrapper": {
        "default": "master/bio/samtools/mpileup"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule mpilup:\n    input:\n        # single or list of bam files\n        bam=\"mapped/{sample}.bam\",\n        reference_genome=\"genome.fasta\",\n    output:\n        \"mpileup/{sample}.mpileup.gz\",\n    log:\n        \"logs/samtools/mpileup/{sample}.log\",\n    params:\n        extra=\"-d 10000\",  # optional\n    wrapper:\n        \"master/bio/samtools/mpileup\"\n"
    },
    {
      "name": "muscle_fasta",
      "input": {
        "fasta": "{sample}.fa"
      },
      "output": {
        "alignment": "{sample}.fas"
      },
      "log": {
        "default": "logs/muscle/{sample}.log"
      },
      "params": {
        "extra": "-refineiters 50"
      },
      "wrapper": {
        "default": "master/bio/muscle"
      },
      "input_types": [
        "FASTA file"
      ],
      "output_types": [
        "Alignment file, with FASTA as default file format"
      ],
      "rule": "rule muscle_fasta:\n    input:\n        fasta=\"{sample}.fa\",  # Input fasta file\n    output:\n        alignment=\"{sample}.fas\",  # Output alignment file\n    log:\n        \"logs/muscle/{sample}.log\",\n    params:\n        extra=\"-refineiters 50\",  # Additional arguments\n    threads: 2\n    wrapper:\n        \"master/bio/muscle\"\n\n\nrule muscle_super5:\n    input:\n        fasta=\"{sample}.fa\",\n    output:\n        alignment=\"{sample}.super5.fas\",\n    log:\n        \"logs/muscle/{sample}.super5.log\",\n    params:\n        super5 = True,\n        extra=\"-refineiters 50\",\n    threads: 2\n    wrapper:\n        \"master/bio/muscle\"\n"
    },
    {
      "name": "mutect2",
      "input": {
        "fasta": "genome/genome.fasta",
        "map": "mapped/{sample}.bam"
      },
      "output": {
        "vcf": "variant/{sample}.vcf"
      },
      "log": {
        "default": "logs/mutect_{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/gatk/mutect"
      },
      "input_types": [
        {
          "map": "Mapped reads (SAM/BAM/CRAM)"
        },
        {
          "fasta": "Reference Fasta file"
        },
        {
          "intervals": "Optional path to a BED interval file"
        },
        {
          "pon": "Optional path to Panel of Normals (flagged as BETA)"
        },
        {
          "germline": "Optional path to known germline variants"
        }
      ],
      "output_types": [
        {
          "vcf": "Path to variant file"
        },
        {
          "bam": "Optional path to output bam file"
        },
        {
          "f1r2": "Optional path to f1r2 count file"
        }
      ],
      "rule": "rule mutect2:\n    input:\n        fasta=\"genome/genome.fasta\",\n        map=\"mapped/{sample}.bam\",\n    output:\n        vcf=\"variant/{sample}.vcf\",\n    message:\n        \"Testing Mutect2 with {wildcards.sample}\"\n    threads: 1\n    resources:\n        mem_mb=1024,\n    log:\n        \"logs/mutect_{sample}.log\",\n    wrapper:\n        \"master/bio/gatk/mutect\"\n\n\nrule mutect2_bam:\n    input:\n        fasta=\"genome/genome.fasta\",\n        map=\"mapped/{sample}.bam\",\n    output:\n        vcf=\"variant_bam/{sample}.vcf\",\n        bam=\"variant_bam/{sample}.bam\",\n    message:\n        \"Testing Mutect2 with {wildcards.sample}\"\n    threads: 1\n    resources:\n        mem_mb=1024,\n    log:\n        \"logs/mutect_{sample}.log\",\n    wrapper:\n        \"master/bio/gatk/mutect\"\n\n\nrule mutect2_complete:\n    input:\n        fasta=\"genome/genome.fasta\",\n        map=\"mapped/{sample}.bam\",\n        intervals=\"genome/intervals.bed\",\n    output:\n        vcf=\"variant_complete/{sample}.vcf\",\n        bam=\"variant_complete/{sample}.bam\",\n        f1r2=\"counts/{sample}.f1r2.tar.gz\",\n    message:\n        \"Testing Mutect2 with {wildcards.sample}\"\n    threads: 1\n    resources:\n        mem_mb=1024,\n    log:\n        \"logs/mutect_{sample}.log\",\n    wrapper:\n        \"master/bio/gatk/mutect\"\n\nrule mutect2_list:\n    input:\n        fasta=\"genome/genome.fasta\",\n        map=expand(\"mapped/{sample}.bam\", sample=[\"a\", \"b\"]),\n    output:\n        vcf=\"variant_list/a_b.vcf\",\n    threads: 1\n    resources:\n        mem_mb=1024,\n    log:\n        \"logs/mutect2_list.log\",\n    params:\n        extra=\"--tumor-sample a_normal --normal-sample b_normal\",\n    wrapper:\n        \"master/bio/gatk/mutect\"\n"
    },
    {
      "name": "nonpareil",
      "input": {
        "default": "reads/{sample}"
      },
      "output": {
        "redund_sum": "results/{sample}.npo",
        "redund_val": "results/{sample}.npa",
        "mate_distr": "results/{sample}.npc",
        "log": "results/{sample}.log"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "alg": "kmer",
        "infer_X": true,
        "extra": "-k 3 -F"
      },
      "wrapper": {
        "default": "master/bio/nonpareil/infer"
      },
      "input_types": [
        "reads in FASTA/Q format (can be gziped or bziped)"
      ],
      "output_types": [
        {
          "redund_sum": "redundancy summary TSV file with six columns, representing sequencing effort, summary of the distribution of redundancy (average redundancy, standard deviation, quartile 1, median, and quartile 3)."
        },
        {
          "redund_val": "redundancy values TSV file with three columns (similar to redundancy summary, but provides ALL results), representing sequencing effort, ID of the replicate and estimated redundancy value."
        },
        {
          "mate_distr": "mate distribution file, with the number of reads in the dataset matching a query read."
        },
        {
          "log": "log of internal Nonpareil processing."
        }
      ],
      "rule": "rule nonpareil:\n    input:\n        \"reads/{sample}\",\n    output:\n        redund_sum=\"results/{sample}.npo\",\n        redund_val=\"results/{sample}.npa\",\n        mate_distr=\"results/{sample}.npc\",\n        log=\"results/{sample}.log\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        alg=\"kmer\",\n        infer_X=True,\n        extra=\"-k 3 -F\",\n    threads: 2\n    resources:\n        mem_mb=50,\n    wrapper:\n        \"master/bio/nonpareil/infer\"\n"
    },
    {
      "name": "norm_vcf",
      "input": {
        "default": "{prefix}.bcf"
      },
      "output": {
        "default": "{prefix}.norm.vcf"
      },
      "log": {
        "default": "{prefix}.norm.log"
      },
      "params": {
        "extra": "--rm-dup none"
      },
      "wrapper": {
        "default": "master/bio/bcftools/norm"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule norm_vcf:\n    input:\n        \"{prefix}.bcf\",\n        #ref=\"genome.fasta\"  # optional reference (will be translated into the -f option)\n    output:\n        \"{prefix}.norm.vcf\",  # can also be .bcf, corresponding --output-type parameter is inferred automatically\n    log:\n        \"{prefix}.norm.log\",\n    params:\n        extra=\"--rm-dup none\",  # optional\n        #uncompressed_bcf=False,\n    wrapper:\n        \"master/bio/bcftools/norm\"\n"
    },
    {
      "name": "obtain_asset",
      "input": {},
      "output": {
        "fai": "refs/genome.fasta"
      },
      "log": {},
      "params": {
        "genome": "human_alu",
        "asset": "fasta",
        "tag": "default"
      },
      "wrapper": {
        "default": "master/bio/refgenie"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule obtain_asset:\n    output:\n        # the name refers to the refgenie seek key (see attributes on http://refgenomes.databio.org)\n        fai=\"refs/genome.fasta\"\n        # Multiple outputs/seek keys are possible here.\n    params:\n        genome=\"human_alu\",\n        asset=\"fasta\",\n        tag=\"default\"\n    wrapper:\n        \"master/bio/refgenie\"\n"
    },
    {
      "name": "opencravat",
      "input": {
        "default": "example_input.tsv"
      },
      "output": {
        "default": "example_input.tsv.xlsx"
      },
      "log": {
        "default": "logs/open-cravat/run.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/open-cravat/run"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule opencravat:\n    input:\n        'example_input.tsv',\n        'modules/commons/hg38wgs',\n        'modules/converters/cravat-converter',\n        'modules/mappers/hg38',\n        'modules/annotators/biogrid', \n        'modules/annotators/clinvar',\n        'modules/postaggregators/tagsampler',\n        'modules/postaggregators/varmeta',\n        'modules/postaggregators/vcfinfo',\n        'modules/reporters/excelreporter',\n        'modules/reporters/tsvreporter',\n        'modules/reporters/csvreporter',\n    output:\n        'example_input.tsv.xlsx',\n        'example_input.tsv.variant.tsv', \n        'example_input.tsv.variant.csv'\n    log:\n        \"logs/open-cravat/run.log\"\n    threads: 1 # set number of threads for parallel processing\n    wrapper:\n        \"master/bio/open-cravat/run\"\n\nrule installmodules:  # [hide]\n    output:  # [hide]\n        directory('modules/commons/hg38wgs'),  # [hide]\n        directory('modules/converters/cravat-converter'),  # [hide]\n        directory('modules/mappers/hg38'),  # [hide]\n        directory('modules/annotators/biogrid'),   # [hide]\n        directory('modules/annotators/clinvar'),  # [hide]\n        directory('modules/postaggregators/tagsampler'),  # [hide]\n        directory('modules/postaggregators/varmeta'),  # [hide]\n        directory('modules/postaggregators/vcfinfo'),  # [hide]\n        directory('modules/reporters/excelreporter'),  # [hide]\n        directory('modules/reporters/tsvreporter'),  # [hide]\n        directory('modules/reporters/csvreporter'),  # [hide]\n    log:  # [hide]\n        \"logs/open-cravat/module.log\"  # [hide]\n    wrapper:  # [hide]\n        \"file:module_wrapper/module_wrapper.py\"  # [hide]\n"
    },
    {
      "name": "opencravat_module",
      "input": {},
      "output": {
        "default": "directory('modules/annotators/biogrid')"
      },
      "log": {
        "default": "logs/open-cravat/module.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/open-cravat/module"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule opencravat_module:\n    output:\n        # add any other desired modules as separate directory outputs\n        directory(\"modules/annotators/biogrid\"),\n    log:\n        \"logs/open-cravat/module.log\"\n    wrapper:\n        \"master/bio/open-cravat/module\"\n\n"
    },
    {
      "name": "optitype",
      "input": {
        "reads": [
          "reads/{sample}_1.fished.fastq",
          "reads/{sample}_2.fished.fastq"
        ]
      },
      "output": {
        "pdf": "optitype/{sample}_coverage_plot.pdf",
        "tsv": "optitype/{sample}_result.tsv"
      },
      "log": {
        "default": "logs/optitype/{sample}.log"
      },
      "params": {
        "sequencing_type": "dna",
        "config": "",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/optitype"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule optitype:\n    input:\n        # list of input reads\n        reads=[\"reads/{sample}_1.fished.fastq\", \"reads/{sample}_2.fished.fastq\"]\n    output:\n        pdf=\"optitype/{sample}_coverage_plot.pdf\",\n        tsv=\"optitype/{sample}_result.tsv\",\n    log:\n        \"logs/optitype/{sample}.log\"\n    params:\n        # Type of sequencing data. Can be 'dna' or 'rna'. Default is 'dna'.\n        sequencing_type=\"dna\",\n        # optiype config file, optional\n        config=\"\",\n        # additional parameters\n        extra=\"\"\n    wrapper:\n        \"master/bio/optitype\"\n"
    },
    {
      "name": "paladin_align",
      "input": {
        "reads": [
          "reads/reads.left.fq.gz"
        ],
        "index": "index/prot.fasta.bwt"
      },
      "output": {
        "default": "paladin_mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/paladin/{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/paladin/align"
      },
      "input_types": [
        "nucleotide reads (fastq)",
        "indexed protein fasta file (output of paladin index or prepare)"
      ],
      "output_types": [
        "mapped reads (SAM or BAM format)"
      ],
      "rule": "rule paladin_align:\n    input:\n        reads=[\"reads/reads.left.fq.gz\"], \n        index=\"index/prot.fasta.bwt\", \n    output:\n        \"paladin_mapped/{sample}.bam\" # will output BAM format if output file ends with \".bam\", otherwise SAM format\n    log:\n        \"logs/paladin/{sample}.log\"\n    threads: 4\n    wrapper:\n        \"master/bio/paladin/align\"\n"
    },
    {
      "name": "paladin_index",
      "input": {
        "default": "prot.fasta"
      },
      "output": {
        "default": "index/prot.fasta.bwt"
      },
      "log": {
        "default": "logs/paladin/prot_index.log"
      },
      "params": {
        "reference_type": 3
      },
      "wrapper": {
        "default": "master/bio/paladin/index"
      },
      "input_types": [
        "protein fasta file"
      ],
      "output_types": [
        "file indexed for paladin mapping"
      ],
      "rule": "rule paladin_index:\n    input:\n        \"prot.fasta\", \n    output:\n        \"index/prot.fasta.bwt\" \n    log:\n        \"logs/paladin/prot_index.log\"\n    params:\n      reference_type=3\n    wrapper:\n        \"master/bio/paladin/index\"\n"
    },
    {
      "name": "paladin_prepare",
      "input": {},
      "output": {
        "default": "uniprot_sprot.fasta.gz"
      },
      "log": {
        "default": "logs/paladin/prepare_sprot.log"
      },
      "params": {
        "reference_type": 1
      },
      "wrapper": {
        "default": "master/bio/paladin/prepare"
      },
      "input_types": "undefined",
      "output_types": [
        "prepared uniprot file for mapping with paladin"
      ],
      "rule": "rule paladin_prepare:\n    output:\n        \"uniprot_sprot.fasta.gz\",\n        \"uniprot_sprot.fasta.gz.pro\" \n    log:\n        \"logs/paladin/prepare_sprot.log\"\n    params:\n        reference_type=1, # 1=swiss-prot, 2=uniref90 \n    wrapper:\n        \"master/bio/paladin/prepare\"\n"
    },
    {
      "name": "pandora_index",
      "input": {
        "default": "{gene}/prg.fa"
      },
      "output": {
        "index": "{gene}/prg.fa.k15.w14.idx",
        "kmer_prgs": "directory('{gene}/kmer_prgs')"
      },
      "log": {
        "default": "pandora_index/{gene}.log"
      },
      "params": {
        "options": "-v -k 15 -w 14"
      },
      "wrapper": {
        "default": "master/bio/pandora/index"
      },
      "input_types": [
        "A PRG file (made by `make_prg <https://github.com/iqbal-lab-org/make_prg>`) to index"
      ],
      "output_types": [
        {
          "index": "A pandora index file"
        },
        {
          "kmer_prgs": "A directory of the index kmer PRGs in GFA format"
        }
      ],
      "rule": "rule pandora_index:\n    input:\n        \"{gene}/prg.fa\",\n    output:\n        index=\"{gene}/prg.fa.k15.w14.idx\",\n        kmer_prgs=directory(\"{gene}/kmer_prgs\"),\n    log:\n        \"pandora_index/{gene}.log\",\n    params:\n        options=\"-v -k 15 -w 14\",\n    threads: 1\n    wrapper:\n        \"master/bio/pandora/index\"\n"
    },
    {
      "name": "patch",
      "input": {
        "query": "fasta/{query}.fasta",
        "ref": "fasta/{reference}.fasta"
      },
      "output": {
        "agp": "{query}_{reference}.agp",
        "fasta": "{query}_{reference}.fasta",
        "rename_agp": "{query}_{reference}.rename.agp",
        "rename_fasta": "{query}_{reference}.rename.fasta",
        "ctg_agp": "{query}_{reference}.ctg.agp",
        "ctg_fasta": "{query}_{reference}.ctg.fasta",
        "comps_fasta": "{query}_{reference}.comps.fasta",
        "asm_dir": "directory('{query}_{reference}_asm')"
      },
      "log": {
        "default": "logs/ragtag/{query}_patch_{reference}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/ragtag/patch"
      },
      "input_types": [
        {
          "ref": "reference fasta file (uncompressed or bgzipped)"
        },
        {
          "query": "query fasta file (uncompressed or bgzipped)"
        }
      ],
      "output_types": [
        {
          "fasta": "The final FASTA file containing the patched assembly"
        },
        {
          "agp": "The final AGP file defining how ragtag.patch.fasta is built."
        },
        {
          "rename_agp": "Optional. An AGP file defining the new names for query sequences"
        },
        {
          "rename_fasta": "Optional. A FASTA file with the original query sequence, but with new names."
        },
        {
          "comps_fasta": "Optional. The split target assembly and the renamed query assembly combined into one FASTA file."
        },
        {
          "ctg_agp": "Optional. An AGP file defining how the target assembly was split at gaps"
        },
        {
          "ctg_fasta": "Optional. The target assembly split at gaps"
        },
        {
          "asm_dir": "Optional. A directory containing Assembly alignment files."
        }
      ],
      "rule": "rule patch:\n    input:\n        query=\"fasta/{query}.fasta\",\n        ref=\"fasta/{reference}.fasta\",\n    output:\n        agp=\"{query}_{reference}.agp\",\n        fasta=\"{query}_{reference}.fasta\",\n        rename_agp=\"{query}_{reference}.rename.agp\",\n        rename_fasta=\"{query}_{reference}.rename.fasta\",\n        ctg_agp=\"{query}_{reference}.ctg.agp\",\n        ctg_fasta=\"{query}_{reference}.ctg.fasta\",\n        comps_fasta=\"{query}_{reference}.comps.fasta\",\n        asm_dir=directory(\"{query}_{reference}_asm\"),  # Assembly alignment files\n    params:\n        extra=\"\",\n    threads: 16\n    log:\n        \"logs/ragtag/{query}_patch_{reference}.log\",\n    wrapper:\n        \"master/bio/ragtag/patch\"\n"
    },
    {
      "name": "pbmm2_align",
      "input": {
        "reference": "target/{reference}.fasta",
        "query": "{query}.bam"
      },
      "output": {
        "bam": "aligned/{query}.{reference}.bam",
        "index": "aligned/{query}.{reference}.bam.bai"
      },
      "log": {
        "default": "logs/pbmm2_align/{query}.{reference}.log"
      },
      "params": {
        "preset": "CCS",
        "sample": "",
        "extra": "--sort",
        "loglevel": "INFO"
      },
      "wrapper": {
        "default": "master/bio/pbmm2/align"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule pbmm2_align:\n    input:\n        reference=\"target/{reference}.fasta\", # can be either genome index or genome fasta\n        query=\"{query}.bam\", # can be either unaligned bam, fastq, or fasta\n    output:\n        bam=\"aligned/{query}.{reference}.bam\",\n        index=\"aligned/{query}.{reference}.bam.bai\",\n    log:\n        \"logs/pbmm2_align/{query}.{reference}.log\",\n    params:\n        preset=\"CCS\", # SUBREAD, CCS, HIFI, ISOSEQ, UNROLLED\n        sample=\"\", # sample name for @RG header\n        extra=\"--sort\", # optional additional args\n        loglevel=\"INFO\",\n    threads: 12\n    wrapper:\n        \"master/bio/pbmm2/align\"\n"
    },
    {
      "name": "pbmm2_index",
      "input": {
        "reference": "target/{reference}.fasta"
      },
      "output": {
        "default": "target/{reference}.mmi"
      },
      "log": {
        "default": "logs/pbmm2_index/{reference}.log"
      },
      "params": {
        "preset": "CCS",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pbmm2/index"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule pbmm2_index:\n    input:\n        reference=\"target/{reference}.fasta\",\n    output:\n        \"target/{reference}.mmi\",\n    log:\n        \"logs/pbmm2_index/{reference}.log\",\n    params:\n        preset=\"CCS\", # SUBREAD, CCS, HIFI, ISOSEQ, UNROLLED\n        extra=\"\", # optional additional args\n    threads: 8\n    wrapper:\n        \"master/bio/pbmm2/index\"\n"
    },
    {
      "name": "pear_merge",
      "input": {
        "read1": "reads/reads.left.fq.gz",
        "read2": "reads/reads.right.fq.gz"
      },
      "output": {
        "assembled": "pear/reads_pear_assembled.fq.gz",
        "discarded": "pear/reads_pear_discarded.fq.gz",
        "unassembled_read1": "pear/reads_pear_unassembled_r1.fq.gz",
        "unassembled_read2": "pear/reads_pear_unassembled_r2.fq.gz"
      },
      "log": {
        "default": "logs/pear.log"
      },
      "params": {
        "pval": ".01",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pear"
      },
      "input_types": [
        "paired fastq files"
      ],
      "output_types": [
        "merged fastq"
      ],
      "rule": "rule pear_merge:\n    input:\n        read1=\"reads/reads.left.fq.gz\",\n        read2=\"reads/reads.right.fq.gz\"\n    output:\n        assembled=\"pear/reads_pear_assembled.fq.gz\",\n        discarded=\"pear/reads_pear_discarded.fq.gz\",\n        unassembled_read1=\"pear/reads_pear_unassembled_r1.fq.gz\",\n        unassembled_read2=\"pear/reads_pear_unassembled_r2.fq.gz\",\n    log:\n        'logs/pear.log'\n    params:\n        pval=\".01\",\n        extra=\"\"\n    threads: 4\n    resources:\n        mem_mb=4000 # define amount of memory to be used by pear\n    wrapper:\n        \"master/bio/pear\"\n"
    },
    {
      "name": "picard_collect_hs_metrics",
      "input": {
        "bam": "mapped/{sample}.bam",
        "reference": "genome.fasta",
        "bait_intervals": "regions.intervals",
        "target_intervals": "regions.intervals"
      },
      "output": {
        "default": "stats/hs_metrics/{sample}.txt"
      },
      "log": {
        "default": "logs/picard_collect_hs_metrics/{sample}.log"
      },
      "params": {
        "extra": "--SAMPLE_SIZE 1000"
      },
      "wrapper": {
        "default": "master/bio/picard/collecthsmetrics"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "metrics file"
      ],
      "rule": "rule picard_collect_hs_metrics:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        reference=\"genome.fasta\",\n        # Baits and targets should be given as interval lists. These can\n        # be generated from bed files using picard BedToIntervalList.\n        bait_intervals=\"regions.intervals\",\n        target_intervals=\"regions.intervals\",\n    output:\n        \"stats/hs_metrics/{sample}.txt\",\n    params:\n        # Optional extra arguments. Here we reduce sample size\n        # to reduce the runtime in our unit test.\n        extra=\"--SAMPLE_SIZE 1000\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    log:\n        \"logs/picard_collect_hs_metrics/{sample}.log\",\n    wrapper:\n        \"master/bio/picard/collecthsmetrics\"\n"
    },
    {
      "name": "pindel2vcf",
      "input": {
        "ref": "genome.fasta",
        "pindel": "pindel/all_{type}"
      },
      "output": {
        "default": "pindel/all_{type}.vcf"
      },
      "log": {
        "default": "logs/pindel/pindel2vcf.{type}.log"
      },
      "params": {
        "refname": "hg38",
        "refdate": "20170110",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pindel/pindel2vcf"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule pindel2vcf:\n    input:\n        ref=\"genome.fasta\",\n        pindel=\"pindel/all_{type}\"\n    output:\n        \"pindel/all_{type}.vcf\"\n    params:\n        refname=\"hg38\",  # mandatory, see pindel manual\n        refdate=\"20170110\",  # mandatory, see pindel manual\n        extra=\"\"  # extra params (except -r, -p, -R, -d, -v)\n    log:\n        \"logs/pindel/pindel2vcf.{type}.log\"\n    wrapper:\n        \"master/bio/pindel/pindel2vcf\"\n\nrule pindel2vcf_multi_input:\n    input:\n        ref=\"genome.fasta\",\n        pindel=[\"pindel/all_D\", \"pindel/all_INV\"]\n    output:\n        \"pindel/all.vcf\"\n    params:\n        refname=\"hg38\",  # mandatory, see pindel manual\n        refdate=\"20170110\",  # mandatory, see pindel manual\n        extra=\"\"  # extra params (except -r, -p, -R, -d, -v)\n    log:\n        \"logs/pindel/pindel2vcf.log\"\n    wrapper:\n        \"master/bio/pindel/pindel2vcf\"\n"
    },
    {
      "name": "plass_paired",
      "input": {
        "left": [
          "reads/reads.left.fq.gz",
          "reads/reads2.left.fq.gz"
        ],
        "right": [
          "reads/reads.right.fq.gz",
          "reads/reads2.right.fq.gz"
        ]
      },
      "output": {
        "default": "plass/prot.fasta"
      },
      "log": {
        "default": "logs/plass.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/plass"
      },
      "input_types": [
        "fastq files"
      ],
      "output_types": [
        "fasta containing protein assembly"
      ],
      "rule": "rule plass_paired:\n    input:\n        left=[\"reads/reads.left.fq.gz\", \"reads/reads2.left.fq.gz\"],\n        right=[\"reads/reads.right.fq.gz\", \"reads/reads2.right.fq.gz\"] \n    output:\n        \"plass/prot.fasta\"\n    log:\n        \"logs/plass.log\"\n    params:\n        extra=\"\"\n    threads: 4\n    wrapper:\n        \"master/bio/plass\"\n\nrule plass_single:\n    input:\n        single=[\"reads/reads.left.fq.gz\", \"reads/reads2.left.fq.gz\"],\n    output:\n        \"plass/prot_single.fasta\"\n    log:\n        \"logs/plass_single.log\"\n    params:\n        extra=\"\"\n    threads: 4\n    wrapper:\n        \"master/bio/plass\"\n"
    },
    {
      "name": "plot_fingerprint",
      "input": {
        "bam_files": "expand('samples/{sample}.bam', sample=['a', 'b'])",
        "bam_idx": "expand('samples/{sample}.bam.bai', sample=['a', 'b'])",
        "jsd_sample": "samples/b.bam"
      },
      "output": {
        "fingerprint": "plot_fingerprint/plot_fingerprint.png",
        "counts": "plot_fingerprint/raw_counts.tab",
        "qc_metrics": "plot_fingerprint/qc_metrics.txt"
      },
      "log": {
        "default": "logs/deeptools/plot_fingerprint.log"
      },
      "params": {
        "extra": "--numberOfSamples 200"
      },
      "wrapper": {
        "default": "master/bio/deeptools/plotfingerprint"
      },
      "input_types": [
        "list of BAM files (.bam) AND",
        "list of their index files (.bam.bai)"
      ],
      "output_types": [
        "plot file in image format (.png, .eps, .pdf or .svg)",
        "tab-separated table of read counts per bin (.tab) (optional)",
        "tab-separated table of metrics and JSD calculation (.txt) (optional)"
      ],
      "rule": "rule plot_fingerprint:\n    input:\n        bam_files=expand(\"samples/{sample}.bam\", sample=[\"a\", \"b\"]),\n        bam_idx=expand(\"samples/{sample}.bam.bai\", sample=[\"a\", \"b\"]),\n        jsd_sample=\"samples/b.bam\",  # optional, requires qc_metrics output\n    output:\n        # Please note that --plotFile and --outRawCounts are exclusively defined via output files.\n        # Usable output variables, their extensions and which option they implicitly call are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/deeptools/plotfingerprint.html.\n        fingerprint=\"plot_fingerprint/plot_fingerprint.png\",  # required\n        # optional output\n        counts=\"plot_fingerprint/raw_counts.tab\",\n        qc_metrics=\"plot_fingerprint/qc_metrics.txt\",\n    log:\n        \"logs/deeptools/plot_fingerprint.log\",\n    params:\n        # optional parameters\n        extra=\"--numberOfSamples 200\",\n    threads: 8\n    wrapper:\n        \"master/bio/deeptools/plotfingerprint\"\n"
    },
    {
      "name": "plot_heatmap",
      "input": {
        "default": "matrix.gz"
      },
      "output": {
        "heatmap_img": "plot_heatmap/heatmap.png",
        "regions": "plot_heatmap/heatmap_regions.bed",
        "heatmap_matrix": "plot_heatmap/heatmap_matrix.tab"
      },
      "log": {
        "default": "logs/deeptools/heatmap.log"
      },
      "params": {
        "extra": "--plotType=fill "
      },
      "wrapper": {
        "default": "master/bio/deeptools/plotheatmap"
      },
      "input_types": [
        "gzipped matrix file from ``deepTools computeMatrix`` (.gz)"
      ],
      "output_types": [
        "plot file in image format (.png, .eps, .pdf or .svg) AND/OR",
        "file with sorted regions after skipping zeros or min/max threshold values (.bed) AND/OR",
        "tab-separated table for average profile (.tab)"
      ],
      "rule": "rule plot_heatmap:\n    input:\n         # matrix file from deepTools computeMatrix tool\n         \"matrix.gz\"\n    output:\n        # Please note that --outFileSortedRegions and --outFileNameMatrix are exclusively defined via output files.\n        # Usable output variables, their extensions and which option they implicitly call are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/deeptools/plotheatmap.html.\n        heatmap_img=\"plot_heatmap/heatmap.png\",  # required\n        # optional output files\n        regions=\"plot_heatmap/heatmap_regions.bed\",\n        heatmap_matrix=\"plot_heatmap/heatmap_matrix.tab\"\n    log:\n        \"logs/deeptools/heatmap.log\"\n    params:\n        # optional parameters\n        extra=\"--plotType=fill \"\n    wrapper:\n        \"master/bio/deeptools/plotheatmap\"\n"
    },
    {
      "name": "plot_profile",
      "input": {
        "default": "matrix.gz"
      },
      "output": {
        "plot_img": "plot_profile/plot.png",
        "regions": "plot_profile/regions.bed",
        "data": "plot_profile/data.tab"
      },
      "log": {
        "default": "logs/deeptools/plot_profile.log"
      },
      "params": {
        "extra": "--plotType=fill --perGroup --colors red yellow blue --dpi 150"
      },
      "wrapper": {
        "default": "master/bio/deeptools/plotprofile"
      },
      "input_types": [
        "gzipped matrix file from ``deepTools computeMatrix`` (.gz)"
      ],
      "output_types": [
        "plot file in image format (.png, .eps, .pdf or .svg) AND/OR",
        "file with sorted regions after skipping zeros or min/max threshold values (.bed) AND/OR",
        "tab-separated table for average profile (.tab)"
      ],
      "rule": "rule plot_profile:\n    input:\n         # matrix file from deepTools computeMatrix tool\n         \"matrix.gz\"\n    output:\n        # Please note that --outFileSortedRegions and --outFileNameData are exclusively defined via output files.\n        # Usable output variables, their extensions and which option they implicitly call are listed here:\n        #         https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/deeptools/plotprofile.html.\n        # Through the output variables image file and more output options for plot profile can be selected.\n        plot_img=\"plot_profile/plot.png\",  # required\n        # optional output files\n        regions=\"plot_profile/regions.bed\",\n        data=\"plot_profile/data.tab\"\n    log:\n        \"logs/deeptools/plot_profile.log\"\n    params:\n        # optional parameters\n        extra=\"--plotType=fill --perGroup --colors red yellow blue --dpi 150\"\n    wrapper:\n        \"master/bio/deeptools/plotprofile\"\n"
    },
    {
      "name": "prepare_reference",
      "input": {
        "reference_genome": "genome.fasta"
      },
      "output": {
        "seq": "index/reference.seq",
        "grp": "index/reference.grp",
        "ti": "index/reference.ti"
      },
      "log": {
        "default": "logs/rsem/prepare-reference.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/rsem/prepare-reference"
      },
      "input_types": [
        "reference genome",
        "additional optional arguments"
      ],
      "output_types": [
        "index files for downstream use with rsem"
      ],
      "rule": "rule prepare_reference:\n    input:\n        # reference FASTA with either the entire genome or transcript sequences\n        reference_genome=\"genome.fasta\",\n    output:\n        # one of the index files created and used by RSEM (required)\n        seq=\"index/reference.seq\",\n        # RSEM produces a number of other files which may optionally be specified as output; these may be provided so that snakemake is aware of them, but the wrapper doesn't do anything with this information other than to verify that the file path prefixes match that of output.seq.\n        # for example,\n        grp=\"index/reference.grp\",\n        ti=\"index/reference.ti\",\n    params:\n        # optional additional parameters, for example,\n        #extra=\"--gtf annotations.gtf\",\n        # if building the index against a reference transcript set\n        extra=\"\",\n    log:\n        \"logs/rsem/prepare-reference.log\",\n    wrapper:\n        \"master/bio/rsem/prepare-reference\"\n"
    },
    {
      "name": "preprocess_variants",
      "input": {
        "variants": "variants.vcf"
      },
      "output": {
        "default": "normalized/variants.vcf.gz"
      },
      "log": {
        "default": "log/pre.log"
      },
      "params": {
        "genome": "genome.fasta",
        "extra": "-L"
      },
      "wrapper": {
        "default": "master/bio/hap.py/pre.py"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule preprocess_variants:\n    input:\n        ##vcf/bcf\n        variants=\"variants.vcf\",\n    output:\n        \"normalized/variants.vcf.gz\",\n    log:\n        \"log/pre.log\",\n    params:\n        ## path to reference genome\n        genome=\"genome.fasta\",\n        ## parameters such as -L to left-align variants\n        extra=\"-L\",\n    threads: 2\n    wrapper:\n        \"master/bio/hap.py/pre.py\"\n"
    },
    {
      "name": "preseq_lc_extrap_bam",
      "input": {
        "default": "samples/{sample}.sorted.bam"
      },
      "output": {
        "default": "test_bam/{sample}.lc_extrap"
      },
      "log": {
        "default": "logs/test_bam/{sample}.log"
      },
      "params": {
        "default": "-v"
      },
      "wrapper": {
        "default": "master/bio/preseq/lc_extrap"
      },
      "input_types": [
        "bed files containing duplicates and sorted by chromosome, start position, strand position and finally strand OR",
        "bam files containing duplicates and sorted by using bamtools or samtools sort."
      ],
      "output_types": [
        "lc_extrap (.lc_extrap)"
      ],
      "rule": "rule preseq_lc_extrap_bam:\n    input:\n        \"samples/{sample}.sorted.bam\"\n    output:\n        \"test_bam/{sample}.lc_extrap\"\n    params:\n        \"-v\"   #optional parameters\n    log:\n        \"logs/test_bam/{sample}.log\"\n    wrapper:\n        \"master/bio/preseq/lc_extrap\"\n\nrule preseq_lc_extrap_bed:\n    input:\n        \"samples/{sample}.sorted.bed\"\n    output:\n        \"test_bed/{sample}.lc_extrap\"\n    params:\n        \"-v\"   #optional parameters\n    log:\n        \"logs/test_bed/{sample}.log\"\n    wrapper:\n        \"master/bio/preseq/lc_extrap\"\n"
    },
    {
      "name": "pretext_graph",
      "input": {
        "bedgraph": "{a}.bedgraph",
        "map": "map.pretext"
      },
      "output": {
        "default": "{a}.pretext"
      },
      "log": {
        "default": "logs/{a}.pretext_graph.log"
      },
      "params": {
        "graph_name": "graph_name",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pretext/graph"
      },
      "input_types": [
        "BEDgraph file"
      ],
      "output_types": [
        "pretext contact map"
      ],
      "rule": "rule pretext_graph:\n    input:\n        bedgraph=\"{a}.bedgraph\",\n        map=\"map.pretext\",\n    output:\n        \"{a}.pretext\",\n    log:\n        \"logs/{a}.pretext_graph.log\",\n    params:\n        graph_name=\"graph_name\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/pretext/graph\"\n"
    },
    {
      "name": "pretext_map",
      "input": {
        "default": "a.bam"
      },
      "output": {
        "default": "map.pretext"
      },
      "log": {
        "default": "logs/pretext_map.log"
      },
      "params": {
        "extra": "--sortby length --sortorder descend --mapq 10"
      },
      "wrapper": {
        "default": "master/bio/pretext/map"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "pretext contact map"
      ],
      "rule": "rule pretext_map:\n    input:\n        \"a.bam\",\n    output:\n        \"map.pretext\",\n    log:\n        \"logs/pretext_map.log\",\n    params:\n        extra=\"--sortby length --sortorder descend --mapq 10\",\n    wrapper:\n        \"master/bio/pretext/map\"\n"
    },
    {
      "name": "pretext_snapshot_png",
      "input": {
        "default": "map.pretext"
      },
      "output": {
        "all": "directory('all_maps/')",
        "full": "full_map.png"
      },
      "log": {
        "default": "logs/pretext_snapshot_png.log"
      },
      "params": {
        "extra": "--resolution 1080"
      },
      "wrapper": {
        "default": "master/bio/pretext/snapshot"
      },
      "input_types": [
        "pretext contact map"
      ],
      "output_types": [
        "full image (mandatory)",
        "all images (optional)",
        "specific sequences (optional)"
      ],
      "rule": "rule pretext_snapshot_png:\n    input:\n        \"map.pretext\",\n    output:\n        all=directory(\"all_maps/\"),\n        full=\"full_map.png\",\n    log:\n        \"logs/pretext_snapshot_png.log\",\n    params:\n        extra=\"--resolution 1080\",\n    wrapper:\n        \"master/bio/pretext/snapshot\"\n\n\nrule pretext_snapshot_jpg:\n    input:\n        \"map.pretext\",\n    output:\n        all=directory(\"all_maps/\"),\n        full=\"full_map.jpg\",\n    log:\n        \"logs/pretext_snapshot_jpg.log\",\n    params:\n        extra=\"--resolution 1080\",\n    wrapper:\n        \"master/bio/pretext/snapshot\"\n"
    },
    {
      "name": "primerclip",
      "input": {
        "master_file": "master_file",
        "alignment_file": "mapped/{sample}.bam"
      },
      "output": {
        "alignment_file": "mapped/{sample}.trimmed.bam"
      },
      "log": {
        "default": "logs/primerclip/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/primerclip"
      },
      "input_types": [
        "sam file",
        "master primer file"
      ],
      "output_types": [
        "sam file"
      ],
      "rule": "rule primerclip:\n    input:\n        master_file=\"master_file\",\n        alignment_file=\"mapped/{sample}.bam\"\n    output:\n        alignment_file=\"mapped/{sample}.trimmed.bam\"\n    log:\n        \"logs/primerclip/{sample}.log\"\n    params:\n        extra=\"\"\n    wrapper:\n        \"master/bio/primerclip\"\n"
    },
    {
      "name": "prinseq_plus_plus_fas2fq",
      "input": {
        "default": "reads/{prefix}.fas"
      },
      "output": {
        "good": "results/{prefix}.fq",
        "bad": "results/{prefix}.bad.fq"
      },
      "log": {
        "default": "logs/fas2fq/{prefix}.log"
      },
      "params": {
        "extra": "-min_len 2"
      },
      "wrapper": {
        "default": "master/bio/prinseq-plus-plus"
      },
      "input_types": [
        "fastx file(s)"
      ],
      "output_types": [
        {
          "r1": "fastx file"
        },
        {
          "r2": "fastx file (if PE)"
        },
        {
          "r1_single": "fastx file (if PE)"
        },
        {
          "r2_single": "fastx file (if PE)"
        },
        {
          "r1_bad": "fastx file"
        },
        {
          "r2_bad": "fastx file (if PE)"
        }
      ],
      "rule": "rule prinseq_plus_plus_fas2fq:\n    input:\n        \"reads/{prefix}.fas\",\n    output:\n        good=\"results/{prefix}.fq\",\n        bad=\"results/{prefix}.bad.fq\",\n    log:\n        \"logs/fas2fq/{prefix}.log\",\n    params:\n        extra=\"-min_len 2\",\n    threads: 2\n    wrapper:\n        \"master/bio/prinseq-plus-plus\"\n\n\nrule prinseq_plus_plus_fas2fqgz:\n    input:\n        \"reads/{prefix}.fas\",\n    output:\n        good=\"results/{prefix}.fq.gz\",\n        bad=\"results/{prefix}.bad.fq.gz\",\n    log:\n        \"logs/fas2fqgz/{prefix}.log\",\n    params:\n        extra=\"-min_len 2\",\n    threads: 2\n    wrapper:\n        \"master/bio/prinseq-plus-plus\"\n\n\nrule prinseq_plus_plus_fqgz2fas:\n    input:\n        \"reads/{prefix}.fastq.gz\",\n    output:\n        good=\"results/{prefix}.fasta\",\n        bad=\"results/{prefix}.bad.fasta\",\n    log:\n        \"logs/fqgz2fas/{prefix}.log\",\n    params:\n        extra=\"-min_len 2\",\n    threads: 2\n    wrapper:\n        \"master/bio/prinseq-plus-plus\"\n\n\nrule prinseq_plus_plus_fq2fasgz:\n    input:\n        \"reads/{prefix}.fastq\",\n    output:\n        good=\"results/{prefix}.fas.gz\",\n        bad=\"results/{prefix}.bad.fas.gz\",\n    log:\n        \"logs/fq2fasgz/{prefix}.log\",\n    params:\n        extra=\"-min_len 2\",\n    threads: 2\n    wrapper:\n        \"master/bio/prinseq-plus-plus\"\n\n\nrule prinseq_plus_plus_fqpe:\n    input:\n        \"reads/{prefix}.1.fastq.gz\",\n        \"reads/{prefix}.2.fastq.gz\",\n    output:\n        good=\"results/{prefix}.R1.fq.gz\",\n        good2=\"results/{prefix}.R2.fq.gz\",\n        single=\"results/{prefix}.single.R1.fq.gz\",\n        single2=\"results/{prefix}.single.R2.fq.gz\",\n        bad=\"results/{prefix}.bad.R1.fq.gz\",\n        bad2=\"results/{prefix}.bad.R2.fq.gz\",\n    log:\n        \"logs/fqpe/{prefix}.log\",\n    params:\n        extra=\"-min_len 2\",\n    threads: 2\n    wrapper:\n        \"master/bio/prinseq-plus-plus\"\n"
    },
    {
      "name": "printreads",
      "input": {
        "bam": "{sample}.bam",
        "bai": "{sample}.bai",
        "ref": "genome.fasta",
        "fai": "genome.fasta.fai",
        "dict": "genome.dict"
      },
      "output": {
        "bam": "{sample}.bqsr.bam",
        "bai": "{sample}.bqsr.bai"
      },
      "log": {
        "default": "logs/gatk/bqsr/{sample}.log"
      },
      "params": {
        "extra": "--defaultBaseQualities 20 --filter_reads_with_N_cigar"
      },
      "wrapper": {
        "default": "master/bio/gatk3/printreads"
      },
      "input_types": [
        "bam file",
        "recalibration table",
        "reference genome"
      ],
      "output_types": [
        "bam file"
      ],
      "rule": "rule printreads:\n    input:\n        bam=\"{sample}.bam\",\n        bai=\"{sample}.bai\",\n#        recal_data=\"{sample}.recal_data_table\",\n        ref=\"genome.fasta\",\n        fai=\"genome.fasta.fai\",\n        dict=\"genome.dict\",\n    output:\n        bam=\"{sample}.bqsr.bam\",\n        bai=\"{sample}.bqsr.bai\",\n    log:\n        \"logs/gatk/bqsr/{sample}.log\",\n    params:\n        extra=\"--defaultBaseQualities 20 --filter_reads_with_N_cigar\",  # optional\n    resources:\n        mem_mb=1024,\n    threads: 16\n    wrapper:\n        \"master/bio/gatk3/printreads\"\n"
    },
    {
      "name": "prosolo_calling",
      "input": {
        "single_cell": "data/mapped/{sc}.sorted.bam",
        "single_cell_index": "data/mapped/{sc}.sorted.bam.bai",
        "bulk": "data/mapped/{bulk}.sorted.bam",
        "bulk_index": "data/mapped/{bulk}.sorted.bam.bai",
        "ref": "data/genome.fa",
        "ref_idx": "data/genome.fa.fai",
        "candidates": "data/{sc}.{bulk}.prosolo_candidates.bcf"
      },
      "output": {
        "default": "variant_calling/{sc}.{bulk}.prosolo.bcf"
      },
      "log": {
        "default": "logs/prosolo_{sc}_{bulk}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/prosolo/single-cell-bulk"
      },
      "input_types": [
        "A position-sorted single cell bam file, with its index.",
        "A position-sorted bulk bam file, with its index.",
        "A reference genome sequence in fasta format, with its index.",
        "A vcf or bcf file specifying candidate sites to perform calling on."
      ],
      "output_types": [
        "Variants called in bcf format, with fine-grained posterior probabilities for single cell events."
      ],
      "rule": "rule prosolo_calling:\n    input:\n        single_cell = \"data/mapped/{sc}.sorted.bam\",\n        single_cell_index = \"data/mapped/{sc}.sorted.bam.bai\",\n        bulk = \"data/mapped/{bulk}.sorted.bam\",\n        bulk_index = \"data/mapped/{bulk}.sorted.bam.bai\",\n        ref = \"data/genome.fa\",\n        ref_idx = \"data/genome.fa.fai\",\n        candidates = \"data/{sc}.{bulk}.prosolo_candidates.bcf\",\n    output:\n        \"variant_calling/{sc}.{bulk}.prosolo.bcf\"\n    params:\n        extra = \"\"\n    threads:\n        1\n    log:\n        \"logs/prosolo_{sc}_{bulk}.log\"\n    wrapper:\n        \"master/bio/prosolo/single-cell-bulk\"\n"
    },
    {
      "name": "prosolo_fdr_control",
      "input": {
        "default": "variant_calling/{sc}.{bulk}.prosolo.bcf"
      },
      "output": {
        "default": "fdr_control/{sc}.{bulk}.prosolo.fdr.bcf"
      },
      "log": {
        "default": "logs/prosolo_{sc}_{bulk}.fdr.log"
      },
      "params": {
        "events": "ADO_TO_REF,HET",
        "fdr": 0.05
      },
      "wrapper": {
        "default": "master/bio/prosolo/control-fdr"
      },
      "input_types": [
        "Variants called with prosolo in vcf or bcf format, including the fine-grained posterior probabilities for single cell events."
      ],
      "output_types": [
        "bcf file with all variants that satisfy the chosen false discovery rate threshold with regard to the specified events."
      ],
      "rule": "rule prosolo_fdr_control:\n    input:\n         \"variant_calling/{sc}.{bulk}.prosolo.bcf\"\n    output:\n         \"fdr_control/{sc}.{bulk}.prosolo.fdr.bcf\"\n    threads:\n        1\n    params:\n        # comma-separated set of events for whose (joint)\n        # false discovery rate you want to control\n        events = \"ADO_TO_REF,HET\",\n        # false discovery rate to control for\n        fdr = 0.05\n    log:\n        \"logs/prosolo_{sc}_{bulk}.fdr.log\"\n    wrapper:\n        \"master/bio/prosolo/control-fdr\"\n"
    },
    {
      "name": "prune",
      "input": {
        "vg": "c.vg"
      },
      "output": {
        "pruned": "graph/c.pruned.vg"
      },
      "log": {
        "default": "logs/vg/prune/c.log"
      },
      "params": {
        "default": "-r"
      },
      "wrapper": {
        "default": "master/bio/vg/prune"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule prune:\n    input:\n        vg=\"c.vg\"\n    output:\n        pruned=\"graph/c.pruned.vg\"\n    params:\n        \"-r\"\n    log:\n        \"logs/vg/prune/c.log\"\n    threads:\n        4\n    wrapper:\n        \"master/bio/vg/prune\"\n"
    },
    {
      "name": "ptrimmer_pe",
      "input": {
        "r1": "resources/a.lane1_R1.fastq.gz",
        "r2": "resources/a.lane1_R2.fastq.gz",
        "primers": "resources/primers.txt"
      },
      "output": {
        "r1": "results/a.lane1_R1.fq.gz",
        "r2": "results/a.lane1_R2.fq.gz"
      },
      "log": {
        "default": "logs/ptrimmer/a.lane.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/ptrimmer"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule ptrimmer_pe:\n    input:\n        r1=\"resources/a.lane1_R1.fastq.gz\",\n        r2=\"resources/a.lane1_R2.fastq.gz\",\n        primers=\"resources/primers.txt\"\n    output:\n        r1=\"results/a.lane1_R1.fq.gz\",\n        r2=\"results/a.lane1_R2.fq.gz\"\n    log:\n        \"logs/ptrimmer/a.lane.log\"\n    wrapper:\n        \"master/bio/ptrimmer\"\n\nrule ptrimmer_se:\n    input:\n        r1=\"resources/a.lane1_R1.fastq.gz\",\n        primers=\"resources/primers.txt\"\n    output:\n        r1=\"results/a.lane1_R1.fq\",\n    log:\n        \"logs/ptrimmer/a.lane1.log\"\n    wrapper:\n        \"master/bio/ptrimmer\"\n"
    },
    {
      "name": "purge_dups",
      "input": {
        "paf": "split.self.paf.gz"
      },
      "output": {
        "default": "out/purge_dups.bed"
      },
      "log": {
        "default": "logs/purge_dups.log"
      },
      "params": {
        "extra": "-2"
      },
      "wrapper": {
        "default": "master/bio/purge_dups/purge_dups"
      },
      "input_types": [
        "Self-aligned split assembly in PAF format"
      ],
      "output_types": [
        "BED file"
      ],
      "rule": "rule purge_dups:\n    input:\n        paf=\"split.self.paf.gz\",\n        #cov=\"pbcstat.cov\",\n        #cutoff=\"calcuts.cutoffs\",\n    output:\n        \"out/purge_dups.bed\",\n    log:\n        \"logs/purge_dups.log\",\n    params:\n        extra=\"-2\",\n    threads: 1\n    wrapper:\n        \"master/bio/purge_dups/purge_dups\"\n"
    },
    {
      "name": "purge_dups_calcuts",
      "input": {
        "default": "pbcstat.stat"
      },
      "output": {
        "default": "out/calcuts.cutoffs"
      },
      "log": {
        "default": "logs/calcuts.log"
      },
      "params": {
        "extra": "-l 2 -m 4 -u 8"
      },
      "wrapper": {
        "default": "master/bio/purge_dups/calcuts"
      },
      "input_types": [
        "stats file"
      ],
      "output_types": [
        "coverage cut-offs"
      ],
      "rule": "rule purge_dups_calcuts:\n    input:\n        \"pbcstat.stat\",\n    output:\n        \"out/calcuts.cutoffs\",\n    log:\n        \"logs/calcuts.log\",\n    params:\n        extra=\"-l 2 -m 4 -u 8\",\n    threads: 1\n    wrapper:\n        \"master/bio/purge_dups/calcuts\"\n"
    },
    {
      "name": "purge_dups_get_seqs",
      "input": {
        "fas": "genome.fasta",
        "bed": "purge_dups.bed"
      },
      "output": {
        "hap": "out/get_seqs.hap.fasta",
        "purged": "out/get_seqs.purged.fasta"
      },
      "log": {
        "default": "logs/get_seqs.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/purge_dups/get_seqs"
      },
      "input_types": [
        "BED file",
        "FASTA file"
      ],
      "output_types": [
        "purged FASTA file"
      ],
      "rule": "rule purge_dups_get_seqs:\n    input:\n        fas=\"genome.fasta\",\n        bed=\"purge_dups.bed\",\n    output:\n        hap=\"out/get_seqs.hap.fasta\",\n        purged=\"out/get_seqs.purged.fasta\",\n    log:\n        \"logs/get_seqs.log\",\n    params:\n        extra=\"\",\n    threads: 1\n    wrapper:\n        \"master/bio/purge_dups/get_seqs\"\n"
    },
    {
      "name": "purge_dups_ngscstat",
      "input": {
        "bam": "reads.bam"
      },
      "output": {
        "cov": "out/ngscstat.cov",
        "stat": "out/ngscstat.stat"
      },
      "log": {
        "default": "logs/ngscstat.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/purge_dups/ngscstat"
      },
      "input_types": [
        "mapped reads in PAF format"
      ],
      "output_types": [
        "coverage",
        "stats"
      ],
      "rule": "rule purge_dups_ngscstat:\n    input:\n        bam=\"reads.bam\",\n    output:\n        cov=\"out/ngscstat.cov\",\n        stat=\"out/ngscstat.stat\",\n    log:\n        \"logs/ngscstat.log\",\n    params:\n        extra=\"\",\n    threads: 1\n    wrapper:\n        \"master/bio/purge_dups/ngscstat\"\n"
    },
    {
      "name": "purge_dups_pbcstat",
      "input": {
        "paf": "HiFi_dataset_01.paf.gz"
      },
      "output": {
        "cov": "out/pbcstat.cov",
        "stat": "out/pbcstat.stat"
      },
      "log": {
        "default": "logs/pbcstat.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/purge_dups/pbcstat"
      },
      "input_types": [
        "mapped reads in PAF format"
      ],
      "output_types": [
        "coverage",
        "stats"
      ],
      "rule": "rule purge_dups_pbcstat:\n    input:\n        paf=\"HiFi_dataset_01.paf.gz\",\n    output:\n        cov=\"out/pbcstat.cov\",\n        stat=\"out/pbcstat.stat\",\n    log:\n        \"logs/pbcstat.log\",\n    params:\n        extra=\"\",\n    threads: 1\n    wrapper:\n        \"master/bio/purge_dups/pbcstat\"\n"
    },
    {
      "name": "purge_dups_split_fa",
      "input": {
        "default": "{a}.fasta"
      },
      "output": {
        "default": "out/{a}.split"
      },
      "log": {
        "default": "logs/{a}.split_fa.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/purge_dups/split_fa"
      },
      "input_types": [
        "stats file"
      ],
      "output_types": [
        "coverage cut-offs"
      ],
      "rule": "rule purge_dups_split_fa:\n    input:\n        \"{a}.fasta\",\n    output:\n        \"out/{a}.split\",\n    log:\n        \"logs/{a}.split_fa.log\",\n    params:\n        extra=\"\",\n    threads: 1\n    wrapper:\n        \"master/bio/purge_dups/split_fa\"\n"
    },
    {
      "name": "qualimap",
      "input": {
        "bam": "mapped/a.bam",
        "gtf": "annotation.gtf"
      },
      "output": {
        "default": "directory('qc/a')"
      },
      "log": {
        "default": "logs/qualimap/rna-seq/a.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/qualimap/rnaseq"
      },
      "input_types": [
        "BAM file of RNA-seq data aligned to genome",
        "GTF file containing genome annotations"
      ],
      "output_types": [
        "QC report in html/pdf format"
      ],
      "rule": "rule qualimap:\n    input:\n        # BAM aligned, splicing-aware, to reference genome\n        bam=\"mapped/a.bam\",\n        # GTF containing transcript, gene, and exon data\n        gtf=\"annotation.gtf\" \n    output:\n        directory(\"qc/a\")\n    log:\n        \"logs/qualimap/rna-seq/a.log\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    wrapper:\n        \"master/bio/qualimap/rnaseq\"\n"
    },
    {
      "name": "quast",
      "input": {
        "fasta": "genome.fasta",
        "ref": "genome.fasta"
      },
      "output": {
        "report_html": "{sample}/report.html",
        "report_tex": "{sample}/report.tex",
        "report_txt": "{sample}/report.txt",
        "report_pdf": "{sample}/report.pdf",
        "report_tsv": "{sample}/report.tsv",
        "treport_tex": "{sample}/treport.tex",
        "treport_txt": "{sample}/treport.txt",
        "treport_tsv": "{sample}/treport.tsv",
        "stats_cum": "{sample}/stats/cumulative.pdf",
        "stats_gc_plot": "{sample}/stats/gc.pdf",
        "stats_gc_icarus": "{sample}/stats/gc.icarus.txt",
        "stats_gc_fasta": "{sample}/stats/gc_fasta.pdf",
        "stats_ngx": "{sample}/stats/NGx.pdf",
        "stats_nx": "{sample}/stats/Nx.pdf",
        "contigs": "{sample}/contigs.all_alignments.tsv",
        "contigs_mis": "{sample}/contigs.mis_contigs.info",
        "icarus": "{sample}/icarus.html",
        "icarus_viewer": "{sample}/icarus_viewer.html"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "--min-contig 5 --min-identity 95.0"
      },
      "wrapper": {
        "default": "master/bio/quast"
      },
      "input_types": [
        "Sequences in FASTA format",
        "Reference genome (optional)",
        "GFF (optional)",
        "Paired end read (optional)",
        "Mate-pair reads (optional)",
        "Unpaired reads (optional)",
        "PacBio SMRT reads (optional)",
        "Oxford Nanopore reads (optional)",
        "Mapped reads against the reference in SAM/BAM (optional)",
        "Mapped reads against each of the assemblies in SAM/BAM (same order; optional)",
        "Structural variants in BEDPE (optional)"
      ],
      "output_types": [
        "Assessment summary in plain text format",
        "Tab-separated version of the summary",
        "LaTeX version of the summary",
        "Icarus main menu with links to interactive viewers",
        "PDF report of all plots combined with all tables",
        "HTML version of the report with interactive plots inside",
        "Report on misassemblies",
        "Report on unaligned and partially unaligned contigs",
        "Report on k-mer-based metrics",
        "Report on mapped reads statistics."
      ],
      "rule": "rule quast:\n    input:\n        fasta=\"genome.fasta\",\n        ref=\"genome.fasta\",\n        #gff=\"annotations.gff\",\n        #pe1=\"reads_R1.fastq\",\n        #pe2=\"reads_R2.fastq\",\n        #pe12=\"reads.fastq\",\n        #mp1=\"matereads_R1.fastq\",\n        #mp2=\"matereads_R2.fastq\",\n        #mp12=\"matereads.fastq\",\n        #single=\"single.fastq\",\n        #pacbio=\"pacbio.fas\",\n        #nanopore=\"nanopore.fastq\",\n        #ref_bam=\"ref.bam\",\n        #ref_sam=\"ref.sam\",\n        #bam=[\"s1.bam\",\"s2.bam\"],\n        #sam=[\"s1.sam\",\"s2.sam\"],\n        #sv_bedpe=\"sv.bed\",\n    output:\n        report_html=\"{sample}/report.html\",\n        report_tex=\"{sample}/report.tex\",\n        report_txt=\"{sample}/report.txt\",\n        report_pdf=\"{sample}/report.pdf\",\n        report_tsv=\"{sample}/report.tsv\",\n        treport_tex=\"{sample}/treport.tex\",\n        treport_txt=\"{sample}/treport.txt\",\n        treport_tsv=\"{sample}/treport.tsv\",\n        stats_cum=\"{sample}/stats/cumulative.pdf\",\n        stats_gc_plot=\"{sample}/stats/gc.pdf\",\n        stats_gc_icarus=\"{sample}/stats/gc.icarus.txt\",\n        stats_gc_fasta=\"{sample}/stats/gc_fasta.pdf\",\n        stats_ngx=\"{sample}/stats/NGx.pdf\",\n        stats_nx=\"{sample}/stats/Nx.pdf\",\n        contigs=\"{sample}/contigs.all_alignments.tsv\",\n        contigs_mis=\"{sample}/contigs.mis_contigs.info\",\n        icarus=\"{sample}/icarus.html\",\n        icarus_viewer=\"{sample}/icarus_viewer.html\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"--min-contig 5 --min-identity 95.0\",\n    wrapper:\n        \"master/bio/quast\"\n"
    },
    {
      "name": "razers3",
      "input": {
        "reads": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ]
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/razers3/{sample}.log"
      },
      "params": {
        "genome": "genome.fasta",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/razers3"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule razers3:\n    input:\n        # list of input reads\n        reads=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"]\n    output:\n        # output format is automatically inferred from file extension. Can be bam/sam or other formats.\n        \"mapped/{sample}.bam\"\n    log:\n        \"logs/razers3/{sample}.log\"\n    params:\n        # the reference genome\n        genome=\"genome.fasta\",\n        # additional parameters\n        extra=\"\"\n    threads: 8\n    wrapper:\n        \"master/bio/razers3\"\n"
    },
    {
      "name": "realignertargetcreator",
      "input": {
        "bam": "{sample}.bam",
        "bai": "{sample}.bai",
        "ref": "genome.fasta",
        "fai": "genome.fasta.fai",
        "dict": "genome.dict",
        "known": "dbsnp.vcf.gz",
        "known_idx": "dbsnp.vcf.gz.tbi"
      },
      "output": {
        "intervals": "{sample}.intervals"
      },
      "log": {
        "default": "logs/gatk/realignertargetcreator/{sample}.log"
      },
      "params": {
        "extra": "--defaultBaseQualities 20 --filter_reads_with_N_cigar"
      },
      "wrapper": {
        "default": "master/bio/gatk3/realignertargetcreator"
      },
      "input_types": [
        "bam file",
        "reference genome",
        "bed file (optional)",
        "vcf files known variation (optional)"
      ],
      "output_types": [
        "target intervals",
        "temp dir (optional)"
      ],
      "rule": "rule realignertargetcreator:\n    input:\n        bam=\"{sample}.bam\",\n        bai=\"{sample}.bai\",\n        ref=\"genome.fasta\",\n        fai=\"genome.fasta.fai\",\n        dict=\"genome.dict\",\n        known=\"dbsnp.vcf.gz\",\n        known_idx=\"dbsnp.vcf.gz.tbi\",\n    output:\n        intervals=\"{sample}.intervals\",\n    log:\n        \"logs/gatk/realignertargetcreator/{sample}.log\",\n    params:\n        extra=\"--defaultBaseQualities 20 --filter_reads_with_N_cigar\",  # optional\n    resources:\n        mem_mb=1024,\n    threads: 16\n    wrapper:\n        \"master/bio/gatk3/realignertargetcreator\"\n"
    },
    {
      "name": "rebaler",
      "input": {
        "reference": "ref.fa",
        "reads": "{sample}.fq"
      },
      "output": {
        "assembly": "{sample}.asm.fa"
      },
      "log": {
        "default": "logs/rebaler/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/rebaler"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule rebaler:\n    input:\n        reference=\"ref.fa\",\n        reads=\"{sample}.fq\",\n    output:\n        assembly=\"{sample}.asm.fa\",\n    log:\n        \"logs/rebaler/{sample}.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/rebaler\"\n"
    },
    {
      "name": "replace_bases",
      "input": {
        "default": "{sample}.rna.fa"
      },
      "output": {
        "default": "{sample}.dna.fa"
      },
      "log": {
        "default": "logs/fastaq/replace_bases/test/{sample}.log"
      },
      "params": {
        "old_base": "U",
        "new_base": "T"
      },
      "wrapper": {
        "default": "master/bio/pyfastaq/replace_bases"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule replace_bases:\n    input:\n        \"{sample}.rna.fa\"\n    output:\n        \"{sample}.dna.fa\",\n    params:\n        old_base = \"U\",\n        new_base = \"T\",\n    log:\n        \"logs/fastaq/replace_bases/test/{sample}.log\"\n    wrapper:\n        \"master/bio/pyfastaq/replace_bases\"\n"
    },
    {
      "name": "replace_rg",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "fixed-rg/{sample}.bam"
      },
      "log": {
        "default": "logs/picard/replace_rg/{sample}.log"
      },
      "params": {
        "extra": "--RGLB lib1 --RGPL illumina --RGPU {sample} --RGSM {sample}"
      },
      "wrapper": {
        "default": "master/bio/picard/addorreplacereadgroups"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "bam file with added or replaced read groups"
      ],
      "rule": "rule replace_rg:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"fixed-rg/{sample}.bam\",\n    log:\n        \"logs/picard/replace_rg/{sample}.log\",\n    params:\n        extra=\"--RGLB lib1 --RGPL illumina --RGPU {sample} --RGSM {sample}\",\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/addorreplacereadgroups\"\n"
    },
    {
      "name": "revert_bam",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "revert/{sample}.bam"
      },
      "log": {
        "default": "logs/picard/revert_sam/{sample}.log"
      },
      "params": {
        "extra": "--SANITIZE true"
      },
      "wrapper": {
        "default": "master/bio/picard/revertsam"
      },
      "input_types": [
        "sam/bam file"
      ],
      "output_types": [
        "sam/bam file."
      ],
      "rule": "rule revert_bam:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"revert/{sample}.bam\",\n    log:\n        \"logs/picard/revert_sam/{sample}.log\",\n    params:\n        extra=\"--SANITIZE true\",  # optional: Extra arguments for picard.\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/revertsam\"\n"
    },
    {
      "name": "rsem_generate_data_matrix",
      "input": {
        "default": [
          "a.genes.results",
          "b.genes.results"
        ]
      },
      "output": {
        "default": "genes.results"
      },
      "log": {
        "default": "logs/rsem/generate_data_matrix.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/rsem/generate-data-matrix"
      },
      "input_types": [
        "a list of rsem results files"
      ],
      "output_types": [
        "Quantification results summarized by allele/gene/isoform per sample"
      ],
      "rule": "rule rsem_generate_data_matrix:\n    input:\n        # one or more expression files created by rsem-calculate-expression\n        [\"a.genes.results\", \"b.genes.results\"],\n    output:\n        # a tsv containing each sample in the input as a column\n        \"genes.results\",\n    params:\n        # optional additional parameters\n        extra=\"\",\n    log:\n        \"logs/rsem/generate_data_matrix.log\",\n    wrapper:\n        \"master/bio/rsem/generate-data-matrix\"\n"
    },
    {
      "name": "rubic",
      "input": {
        "seg": "{samples}/segments.txt",
        "markers": "{samples}/markers.txt"
      },
      "output": {
        "out_gains": "out/{samples}/gains.txt",
        "out_losses": "out/{samples}/losses.txt",
        "out_plots": "directory('out/{samples}/plots')"
      },
      "log": {
        "default": "logs/{samples}/rubic.log"
      },
      "params": {
        "fdr": 0.2
      },
      "wrapper": {
        "default": "master/bio/rubic"
      },
      "input_types": {
        "seg": "segmentation file containing copy number profiles from multiple tumor samples",
        "markers": "file with marker positions",
        "genefile": "file path to use custom gene file (optional, do note specify to use default file)"
      },
      "output_types": {
        "out_gains": "file with recurrent gains",
        "out_losses": "file with recurrent losses",
        "out_plots": "directory with plots per chromosome (possibly causes problems for the worklfow due to the time stamp)"
      },
      "rule": "rule rubic:\n    input:\n        seg=\"{samples}/segments.txt\",\n        markers=\"{samples}/markers.txt\"\n#        genefile=\"path/to/genefile\"\n    output:\n        out_gains=\"out/{samples}/gains.txt\",\n        out_losses=\"out/{samples}/losses.txt\",\n        out_plots=directory(\"out/{samples}/plots\") #only possible to provide output directory for plots\n    log:\n        \"logs/{samples}/rubic.log\"\n    params:\n        fdr=0.2,\n    wrapper:\n        \"master/bio/rubic\"\n"
    },
    {
      "name": "run_assembly_stats",
      "input": {
        "assembly": "{sample}.fasta"
      },
      "output": {
        "assembly_stats": "{sample}_stats.txt"
      },
      "log": {
        "default": "logs/{sample}.assembly-stats.log"
      },
      "params": {
        "extra": "-t"
      },
      "wrapper": {
        "default": "master/bio/assembly-stats"
      },
      "input_types": [
        {
          "assembly": "Genomic assembly (fasta format)"
        }
      ],
      "output_types": [
        {
          "assembly_stats": "Assembly statistics (format of your choosing, default = tab-delimited)"
        }
      ],
      "rule": "rule run_assembly_stats:\n    input:\n        #Input assembly\n        assembly=\"{sample}.fasta\",\n    output:\n        #Assembly statistics\n        assembly_stats=\"{sample}_stats.txt\",\n    params:\n        # Tab delimited output, with a header, is set as the default. Other options are available:\n        #   -l <int>\n        #       Minimum length cutoff for each sequence.\n        #       Sequences shorter than the cutoff will be ignored [1]\n        #   -s\n        #       Print 'grep friendly' output\n        #   -t\n        #       Print tab-delimited output\n        #   -u\n        #       Print tab-delimited output with no header line\n        # If you want to add multiple options just delimit them with a space.\n        # Note that you can only pick one output format\n        # Check https://github.com/sanger-pathogens/assembly-stats for more details\n        extra=\"-t\",\n    log:\n        \"logs/{sample}.assembly-stats.log\",\n    threads: 1\n    wrapper:\n        \"master/bio/assembly-stats\"\n"
    },
    {
      "name": "run_busco",
      "input": {
        "default": "protein.fasta"
      },
      "output": {
        "short_json": "txome_busco/short_summary.json",
        "short_txt": "txome_busco/short_summary.txt",
        "full_table": "txome_busco/full_table.tsv",
        "miss_list": "txome_busco/busco_missing.tsv",
        "dataset_dir": "directory('resources/busco_downloads')"
      },
      "log": {
        "default": "logs/proteins_busco.log"
      },
      "params": {
        "mode": "proteins",
        "lineage": "stramenopiles_odb10",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/busco"
      },
      "input_types": [
        "Path to assembly fasta"
      ],
      "output_types": [
        {
          "out_dir": "Path to annotation quality files"
        },
        {
          "dataset_dir": "Optional path to dataset directory"
        },
        {
          "short_txt": "Optional path to plain text results summary. Requires parameter `lineage`."
        },
        {
          "short_json": "Optional path to json formatted results summary. Requires parameter `lineage`."
        },
        {
          "full_table": "Optional path to TSV formatted results. Requires parameter `lineage`."
        },
        {
          "miss_list": "Contains a list of missing BUSCOs. Requires parameter `lineage`."
        }
      ],
      "rule": "rule run_busco:\n    input:\n        \"protein.fasta\",\n    output:\n        short_json=\"txome_busco/short_summary.json\",\n        short_txt=\"txome_busco/short_summary.txt\",\n        full_table=\"txome_busco/full_table.tsv\",\n        miss_list=\"txome_busco/busco_missing.tsv\",\n        dataset_dir=directory(\"resources/busco_downloads\"),\n    log:\n        \"logs/proteins_busco.log\",\n    params:\n        mode=\"proteins\",\n        lineage=\"stramenopiles_odb10\",\n        # optional parameters\n        extra=\"\",\n    threads: 8\n    wrapper:\n        \"master/bio/busco\"\n\n\nrule run_busco_euk:\n    input:\n        \"protein.fasta\",\n    output:\n        out_dir=directory(\"txome_busco/euk\"),\n        dataset_dir=directory(\"resources/busco_downloads\"),\n    log:\n        \"logs/proteins_busco_euk.log\",\n    params:\n        mode=\"proteins\",\n        # optional parameters\n        extra=\"--auto-lineage-euk\",\n    threads: 8\n    wrapper:\n        \"master/bio/busco\"\n\n\nrule run_busco_prok:\n    input:\n        \"protein.fasta\",\n    output:\n        out_dir=directory(\"txome_busco/prok\"),\n        dataset_dir=directory(\"resources/busco_downloads\"),\n    log:\n        \"logs/proteins_busco_prok.log\",\n    params:\n        mode=\"proteins\",\n        # optional parameters\n        extra=\"--auto-lineage-prok\",\n    threads: 8\n    wrapper:\n        \"master/bio/busco\"\n"
    },
    {
      "name": "run_merqury_haploid",
      "input": {
        "fasta": "in_files/hap1.fasta",
        "meryldb": "in_files/meryldb"
      },
      "output": {
        "filt": "results/haploid/meryldb.filt",
        "hist": "results/haploid/meryldb.hist",
        "hist_ploidy": "results/haploid/meryldb.hist.ploidy",
        "completeness_stats": "results/haploid/out.completeness.stats",
        "dist_only_hist": "results/haploid/out.dist.only.hist",
        "qv": "results/haploid/out.qv",
        "spectra_asm_hist": "results/haploid/out.spectra_asm.hist",
        "spectra_asm_ln_png": "results/haploid/out.spectra_asm.png",
        "fas1_only_bed": "results/haploid/hap1.bed",
        "fas1_only_wig": "results/haploid/hap1.wig",
        "fas1_only_hist": "results/haploid/hap1.hist",
        "fas1_qv": "results/haploid/hap1.qv",
        "fas1_spectra_cn_hist": "results/haploid/hap1.spectra.hist",
        "fas1_spectra_cn_ln_png": "results/haploid/hap1.spectra.png"
      },
      "log": {
        "std": "logs/haploid.log",
        "spectra_cn": "logs/haploid.spectra-cn.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/merqury"
      },
      "input_types": [
        {
          "fasta": "one on two assembly fasta file(s)"
        },
        {
          "meryldb": "meryl database"
        },
        {
          "meryldb_parents": "meryl database of parents (for trio analysis)"
        }
      ],
      "output_types": [
        "annotation quality files (depends on running mode)"
      ],
      "rule": "rule run_merqury_haploid:\n    input:\n        fasta=\"in_files/hap1.fasta\",\n        meryldb=\"in_files/meryldb\",\n    output:\n        # meryldb output\n        filt=\"results/haploid/meryldb.filt\",\n        hist=\"results/haploid/meryldb.hist\",\n        hist_ploidy=\"results/haploid/meryldb.hist.ploidy\",\n        # general output\n        completeness_stats=\"results/haploid/out.completeness.stats\",\n        dist_only_hist=\"results/haploid/out.dist.only.hist\",\n        qv=\"results/haploid/out.qv\",\n        spectra_asm_hist=\"results/haploid/out.spectra_asm.hist\",\n        spectra_asm_ln_png=\"results/haploid/out.spectra_asm.png\",\n        # haplotype-specific output\n        fas1_only_bed=\"results/haploid/hap1.bed\",\n        fas1_only_wig=\"results/haploid/hap1.wig\",\n        fas1_only_hist=\"results/haploid/hap1.hist\",\n        fas1_qv=\"results/haploid/hap1.qv\",\n        fas1_spectra_cn_hist=\"results/haploid/hap1.spectra.hist\",\n        fas1_spectra_cn_ln_png=\"results/haploid/hap1.spectra.png\",\n    log:\n        std=\"logs/haploid.log\",\n        spectra_cn=\"logs/haploid.spectra-cn.log\",\n    threads: 1\n    wrapper:\n        \"master/bio/merqury\"\n\n\nrule run_merqury_diploid:\n    input:\n        fasta=[\"in_files/hap1.fasta\", \"in_files/hap2.fasta\"],\n        meryldb=\"in_files/meryldb\",\n    output:\n        # meryldb output\n        filt=\"results/diploid/meryldb.filt\",\n        hist=\"results/diploid/meryldb.hist\",\n        hist_ploidy=\"results/diploid/meryldb.hist.ploidy\",\n        # general output\n        completeness_stats=\"results/diploid/out.completeness.stats\",\n        dist_only_hist=\"results/diploid/out.dist.only.hist\",\n        only_hist=\"results/diploid/out.only.hist\",\n        qv=\"results/diploid/out.qv\",\n        spectra_asm_hist=\"results/diploid/out.spectra_asm.hist\",\n        spectra_asm_ln_png=\"results/diploid/out.spectra_asm.png\",\n        spectra_cn_hist=\"results/diploid/out.spectra_cn.hist\",\n        spectra_cn_ln_png=\"results/diploid/out.spectra_cn.png\",\n        # haplotype-specific output\n        fas1_only_bed=\"results/diploid/hap1.bed\",\n        fas1_only_wig=\"results/diploid/hap1.wig\",\n        fas1_only_hist=\"results/diploid/hap1.hist\",\n        fas1_qv=\"results/diploid/hap1.qv\",\n        fas1_spectra_cn_hist=\"results/diploid/hap1.spectra.hist\",\n        fas1_spectra_cn_ln_png=\"results/diploid/hap1.spectra.png\",\n        fas2_only_bed=\"results/diploid/hap2.bed\",\n        fas2_only_wig=\"results/diploid/hap2.wig\",\n        fas2_only_hist=\"results/diploid/hap2.hist\",\n        fas2_qv=\"results/diploid/hap2.qv\",\n        fas2_spectra_cn_hist=\"results/diploid/hap2.spectra.hist\",\n        fas2_spectra_cn_ln_png=\"results/diploid/hap2.spectra.png\",\n    log:\n        std=\"logs/diploid.log\",\n        spectra_cn=\"logs/diploid.spectra-cn.log\",\n    threads: 1\n    wrapper:\n        \"master/bio/merqury\"\n"
    },
    {
      "name": "run_mlst",
      "input": {
        "assembly": "{sample}.fasta"
      },
      "output": {
        "mlst": "{sample}_mlst.txt"
      },
      "log": {
        "default": "logs/{sample}.mlst.log"
      },
      "params": {
        "extra": "--nopath"
      },
      "wrapper": {
        "default": "master/bio/mlst"
      },
      "input_types": [
        "Genomic assembly (fasta format)"
      ],
      "output_types": [
        "Returns a tab-separated line containing the filename, matching PubMLST scheme name, ST (sequence type) and the allele IDs. Other output formats are also available (eg. CSV, JSON)"
      ],
      "rule": "rule run_mlst:\n    input:\n        #Input assembly\n        assembly=\"{sample}.fasta\",\n    output:\n        #Tab delimited mlst designation\n        mlst=\"{sample}_mlst.txt\",\n    params:\n    #extra parameters should be space delimited\n        # SYNOPSIS\n        #   Automatic MLST calling from assembled contigs\n        # USAGE\n        #   % mlst --list                                            # list known schemes\n        #   % mlst [options] <contigs.{fasta,gbk,embl}[.gz]          # auto-detect scheme\n        #   % mlst --scheme <scheme> <contigs.{fasta,gbk,embl}[.gz]> # force a scheme\n        # GENERAL\n        #   --help            This help\n        #   --version         Print version and exit(default ON)\n        #   --check           Just check dependencies and exit (default OFF)\n        #   --quiet           Quiet - no stderr output (default OFF)\n        #   --threads [N]     Number of BLAST threads (suggest GNU Parallel instead) (default '1')\n        #   --debug           Verbose debug output to stderr (default OFF)\n        # SCHEME\n        #   --scheme [X]      Don't autodetect, force this scheme on all inputs (default '')\n        #   --list            List available MLST scheme names (default OFF)\n        #   --longlist        List allelles for all MLST schemes (default OFF)\n        #   --exclude [X]     Ignore these schemes (comma sep. list) (default 'ecoli_2,abaumannii')\n        # OUTPUT\n        #   --csv             Output CSV instead of TSV (default OFF)\n        #   --json [X]        Also write results to this file in JSON format (default '')\n        #   --label [X]       Replace FILE with this name instead (default '')\n        #   --nopath          Strip filename paths from FILE column (default OFF)\n        #   --novel [X]       Save novel alleles to this FASTA file (default '')\n        #   --legacy          Use old legacy output with allele header row (requires --scheme) (default OFF)\n        # SCORING\n        #   --minid [n.n]     DNA %identity of full allelle to consider 'similar' [~] (default '95')\n        #   --mincov [n.n]    DNA %cov to report partial allele at all [?] (default '10')\n        #   --minscore [n.n]  Minumum score out of 100 to match a scheme (when auto --scheme) (default '50')\n        # PATHS\n        #   --blastdb [X]     BLAST database\n        #   --datadir [X]     PubMLST data\n        # HOMEPAGE\n        #   https://github.com/tseemann/mlst - Torsten Seemann\n        extra=\"--nopath\",\n    log:\n        \"logs/{sample}.mlst.log\",\n    threads: 1\n    wrapper:\n        \"master/bio/mlst\"\n"
    },
    {
      "name": "salmon_index",
      "input": {
        "sequences": "assembly/transcriptome.fasta"
      },
      "output": {
        "default": "multiext('salmon/transcriptome_index/', 'complete_ref_lens.bin', 'ctable.bin', 'ctg_offsets.bin', 'duplicate_clusters.tsv', 'info.json', 'mphf.bin', 'pos.bin', 'pre_indexing.log', 'rank.bin', 'refAccumLengths.bin', 'ref_indexing.log', 'reflengths.bin', 'refseq.bin', 'seq.bin', 'versionInfo.json')"
      },
      "log": {
        "default": "logs/salmon/transcriptome_index.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/salmon/index"
      },
      "input_types": [
        {
          "sequences": "Path to sequences to index with Salmon. This can be transcriptome sequences or gentrome."
        },
        {
          "decoys": "Optional path to decoy sequences name, in case the above `sequence` was a gentrome."
        }
      ],
      "output_types": [
        "indexed assembly"
      ],
      "rule": "rule salmon_index:\n    input:\n        sequences=\"assembly/transcriptome.fasta\",\n    output:\n        multiext(\n            \"salmon/transcriptome_index/\",\n            \"complete_ref_lens.bin\",\n            \"ctable.bin\",\n            \"ctg_offsets.bin\",\n            \"duplicate_clusters.tsv\",\n            \"info.json\",\n            \"mphf.bin\",\n            \"pos.bin\",\n            \"pre_indexing.log\",\n            \"rank.bin\",\n            \"refAccumLengths.bin\",\n            \"ref_indexing.log\",\n            \"reflengths.bin\",\n            \"refseq.bin\",\n            \"seq.bin\",\n            \"versionInfo.json\",\n        ),\n    log:\n        \"logs/salmon/transcriptome_index.log\",\n    threads: 2\n    params:\n        # optional parameters\n        extra=\"\",\n    wrapper:\n        \"master/bio/salmon/index\"\n"
    },
    {
      "name": "salmon_quant_reads",
      "input": {
        "r1": "reads/{sample}_1.fq.gz",
        "r2": "reads/{sample}_2.fq.gz",
        "index": "salmon/transcriptome_index"
      },
      "output": {
        "quant": "salmon/{sample}/quant.sf",
        "lib": "salmon/{sample}/lib_format_counts.json"
      },
      "log": {
        "default": "logs/salmon/{sample}.log"
      },
      "params": {
        "libtype": "A",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/salmon/quant"
      },
      "input_types": [
        {
          "index": "Path to Salmon indexed sequences, see `bio/salmon/index`"
        },
        {
          "gtf": "Optional path to a GTF formatted genome annotation"
        },
        {
          "r": "Path to unpaired reads"
        },
        {
          "r1": "Path to upstream reads file."
        },
        {
          "r2": "Path to downstream reads file."
        }
      ],
      "output_types": [
        "Path to quantification file",
        {
          "bam": "Path to pseudo-bam file"
        }
      ],
      "rule": "rule salmon_quant_reads:\n    input:\n        # If you have multiple fastq files for a single sample (e.g. technical replicates)\n        # use a list for r1 and r2.\n        r1=\"reads/{sample}_1.fq.gz\",\n        r2=\"reads/{sample}_2.fq.gz\",\n        index=\"salmon/transcriptome_index\",\n    output:\n        quant=\"salmon/{sample}/quant.sf\",\n        lib=\"salmon/{sample}/lib_format_counts.json\",\n    log:\n        \"logs/salmon/{sample}.log\",\n    params:\n        # optional parameters\n        libtype=\"A\",\n        extra=\"\",\n    threads: 2\n    wrapper:\n        \"master/bio/salmon/quant\"\n"
    },
    {
      "name": "salsa2",
      "input": {
        "fas": "{sample}.fasta",
        "fai": "{sample}.fasta.fai",
        "bed": "{sample}.bed"
      },
      "output": {
        "agp": "out/{sample}.agp",
        "fas": "out/{sample}.fas"
      },
      "log": {
        "default": "logs/salsa2/{sample}.log"
      },
      "params": {
        "enzyme": "CTTAAG",
        "extra": "--clean yes"
      },
      "wrapper": {
        "default": "master/bio/salsa2"
      },
      "input_types": [
        "BED file",
        "FASTA file",
        "FASTA index file"
      ],
      "output_types": [
        "polished assembly (FASTA format)",
        "polished assembly (AGP format)"
      ],
      "rule": "rule salsa2:\n    input:\n        fas=\"{sample}.fasta\",\n        fai=\"{sample}.fasta.fai\",\n        bed=\"{sample}.bed\",\n    output:\n        agp=\"out/{sample}.agp\",\n        fas=\"out/{sample}.fas\",\n    log:\n        \"logs/salsa2/{sample}.log\",\n    params:\n        enzyme=\"CTTAAG\",  # optional\n        extra=\"--clean yes\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/salsa2\"\n"
    },
    {
      "name": "sambamba_flagstat",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.stats.txt"
      },
      "log": {
        "default": "logs/sambamba-flagstat/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/sambamba/flagstat"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "flag statistics"
      ],
      "rule": "rule sambamba_flagstat:\n    input:\n        \"mapped/{sample}.bam\"\n    output:\n        \"mapped/{sample}.stats.txt\"\n    params:\n        extra=\"\"  # optional parameters\n    log:\n        \"logs/sambamba-flagstat/{sample}.log\"\n    threads: 1\n    wrapper:\n        \"master/bio/sambamba/flagstat\"\n"
    },
    {
      "name": "sambamba_index",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.bam.bai"
      },
      "log": {
        "default": "logs/sambamba-index/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/sambamba/index"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "bam index"
      ],
      "rule": "rule sambamba_index:\n    input:\n        \"mapped/{sample}.bam\"\n    output:\n        \"mapped/{sample}.bam.bai\"\n    params:\n        extra=\"\"  # optional parameters\n    log:\n        \"logs/sambamba-index/{sample}.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/sambamba/index\"\n"
    },
    {
      "name": "sambamba_markdup",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.rmdup.bam"
      },
      "log": {
        "default": "logs/sambamba-markdup/{sample}.log"
      },
      "params": {
        "extra": "-r"
      },
      "wrapper": {
        "default": "master/bio/sambamba/markdup"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "deduplicated bam file"
      ],
      "rule": "rule sambamba_markdup:\n    input:\n        \"mapped/{sample}.bam\"\n    output:\n        \"mapped/{sample}.rmdup.bam\"\n    params:\n        extra=\"-r\"  # optional parameters\n    log:\n        \"logs/sambamba-markdup/{sample}.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/sambamba/markdup\"\n"
    },
    {
      "name": "sambamba_merge",
      "input": {
        "default": [
          "mapped/{sample}_1.sorted.bam",
          "mapped/{sample}_2.sorted.bam"
        ]
      },
      "output": {
        "default": "mapped/{sample}.merged.bam"
      },
      "log": {
        "default": "logs/sambamba-merge/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/sambamba/merge"
      },
      "input_types": [
        "sorted bam files"
      ],
      "output_types": [
        "merged bam file"
      ],
      "rule": "rule sambamba_merge:\n    input:\n        [\"mapped/{sample}_1.sorted.bam\", \"mapped/{sample}_2.sorted.bam\"]\n    output:\n        \"mapped/{sample}.merged.bam\"\n    params:\n        extra=\"\"  # optional parameters\n    log:\n        \"logs/sambamba-merge/{sample}.log\"\n    threads: 1\n    wrapper:\n        \"master/bio/sambamba/merge\"\n"
    },
    {
      "name": "sambamba_slice",
      "input": {
        "bam": "mapped/{sample}.bam",
        "bai": "mapped/{sample}.bam.bai"
      },
      "output": {
        "default": "mapped/{sample}.region.bam"
      },
      "log": {
        "default": "logs/sambamba-slice/{sample}.log"
      },
      "params": {
        "region": "xx:1-10"
      },
      "wrapper": {
        "default": "master/bio/sambamba/slice"
      },
      "input_types": [
        "coordinate-sorted and indexed bam file"
      ],
      "output_types": [
        "new bam file with specific region"
      ],
      "rule": "rule sambamba_slice:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        bai=\"mapped/{sample}.bam.bai\"\n    output:\n        \"mapped/{sample}.region.bam\"\n    params:\n        region=\"xx:1-10\"  # region to catch (contig:start-end)\n    log:\n        \"logs/sambamba-slice/{sample}.log\"\n    wrapper:\n        \"master/bio/sambamba/slice\"\n"
    },
    {
      "name": "sambamba_sort",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.sorted.bam"
      },
      "log": {
        "default": "logs/sambamba-sort/{sample}.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/sambamba/sort"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "sorted bam file"
      ],
      "rule": "rule sambamba_sort:\n    input:\n        \"mapped/{sample}.bam\"\n    output:\n        \"mapped/{sample}.sorted.bam\"\n    params:\n        \"\"  # optional parameters\n    log:\n        \"logs/sambamba-sort/{sample}.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/sambamba/sort\"\n"
    },
    {
      "name": "sambamba_view",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.filtered.bam"
      },
      "log": {
        "default": "logs/sambamba-view/{sample}.log"
      },
      "params": {
        "extra": "-f bam -F 'mapping_quality >= 50'"
      },
      "wrapper": {
        "default": "master/bio/sambamba/view"
      },
      "input_types": [
        "bam/sam file"
      ],
      "output_types": [
        "(filtered) bam/sam file"
      ],
      "rule": "rule sambamba_view:\n    input:\n        \"mapped/{sample}.bam\"\n    output:\n        \"mapped/{sample}.filtered.bam\"\n    params:\n        extra=\"-f bam -F 'mapping_quality >= 50'\"  # optional parameters\n    log:\n        \"logs/sambamba-view/{sample}.log\"\n    threads: 8\n    wrapper:\n        \"master/bio/sambamba/view\"\n"
    },
    {
      "name": "samtools_calmd",
      "input": {
        "aln": "{sample}.bam",
        "ref": "genome.fasta"
      },
      "output": {
        "default": "{sample}.calmd.bam"
      },
      "log": {
        "default": "{sample}.calmd.log"
      },
      "params": {
        "extra": "-E"
      },
      "wrapper": {
        "default": "master/bio/samtools/calmd"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "SAM/BAM/CRAM file",
        "SAM/BAM/CRAM index file (optional)"
      ],
      "rule": "rule samtools_calmd:\n    input:\n        aln=\"{sample}.bam\",  # Can be 'sam', 'bam', or 'cram'\n        ref=\"genome.fasta\",\n    output:\n        \"{sample}.calmd.bam\",\n    log:\n        \"{sample}.calmd.log\",\n    params:\n        extra=\"-E\",  # optional params string\n    threads: 2\n    wrapper:\n        \"master/bio/samtools/calmd\"\n"
    },
    {
      "name": "samtools_collate",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "{sample}.collated.bam"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "-f"
      },
      "wrapper": {
        "default": "master/bio/samtools/collate"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "SAM/BAM/CRAM file"
      ],
      "rule": "rule samtools_collate:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"{sample}.collated.bam\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"-f\",\n    threads: 2\n    wrapper:\n        \"master/bio/samtools/collate\"\n"
    },
    {
      "name": "samtools_depth",
      "input": {
        "bams": [
          "mapped/A.bam",
          "mapped/B.bam"
        ],
        "bed": "regionToCalcDepth.bed"
      },
      "output": {
        "default": "depth.txt"
      },
      "log": {
        "default": "depth.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/depth"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule samtools_depth:\n    input:\n        bams=[\"mapped/A.bam\", \"mapped/B.bam\"],\n        bed=\"regionToCalcDepth.bed\",  # optional\n    output:\n        \"depth.txt\",\n    log:\n        \"depth.log\",\n    params:\n        # optional bed file passed to -b\n        extra=\"\",  # optional additional parameters as string\n    wrapper:\n        \"master/bio/samtools/depth\"\n"
    },
    {
      "name": "samtools_faidx",
      "input": {
        "default": "{sample}.fa"
      },
      "output": {
        "default": "out/{sample}.fa.fai"
      },
      "log": {
        "default": "{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/faidx"
      },
      "input_types": [
        "reference sequence file (.fa)",
        {
          "regions": "file with regions"
        },
        {
          "fai": "index for reference file (optional)"
        },
        {
          "gzi": "index for BGZip'ed reference file (optional)"
        }
      ],
      "output_types": [
        "indexed reference sequence file (.fai)",
        {
          "fai": "index for reference file (optional)"
        },
        {
          "gzi": "index for BGZip'ed reference file (optional)"
        }
      ],
      "rule": "rule samtools_faidx:\n    input:\n        \"{sample}.fa\",\n    output:\n        \"out/{sample}.fa.fai\",\n    log:\n        \"{sample}.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/samtools/faidx\"\n\n\nrule samtools_faidx_named:\n    input:\n        \"{sample}.fa\",\n    output:\n        fai=\"out/{sample}.named.fa.fai\",\n    log:\n        \"{sample}.named.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/samtools/faidx\"\n\n\nrule samtools_faidx_bgzip:\n    input:\n        \"{sample}.fa.bgz\",\n    output:\n        fai=\"out/{sample}.fas.bgz.fai\",\n        gzi=\"out/{sample}.fas.bgz.gzi\",\n    log:\n        \"{sample}.bzgip.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/samtools/faidx\"\n\n\nrule samtools_faidx_region_file:\n    input:\n        \"{sample}.fa\",\n        fai=\"idx/{sample}.fa.fai\",\n        regions=\"{sample}.regions\",\n    output:\n        \"out/{sample}.region_file.fas\",\n    log:\n        \"{sample}.region_file.log\",\n    params:\n        extra=\"--length 5\",\n    wrapper:\n        \"master/bio/samtools/faidx\"\n\n\nrule samtools_faidx_region_array:\n    input:\n        \"{sample}.fa\",\n        fai=\"idx/{sample}.fa.fai\",\n    output:\n        \"out/{sample}.region_array.fas\",\n    log:\n        \"{sample}.region_array.log\",\n    params:\n        region=[\"ref\", \"ref2\"],\n        extra=\"--length 5\",\n    wrapper:\n        \"master/bio/samtools/faidx\"\n\n\nrule samtools_faidx_bgzip_region:\n    input:\n        \"{sample}.fa.bgz\",\n        fai=\"idx/{sample}.fa.bgz.fai\",\n        gzi=\"idx/{sample}.fa.bgz.gzi\",\n    output:\n        \"out/{sample}.region_bgzip.fas\",\n    log:\n        \"{sample}.region_bgzip.log\",\n    params:\n        region=\"ref\",\n        extra=\"--length 5\",\n    wrapper:\n        \"master/bio/samtools/faidx\"\n"
    },
    {
      "name": "samtools_fastq",
      "input": {
        "default": "{prefix}.sam"
      },
      "output": {
        "default": "{prefix}.fasta"
      },
      "log": {
        "default": "{prefix}.log"
      },
      "params": {
        "outputtype": "fasta",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/fastx/"
      },
      "input_types": [
        "bam or sam file (.bam, .sam)"
      ],
      "output_types": [
        "fastq file (.fastq) or fasta file (.fasta)"
      ],
      "rule": "rule samtools_fastq:\n    input:\n        \"{prefix}.sam\",\n    output:\n        \"{prefix}.fasta\",\n    log:\n        \"{prefix}.log\",\n    message:\n        \"\"\n    # Samtools takes additional threads through its option -@\n    threads: 2  # This value - 1 will be sent to -@\n    params:\n        outputtype=\"fasta\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/samtools/fastx/\"\n"
    },
    {
      "name": "samtools_fastq_interleaved",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "reads/{sample}.fq"
      },
      "log": {
        "default": "{sample}.interleaved.log"
      },
      "params": {
        "default": " "
      },
      "wrapper": {
        "default": "master/bio/samtools/fastq/interleaved"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule samtools_fastq_interleaved:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"reads/{sample}.fq\",\n    log:\n        \"{sample}.interleaved.log\",\n    params:\n        \" \",\n    threads: 3\n    wrapper:\n        \"master/bio/samtools/fastq/interleaved\"\n"
    },
    {
      "name": "samtools_fastq_separate",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "reads/{sample}.1.fq"
      },
      "log": {
        "default": "{sample}.separate.log"
      },
      "params": {
        "collate": "",
        "fastq": "-n"
      },
      "wrapper": {
        "default": "master/bio/samtools/fastq/separate"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule samtools_fastq_separate:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"reads/{sample}.1.fq\",\n        \"reads/{sample}.2.fq\",\n    log:\n        \"{sample}.separate.log\",\n    params:\n        collate=\"\",\n        fastq=\"-n\",\n    # Remember, this is the number of samtools' additional threads. At least 2 threads have to be requested on cluster sumbission. This value - 2 will be sent to samtools sort -@ argument.\n    threads: 3\n    wrapper:\n        \"master/bio/samtools/fastq/separate\"\n"
    },
    {
      "name": "samtools_fixmate",
      "input": {
        "default": "mapped/{input}"
      },
      "output": {
        "default": "fixed/{input}"
      },
      "log": {
        "default": "{input}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/fixmate/"
      },
      "input_types": [
        "bam or sam file (.bam,.sam)"
      ],
      "output_types": [
        "bam or sam file (.bam,.sam)"
      ],
      "rule": "rule samtools_fixmate:\n    input:\n        \"mapped/{input}\",\n    output:\n        \"fixed/{input}\",\n    log:\n        \"{input}.log\",\n    message:\n        \"Fixing mate information in {wildcards.input}\"\n    threads: 1\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/samtools/fixmate/\"\n"
    },
    {
      "name": "samtools_flagstat",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.bam.flagstat"
      },
      "log": {
        "default": "{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/flagstat"
      },
      "input_types": [
        "bam or sam file (.bam,.sam)"
      ],
      "output_types": [
        "flagstat file (.flagstat)"
      ],
      "rule": "rule samtools_flagstat:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"mapped/{sample}.bam.flagstat\",\n    log:\n        \"{sample}.log\",\n    params:\n        extra=\"\",  # optional params string\n    wrapper:\n        \"master/bio/samtools/flagstat\"\n"
    },
    {
      "name": "samtools_idxstats",
      "input": {
        "bam": "mapped/{sample}.bam",
        "idx": "mapped/{sample}.bam.bai"
      },
      "output": {
        "default": "mapped/{sample}.bam.idxstats"
      },
      "log": {
        "default": "logs/samtools/idxstats/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/idxstats"
      },
      "input_types": [
        "indexed SAM, BAM or CRAM file (.SAM, .BAM, .CRAM)",
        "corresponding index files"
      ],
      "output_types": [
        "idxstat file (.idxstats)"
      ],
      "rule": "rule samtools_idxstats:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        idx=\"mapped/{sample}.bam.bai\",\n    output:\n        \"mapped/{sample}.bam.idxstats\",\n    log:\n        \"logs/samtools/idxstats/{sample}.log\",\n    params:\n        extra=\"\",  # optional params string\n    wrapper:\n        \"master/bio/samtools/idxstats\"\n"
    },
    {
      "name": "samtools_index",
      "input": {
        "default": "mapped/{sample}.sorted.bam"
      },
      "output": {
        "default": "mapped/{sample}.sorted.bam.bai"
      },
      "log": {
        "default": "logs/samtools_index/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/index"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "bam file index (.bai)"
      ],
      "rule": "rule samtools_index:\n    input:\n        \"mapped/{sample}.sorted.bam\",\n    output:\n        \"mapped/{sample}.sorted.bam.bai\",\n    log:\n        \"logs/samtools_index/{sample}.log\",\n    params:\n        extra=\"\",  # optional params string\n    threads: 4  # This value - 1 will be sent to -@\n    wrapper:\n        \"master/bio/samtools/index\"\n"
    },
    {
      "name": "samtools_markdup",
      "input": {
        "aln": "{sample}.bam"
      },
      "output": {
        "bam": "{sample}.markdup.bam",
        "idx": "{sample}.markdup.bam.csi"
      },
      "log": {
        "default": "{sample}.markdup.log"
      },
      "params": {
        "extra": "-c --no-PG"
      },
      "wrapper": {
        "default": "master/bio/samtools/markdup"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "SAM/BAM/CRAM file",
        "SAM/BAM/CRAM index file (optional)"
      ],
      "rule": "rule samtools_markdup:\n    input:\n        aln=\"{sample}.bam\",\n    output:\n        bam=\"{sample}.markdup.bam\",\n        idx=\"{sample}.markdup.bam.csi\",\n    log:\n        \"{sample}.markdup.log\",\n    params:\n        extra=\"-c --no-PG\",\n    threads: 2\n    wrapper:\n        \"master/bio/samtools/markdup\"\n"
    },
    {
      "name": "samtools_merge",
      "input": {
        "default": [
          "mapped/A.bam",
          "mapped/B.bam"
        ]
      },
      "output": {
        "default": "merged.bam"
      },
      "log": {
        "default": "merged.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/merge"
      },
      "input_types": [
        "list of bam files to merge"
      ],
      "output_types": [
        "merged bam file"
      ],
      "rule": "rule samtools_merge:\n    input:\n        [\"mapped/A.bam\", \"mapped/B.bam\"],\n    output:\n        \"merged.bam\",\n    log:\n        \"merged.log\",\n    params:\n        extra=\"\",  # optional additional parameters as string\n    threads: 8\n    wrapper:\n        \"master/bio/samtools/merge\"\n"
    },
    {
      "name": "samtools_sort",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "mapped/{sample}.sorted.bam"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "-m 4G"
      },
      "wrapper": {
        "default": "master/bio/samtools/sort"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "SAM/BAM/CRAM file",
        "SAM/BAM/CRAM index file (optional)"
      ],
      "rule": "rule samtools_sort:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"mapped/{sample}.sorted.bam\",\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=\"-m 4G\",\n    threads: 8\n    wrapper:\n        \"master/bio/samtools/sort\"\n"
    },
    {
      "name": "samtools_stats",
      "input": {
        "bam": "mapped/{sample}.bam",
        "bed": "design.bed"
      },
      "output": {
        "default": "samtools_stats/{sample}.txt"
      },
      "log": {
        "default": "logs/samtools_stats/{sample}.log"
      },
      "params": {
        "extra": "",
        "region": "xx:1000000-2000000"
      },
      "wrapper": {
        "default": "master/bio/samtools/stats"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "statistics file"
      ],
      "rule": "rule samtools_stats:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        bed=\"design.bed\",  #Optional input, specify target regions\n    output:\n        \"samtools_stats/{sample}.txt\",\n    params:\n        extra=\"\",  # Optional: extra arguments.\n        region=\"xx:1000000-2000000\",  # Optional: region string.\n    log:\n        \"logs/samtools_stats/{sample}.log\",\n    wrapper:\n        \"master/bio/samtools/stats\"\n"
    },
    {
      "name": "samtools_view",
      "input": {
        "default": "{sample}.sam"
      },
      "output": {
        "bam": "{sample}.bam",
        "idx": "{sample}.bai"
      },
      "log": {
        "default": "{sample}.log"
      },
      "params": {
        "extra": "",
        "region": ""
      },
      "wrapper": {
        "default": "master/bio/samtools/view"
      },
      "input_types": [
        "SAM/BAM/CRAM file"
      ],
      "output_types": [
        "SAM/BAM/CRAM file",
        "SAM/BAM/CRAM index file (optional)"
      ],
      "rule": "rule samtools_view:\n    input:\n        \"{sample}.sam\",\n    output:\n        bam=\"{sample}.bam\",\n        idx=\"{sample}.bai\",\n    log:\n        \"{sample}.log\",\n    params:\n        extra=\"\",  # optional params string\n        region=\"\",  # optional region string\n    threads: 2\n    wrapper:\n        \"master/bio/samtools/view\"\n"
    },
    {
      "name": "scaffold",
      "input": {
        "query": "fasta/{query}.fasta",
        "ref": "fasta/{reference}.fasta"
      },
      "output": {
        "fasta": "{query}_scaffold_{reference}/ragtag.scaffold.fasta",
        "agp": "{query}_scaffold_{reference}/ragtag.scaffold.agp",
        "stats": "{query}_scaffold_{reference}/ragtag.scaffold.stats"
      },
      "log": {
        "default": "logs/ragtag/{query}_scaffold_{reference}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/ragtag/scaffold"
      },
      "input_types": [
        {
          "ref": "reference fasta file (uncompressed or bgzipped)"
        },
        {
          "query": "query fasta file (uncompressed or bgzipped)"
        }
      ],
      "output_types": [
        {
          "fasta": "The scaffolds in FASTA format, defined by the ordering and orientations of ragtag.scaffold.agp."
        },
        {
          "agp": "The ordering and orientations of query sequences in AGP format."
        },
        {
          "stats": "Summary statistics for the scaffolding process."
        }
      ],
      "rule": "rule scaffold:\n    input:\n        query=\"fasta/{query}.fasta\",\n        ref=\"fasta/{reference}.fasta\",\n    output:\n        fasta=\"{query}_scaffold_{reference}/ragtag.scaffold.fasta\",\n        agp=\"{query}_scaffold_{reference}/ragtag.scaffold.agp\",\n        stats=\"{query}_scaffold_{reference}/ragtag.scaffold.stats\",\n    params:\n        extra=\"\",\n    threads: 16\n    log:\n        \"logs/ragtag/{query}_scaffold_{reference}.log\",\n    wrapper:\n        \"master/bio/ragtag/scaffold\"\n"
    },
    {
      "name": "seqkit_seq",
      "input": {
        "fasta": "data/{sample}.fa"
      },
      "output": {
        "fasta": "out/seq/{sample}.fa.gz"
      },
      "log": {
        "default": "logs/seq/{sample}.log"
      },
      "params": {
        "command": "seq",
        "extra": "--min-len 10"
      },
      "wrapper": {
        "default": "master/bio/seqkit"
      },
      "input_types": [
        "input file(s)"
      ],
      "output_types": [
        "output file(s)"
      ],
      "rule": "rule seqkit_seq:\n    input:\n        fasta=\"data/{sample}.fa\",\n    output:\n        fasta=\"out/seq/{sample}.fa.gz\",\n    log:\n        \"logs/seq/{sample}.log\",\n    params:\n        command=\"seq\",\n        extra=\"--min-len 10\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_subseq_bed:\n    input:\n        fasta=\"data/{sample}.fa\",\n        bed=\"data/{sample}.bed\",\n    output:\n        fasta=\"out/subseq/bed/{sample}.fa.gz\",\n    log:\n        \"logs/subseq/bed/{sample}.log\",\n    params:\n        command=\"subseq\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_subseq_gtf:\n    input:\n        fasta=\"data/{sample}.fa\",\n        gtf=\"data/{sample}.gtf\",\n    output:\n        fasta=\"out/subseq/gtf/{sample}.fa.gz\",\n    log:\n        \"logs/subseq/gtf/{sample}.log\",\n    params:\n        command=\"subseq\",\n        extra=\"--feature CDS\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_subseq_region:\n    input:\n        fasta=\"data/{sample}.fa\",\n    output:\n        fasta=\"out/subseq/region/{sample}.fa.gz\",\n    log:\n        \"logs/subseq/region/{sample}.log\",\n    params:\n        command=\"subseq\",\n        extra=\"--region 1:12\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_fx2tab:\n    input:\n        fastx=\"data/{sample}.fastq\",\n    output:\n        tsv=\"out/fx2tab/{sample}.tsv\",\n    log:\n        \"logs/fx2tab/{sample}.log\",\n    params:\n        command=\"fx2tab\",\n        extra=\"--name\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_grep_name:\n    input:\n        fastx=\"data/{sample}.fastq\",\n        pattern=\"data/name.txt\",\n    output:\n        fastx=\"out/grep/name/{sample}.fastq.gz\",\n    log:\n        \"logs/grep/name/{sample}.log\",\n    params:\n        command=\"grep\",\n        extra=\"--by-name\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_grep_seq:\n    input:\n        fastx=\"data/{sample}.fastq\",\n        pattern=\"data/seq.txt\",\n    output:\n        fastx=\"out/grep/seq/{sample}.fastq.gz\",\n    log:\n        \"logs/grep/seq/{sample}.log\",\n    params:\n        command=\"grep\",\n        extra=\"--by-seq\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_rmdup_name:\n    input:\n        fastx=\"data/{sample}.fastq\",\n    output:\n        fastx=\"out/rmdup/name/{sample}.fastq.gz\",\n        dup_num=\"out/rmdup/name/{sample}.num.txt\",\n        dup_seqs=\"out/rmdup/name/{sample}.seq.txt\",\n    log:\n        \"logs/rmdup/name/{sample}.log\",\n    params:\n        command=\"rmdup\",\n        extra=\"--by-name\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_rmdup_seq:\n    input:\n        fastx=\"data/{sample}.fastq\",\n    output:\n        fastx=\"out/rmdup/seq/{sample}.fastq.gz\",\n        dup_num=\"out/rmdup/seq/{sample}.num.txt\",\n        dup_seqs=\"out/rmdup/seq/{sample}.seq.txt\",\n    log:\n        \"logs/rmdup/seq/{sample}.log\",\n    params:\n        command=\"rmdup\",\n        extra=\"--by-seq\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_stats:\n    input:\n        fastx=\"data/{sample}.fastq\",\n    output:\n        stats=\"out/stats/{sample}.tsv\",\n    log:\n        \"logs/stats/{sample}.log\",\n    params:\n        command=\"stats\",\n        extra=\"--all --tabular\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_common:\n    input:\n        fastas=[\n            \"data/{sample1}.fa\",\n            \"data/{sample2}.fa\",\n        ],\n    output:\n        fasta=\"out/common/{sample1}_{sample2}.fa.gz\",\n    log:\n        \"logs/common/{sample1}_{sample2}.log\",\n    params:\n        command=\"common\",\n        extra=\"\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_concat:\n    input:\n        fastas=[\n            \"data/{sample1}.fa\",\n            \"data/{sample2}.fa\",\n        ],\n    output:\n        fasta=\"out/concat/{sample1}_{sample2}.fa.gz\",\n    log:\n        \"logs/concat/{sample1}_{sample2}.log\",\n    params:\n        command=\"concat\",\n        extra=\"\",\n        out_bgzip=True,\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n\n\nrule seqkit_split2_part:\n    input:\n        fasta=\"data/{sample}.fa\",\n    output:\n        fasta=[\n            \"out/split2/part/{sample}.1-of-2.fas\",\n            \"out/split2/part/{sample}.2-of-2.fas\",\n        ],\n    log:\n        \"logs/split/part/{sample}.log\",\n    params:\n        command=\"split2\",\n        extra=\"--by-part 2\",\n    threads: 2\n    wrapper:\n        \"master/bio/seqkit\"\n"
    },
    {
      "name": "seqtk_seq_fq2fas",
      "input": {
        "default": "reads/{prefix}.fastq"
      },
      "output": {
        "default": "results/fq2fas/{prefix}.fasta"
      },
      "log": {
        "default": "logs/fq2fas/{prefix}.log"
      },
      "params": {
        "command": "seq",
        "extra": "-A"
      },
      "wrapper": {
        "default": "master/bio/seqtk"
      },
      "input_types": [
        "fastx file(s) (can be gzip compressed)"
      ],
      "output_types": [
        "fastn files (can be gzip compressed)"
      ],
      "rule": "rule seqtk_seq_fq2fas:\n    input:\n        \"reads/{prefix}.fastq\",\n    output:\n        \"results/fq2fas/{prefix}.fasta\",\n    log:\n        \"logs/fq2fas/{prefix}.log\",\n    params:\n        command=\"seq\",\n        extra=\"-A\",\n    wrapper:\n        \"master/bio/seqtk\"\n\n\nrule seqtk_seq_convBQ:\n    input:\n        \"reads/{prefix}.fastq\",\n    output:\n        \"results/convBQ/{prefix}.fasta\",\n    log:\n        \"logs/convBQ/{prefix}.log\",\n    params:\n        command=\"seq\",\n        extra=\"-aQ 64 -q 20 -n N\",\n    wrapper:\n        \"master/bio/seqtk\"\n\n\nrule seqtk_subseq_list:\n    input:\n        \"reads/{prefix}.fastq\",\n        \"reads/id.list\",\n    output:\n        \"results/subseq_list/{prefix}.fq.gz\",\n    log:\n        \"logs/subseq_list/{prefix}.log\",\n    params:\n        command=\"subseq\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/seqtk\"\n\n\nrule seqtk_mergepe:\n    input:\n        r1=\"reads/{sample}.1.fastq.gz\",\n        r2=\"reads/{sample}.2.fastq.gz\",\n    output:\n        merged=\"results/mergepe/{sample}.fastq.gz\",\n    log:\n        \"logs/mergepe/{sample}.log\",\n    params:\n        command=\"mergepe\",\n        compress_lvl=9,\n    threads: 2\n    wrapper:\n        \"master/bio/seqtk\"\n\n\nrule seqtk_sample_se:\n    input:\n        \"reads/{sample}.fastq.gz\",\n    output:\n        \"results/sample_se/{sample}.fastq.gz\",\n    log:\n        \"logs/sample_se/{sample}.log\",\n    params:\n        command=\"sample\",\n        n=3,\n        extra=\"-s 12345\",\n    threads: 1\n    wrapper:\n        \"master/bio/seqtk\"\n\n\nrule seqtk_sample_pe:\n    input:\n        f1=\"reads/{sample}.1.fastq.gz\",\n        f2=\"reads/{sample}.2.fastq.gz\",\n    output:\n        f1=\"results/sample_pe/{sample}.1.fastq.gz\",\n        f2=\"results/sample_pe/{sample}.2.fastq.gz\",\n    log:\n        \"logs/sample_pe/{sample}.log\",\n    params:\n        command=\"sample\",\n        n=3,\n        extra=\"-s 12345\",\n    threads: 1\n    wrapper:\n        \"master/bio/seqtk\"\n"
    },
    {
      "name": "shovill",
      "input": {
        "r1": "reads/{sample}_R1.fq.gz",
        "r2": "reads/{sample}_R2.fq.gz"
      },
      "output": {
        "raw_assembly": "assembly/{sample}.{assembler}.assembly.fa",
        "contigs": "assembly/{sample}.{assembler}.contigs.fa"
      },
      "log": {
        "default": "logs/shovill/{sample}.{assembler}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/shovill"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule shovill:\n  input:\n    r1=\"reads/{sample}_R1.fq.gz\",\n    r2=\"reads/{sample}_R2.fq.gz\"\n  output:\n    raw_assembly=\"assembly/{sample}.{assembler}.assembly.fa\",\n    contigs=\"assembly/{sample}.{assembler}.contigs.fa\"\n  params:\n    extra=\"\"\n  log:\n    \"logs/shovill/{sample}.{assembler}.log\"\n  threads: 1\n  wrapper:\n    \"master/bio/shovill\"\n"
    },
    {
      "name": "sickle_pe",
      "input": {
        "r1": "reads/{sample}.1.fastq",
        "r2": "reads/{sample}.2.fastq"
      },
      "output": {
        "r1": "{sample}.1.fastq",
        "r2": "{sample}.2.fastq",
        "rs": "{sample}.single.fastq"
      },
      "log": {
        "default": "logs/sickle/{sample}.log"
      },
      "params": {
        "qual_type": "sanger",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/sickle/pe"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule sickle_pe:\n  input:\n    r1=\"reads/{sample}.1.fastq\",\n    r2=\"reads/{sample}.2.fastq\"\n  output:\n    r1=\"{sample}.1.fastq\",\n    r2=\"{sample}.2.fastq\",\n    rs=\"{sample}.single.fastq\",\n  log:\n    \"logs/sickle/{sample}.log\"\n  params:\n    qual_type=\"sanger\",\n    # optional extra parameters\n    extra=\"\"\n  wrapper:\n    \"master/bio/sickle/pe\"\n"
    },
    {
      "name": "sickle_se",
      "input": {
        "default": "reads/{sample}.1.fastq"
      },
      "output": {
        "default": "{sample}.1.fastq"
      },
      "log": {
        "default": "logs/sickle/{sample}.log"
      },
      "params": {
        "qual_type": "sanger",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/sickle/se"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule sickle_se:\n  input:\n    \"reads/{sample}.1.fastq\"\n  output:\n    \"{sample}.1.fastq\"\n  log:\n    \"logs/sickle/{sample}.log\"\n  params:\n    qual_type=\"sanger\",\n    # optional extra parameters\n    extra=\"\"\n  wrapper:\n    \"master/bio/sickle/se\"\n"
    },
    {
      "name": "sim",
      "input": {
        "xg": "x.xg"
      },
      "output": {
        "reads": "reads/x.seq"
      },
      "log": {
        "default": "logs/vg/sim/x.log"
      },
      "params": {
        "default": "--read-length 100 --num-reads 100 -f"
      },
      "wrapper": {
        "default": "master/bio/vg/sim"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule sim:\n    input:\n        xg=\"x.xg\"\n    output:\n        reads=\"reads/x.seq\"\n    params:\n        \"--read-length 100 --num-reads 100 -f\"\n    log:\n        \"logs/vg/sim/x.log\"\n    threads:\n        4\n    wrapper:\n        \"master/bio/vg/sim\"\n"
    },
    {
      "name": "snpeff",
      "input": {
        "calls": "{sample}.vcf",
        "db": "resources/snpeff/ebola_zaire"
      },
      "output": {
        "calls": "snpeff/{sample}.vcf",
        "stats": "snpeff/{sample}.html",
        "csvstats": "snpeff/{sample}.csv"
      },
      "log": {
        "default": "logs/snpeff/{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/snpeff/annotate"
      },
      "input_types": [
        {
          "calls": "input VCF/BCF file"
        },
        {
          "db": "SnpEff database"
        }
      ],
      "output_types": [
        {
          "calls": "trimmed fastq file with R1 reads, trimmed fastq file with R2 reads (PE only, optional)"
        },
        {
          "genes": "genes output file (optional)"
        },
        {
          "stats": "stats file (optional)"
        },
        {
          "csvstats": "stats CSV file (optional)"
        }
      ],
      "rule": "rule snpeff:\n    input:\n        calls=\"{sample}.vcf\", # (vcf, bcf, or vcf.gz)\n        db=\"resources/snpeff/ebola_zaire\" # path to reference db downloaded with the snpeff download wrapper\n    output:\n        calls=\"snpeff/{sample}.vcf\",   # annotated calls (vcf, bcf, or vcf.gz)\n        stats=\"snpeff/{sample}.html\",  # summary statistics (in HTML), optional\n        csvstats=\"snpeff/{sample}.csv\" # summary statistics in CSV, optional\n    log:\n        \"logs/snpeff/{sample}.log\"\n    resources:\n        java_opts=\"-XX:ParallelGCThreads=10\",\n        mem_mb=4096\n    wrapper:\n        \"master/bio/snpeff/annotate\"\n\nrule snpeff_nostats:\n    input:\n        calls=\"{sample}.vcf\",\n        db=\"resources/snpeff/ebola_zaire\"\n    output:\n        calls=\"snpeff_nostats/{sample}.vcf\",    # the main output file\n        # if either \"genes\" or \"stats\" outputs are provided, both are created\n    log:\n        \"logs/snpeff_nostats/{sample}.log\"\n    params:\n        java_opts=\"-XX:ParallelGCThreads=10\",\n        extra=\"\"                 # optional parameters\n    resources:\n        mem_mb=1024\n    wrapper:\n        \"master/bio/snpeff/annotate\""
    },
    {
      "name": "snpeff_download",
      "input": {},
      "output": {
        "default": "directory('resources/snpeff/{reference}')"
      },
      "log": {
        "default": "logs/snpeff/download/{reference}.log"
      },
      "params": {
        "reference": "{reference}"
      },
      "wrapper": {
        "default": "master/bio/snpeff/download"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule snpeff_download:\n    output:\n        # wildcard {reference} may be anything listed in `snpeff databases`\n        directory(\"resources/snpeff/{reference}\")\n    log:\n        \"logs/snpeff/download/{reference}.log\"\n    params:\n        reference=\"{reference}\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    wrapper:\n        \"master/bio/snpeff/download\"\n"
    },
    {
      "name": "sort_bam",
      "input": {
        "default": "mapped/{sample}.bam"
      },
      "output": {
        "default": "sorted/{sample}.bam"
      },
      "log": {
        "default": "logs/picard/sort_sam/{sample}.log"
      },
      "params": {
        "sort_order": "coordinate",
        "extra": "--VALIDATION_STRINGENCY LENIENT"
      },
      "wrapper": {
        "default": "master/bio/picard/sortsam"
      },
      "input_types": [
        "sam/bam file"
      ],
      "output_types": [
        "sorted sam/bam file."
      ],
      "rule": "rule sort_bam:\n    input:\n        \"mapped/{sample}.bam\",\n    output:\n        \"sorted/{sample}.bam\",\n    log:\n        \"logs/picard/sort_sam/{sample}.log\",\n    params:\n        sort_order=\"coordinate\",\n        extra=\"--VALIDATION_STRINGENCY LENIENT\",  # optional: Extra arguments for picard.\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/picard/sortsam\"\n"
    },
    {
      "name": "sortmerna_pe",
      "input": {
        "ref": [
          "database1.fa",
          "database2.fa"
        ],
        "reads": [
          "reads_1.fq.gz",
          "reads_2.fq.gz"
        ]
      },
      "output": {
        "aligned": [
          "aligned_1.fastq.gz",
          "aligned_2.fastq.gz"
        ],
        "other": [
          "unpaired_1.fastq.gz",
          "unpaired_2.fastq.gz"
        ],
        "stats": "sortmerna_pe_stats.log"
      },
      "log": {
        "default": "logs/sortmerna/reads_pe.log"
      },
      "params": {
        "extra": "--idx-dir idx --paired_in --out2"
      },
      "wrapper": {
        "default": "master/bio/sortmerna"
      },
      "input_types": [
        "Reference FASTA files (one or more)",
        "Query FASTA file (single or paired-end)"
      ],
      "output_types": [
        "Aligned reads",
        "Unaligned reads (other)"
      ],
      "rule": "rule sortmerna_pe:\n    input:\n        ref=[\"database1.fa\", \"database2.fa\"],\n        reads=[\"reads_1.fq.gz\", \"reads_2.fq.gz\"],\n    output:\n        aligned=[\"aligned_1.fastq.gz\", \"aligned_2.fastq.gz\"],\n        other=[\"unpaired_1.fastq.gz\", \"unpaired_2.fastq.gz\"],\n        stats=\"sortmerna_pe_stats.log\",\n    params:\n        extra=\"--idx-dir idx --paired_in --out2\",\n    threads: 16\n    resources:\n        mem_mb=3072,  # amount of memory for building the index\n    log:\n        \"logs/sortmerna/reads_pe.log\",\n    wrapper:\n        \"master/bio/sortmerna\"\n\n\nrule sortmerna_se:\n    input:\n        ref=[\"database1.fa\", \"database2.fa\"],\n        reads=\"reads.fq\",\n    output:\n        aligned=\"aligned.fastq\",\n        other=\"unpaired.fastq\",\n        stats=\"sortmerna_se_stats.log\",\n    params:\n        extra=\"--idx-dir idx\",\n    threads: 16\n    resources:\n        mem_mb=3072,  # amount of memory for building the index\n    log:\n        \"logs/sortmerna/reads_se.log\",\n    wrapper:\n        \"master/bio/sortmerna\"\n"
    },
    {
      "name": "sourmash_reads",
      "input": {
        "default": "reads/a.fastq"
      },
      "output": {
        "default": "reads.sig"
      },
      "log": {
        "default": "logs/sourmash/sourmash_compute_reads.log"
      },
      "params": {
        "k": "31",
        "scaled": "1000",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/sourmash/compute"
      },
      "input_types": [
        "assembly fasta, or reads fastq"
      ],
      "output_types": [
        "sourmash signature"
      ],
      "rule": "rule sourmash_reads:\n    input:\n        \"reads/a.fastq\"\n    output:\n        \"reads.sig\"\n    log:\n        \"logs/sourmash/sourmash_compute_reads.log\"\n    threads: 2\n    params:\n        # optional parameters\n        k = \"31\",\n        scaled = \"1000\",\n        extra = \"\"\n    wrapper:\n        \"master/bio/sourmash/compute\"\n\n\nrule sourmash_transcriptome:\n    input:\n        \"assembly/transcriptome.fasta\"\n    output:\n        \"transcriptome.sig\"\n    log:\n        \"logs/sourmash/sourmash_compute_transcriptome.log\"\n    threads: 2\n    params:\n        # optional parameters\n        k = \"31\",\n        scaled = \"1000\",\n        extra = \"\"\n    wrapper:\n        \"master/bio/sourmash/compute\"\n"
    },
    {
      "name": "splitncigarreads",
      "input": {
        "bam": "mapped/{sample}.bam",
        "ref": "genome.fasta"
      },
      "output": {
        "default": "split/{sample}.bam"
      },
      "log": {
        "default": "logs/gatk/splitNCIGARreads/{sample}.log"
      },
      "params": {
        "extra": "",
        "java_opts": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/splitncigarreads"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "split bam file"
      ],
      "rule": "rule splitncigarreads:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        ref=\"genome.fasta\",\n    output:\n        \"split/{sample}.bam\",\n    log:\n        \"logs/gatk/splitNCIGARreads/{sample}.log\",\n    params:\n        extra=\"\",  # optional\n        java_opts=\"\",  # optional\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/gatk/splitncigarreads\"\n"
    },
    {
      "name": "star_index",
      "input": {
        "fasta": "{genome}.fasta"
      },
      "output": {
        "default": "directory('{genome}')"
      },
      "log": {
        "default": "logs/star_index_{genome}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/star/index"
      },
      "input_types": [
        "A (multi)fasta formatted file"
      ],
      "output_types": [
        "A directory containing the indexed sequence for downstream STAR mapping"
      ],
      "rule": "rule star_index:\n    input:\n        fasta=\"{genome}.fasta\",\n    output:\n        directory(\"{genome}\"),\n    message:\n        \"Testing STAR index\"\n    threads: 1\n    params:\n        extra=\"\",\n    log:\n        \"logs/star_index_{genome}.log\",\n    wrapper:\n        \"master/bio/star/index\"\n"
    },
    {
      "name": "star_pe_multi",
      "input": {
        "fq1": [
          "reads/{sample}_R1.1.fastq",
          "reads/{sample}_R1.2.fastq"
        ],
        "fq2": [
          "reads/{sample}_R2.1.fastq",
          "reads/{sample}_R2.2.fastq"
        ],
        "idx": "index"
      },
      "output": {
        "aln": "star/pe/{sample}/pe_aligned.sam",
        "log": "logs/pe/{sample}/Log.out",
        "sj": "star/pe/{sample}/SJ.out.tab",
        "unmapped": [
          "star/pe/{sample}/unmapped.1.fastq.gz",
          "star/pe/{sample}/unmapped.2.fastq.gz"
        ]
      },
      "log": {
        "default": "logs/pe/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/star/align"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule star_pe_multi:\n    input:\n        # use a list for multiple fastq files for one sample\n        # usually technical replicates across lanes/flowcells\n        fq1=[\"reads/{sample}_R1.1.fastq\", \"reads/{sample}_R1.2.fastq\"],\n        # paired end reads needs to be ordered so each item in the two lists match\n        fq2=[\"reads/{sample}_R2.1.fastq\", \"reads/{sample}_R2.2.fastq\"],  #optional\n        # path to STAR reference genome index\n        idx=\"index\",\n    output:\n        # see STAR manual for additional output files\n        aln=\"star/pe/{sample}/pe_aligned.sam\",\n        log=\"logs/pe/{sample}/Log.out\",\n        sj=\"star/pe/{sample}/SJ.out.tab\",\n        unmapped=[\"star/pe/{sample}/unmapped.1.fastq.gz\",\"star/pe/{sample}/unmapped.2.fastq.gz\"],\n    log:\n        \"logs/pe/{sample}.log\",\n    params:\n        # optional parameters\n        extra=\"\",\n    threads: 8\n    wrapper:\n        \"master/bio/star/align\"\n\n\nrule star_se:\n    input:\n        fq1=\"reads/{sample}_R1.1.fastq\",\n        # path to STAR reference genome index\n        idx=\"index\",\n    output:\n        # see STAR manual for additional output files\n        aln=\"star/se/{sample}/se_aligned.bam\",\n        log=\"logs/se/{sample}/Log.out\",\n        log_final=\"logs/se/{sample}/Log.final.out\",\n        unmapped=\"star/se/{sample}/unmapped.fastq\",\n    log:\n        \"logs/se/{sample}.log\",\n    params:\n        # optional parameters\n        extra=\"--outSAMtype BAM Unsorted\",\n    threads: 8\n    wrapper:\n        \"master/bio/star/align\"\n"
    },
    {
      "name": "strelka",
      "input": {
        "tumor": "data/{tumor}.bam",
        "tumor_index": "data/{tumor}.bam.bai",
        "fasta": "data/genome.fasta",
        "fasta_index": "data/genome.fasta.fai"
      },
      "output": {
        "default": "directory('{tumor}_vcf')"
      },
      "log": {
        "default": "logs/strelka_{tumor}.log"
      },
      "params": {
        "run_extra": "",
        "config_extra": ""
      },
      "wrapper": {
        "default": "master/bio/strelka/somatic"
      },
      "input_types": [
        "A tumor bam file, with its index.",
        "A reference genome sequence in fasta format, with its index.",
        "An optional normal bam file for somatic calling, with its index."
      ],
      "output_types": [
        "Statistics about calling results",
        "Variants called"
      ],
      "rule": "rule strelka:\n    input:\n        # The normal bam and its index\n        # are optional input\n        # normal = \"data/b.bam\",\n        # normal_index = \"data/b.bam.bai\"\n        tumor=\"data/{tumor}.bam\",\n        tumor_index=\"data/{tumor}.bam.bai\",\n        fasta=\"data/genome.fasta\",\n        fasta_index=\"data/genome.fasta.fai\",\n    output:\n        # Strelka output - can be directory or full file path\n        directory(\"{tumor}_vcf\"),\n    threads: 1\n    params:\n        run_extra=\"\",\n        config_extra=\"\",\n    log:\n        \"logs/strelka_{tumor}.log\",\n    wrapper:\n        \"master/bio/strelka/somatic\"\n"
    },
    {
      "name": "strelka_germline",
      "input": {
        "bam": "mapped/{sample}.bam",
        "fasta": "genome.fasta",
        "fasta_index": "genome.fasta.fai"
      },
      "output": {
        "variants": "strelka/{sample}.vcf.gz",
        "variants_index": "strelka/{sample}.vcf.gz.tbi",
        "sample_genomes": [
          "strelka/{sample}.genome.vcf.gz"
        ],
        "sample_genomes_indices": [
          "strelka/{sample}.genome.vcf.gz.tbi"
        ]
      },
      "log": {
        "default": "logs/strelka/germline/{sample}.log"
      },
      "params": {
        "config_extra": "",
        "run_extra": ""
      },
      "wrapper": {
        "default": "master/bio/strelka/germline"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule strelka_germline:\n    input:\n        # the required bam file\n        bam=\"mapped/{sample}.bam\",\n        # path to reference genome fasta and index\n        fasta=\"genome.fasta\",\n        fasta_index=\"genome.fasta.fai\",\n    output:\n        # Strelka results - either use directory or complete file path\n        variants=\"strelka/{sample}.vcf.gz\",\n        variants_index=\"strelka/{sample}.vcf.gz.tbi\",\n        sample_genomes=[\"strelka/{sample}.genome.vcf.gz\"],\n        sample_genomes_indices=[\"strelka/{sample}.genome.vcf.gz.tbi\"],\n    log:\n        \"logs/strelka/germline/{sample}.log\",\n    params:\n        # optional parameters\n        config_extra=\"\",\n        run_extra=\"\",\n    threads: 8\n    wrapper:\n        \"master/bio/strelka/germline\"\n"
    },
    {
      "name": "strling_call",
      "input": {
        "bam": "mapped/{sample}.bam",
        "bai": "mapped/{sample}.bam.bai",
        "bin": "extract/{sample}.bin",
        "reference": "reference/genome.fasta",
        "fai": "reference/genome.fasta.fai",
        "bounds": "merged/group-bounds.txt"
      },
      "output": {
        "default": "call/{sample}-bounds.txt"
      },
      "log": {
        "default": "log/strling/call/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/strling/call"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule strling_call:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        bai=\"mapped/{sample}.bam.bai\",\n        bin=\"extract/{sample}.bin\",\n        reference=\"reference/genome.fasta\",\n        fai=\"reference/genome.fasta.fai\",\n        bounds=\"merged/group-bounds.txt\" # optional, produced by strling merge\n    output:\n        \"call/{sample}-bounds.txt\", # must end with -bounds.txt\n        \"call/{sample}-genotype.txt\", # must end with -genotype.txt\n        \"call/{sample}-unplaced.txt\" # must end with -unplaced.txt\n    params:\n        extra=\"\" # optional extra command line arguments\n    log:\n        \"log/strling/call/{sample}.log\"\n    wrapper:\n        \"master/bio/strling/call\" \n"
    },
    {
      "name": "strling_extract",
      "input": {
        "bam": "mapped/{sample}.bam",
        "bai": "mapped/{sample}.bam.bai",
        "reference": "reference/genome.fasta",
        "fai": "reference/genome.fasta.fai",
        "index": "reference/genome.fasta.str"
      },
      "output": {
        "default": "extract/{sample}.bin"
      },
      "log": {
        "default": "log/strling/extract/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/strling/extract"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule strling_extract:\n    input:\n        bam=\"mapped/{sample}.bam\",\n        bai=\"mapped/{sample}.bam.bai\",\n        reference=\"reference/genome.fasta\",\n        fai=\"reference/genome.fasta.fai\",\n        index=\"reference/genome.fasta.str\" # optional\n    output:\n        \"extract/{sample}.bin\"\n    log:\n        \"log/strling/extract/{sample}.log\"\n    params:\n       extra=\"\" # optionally add further command line arguments\n    wrapper:\n        \"master/bio/strling/extract\""
    },
    {
      "name": "strling_index",
      "input": {
        "default": "reference/genome.fasta"
      },
      "output": {
        "index": "reference/genome.fasta.str",
        "fai": "reference/genome.fasta.fai"
      },
      "log": {
        "default": "log/strling/index.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/strling/index"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule strling_index:\n    input:\n        \"reference/genome.fasta\"\n    output:\n        index=\"reference/genome.fasta.str\",\n        fai=\"reference/genome.fasta.fai\"\n    params:\n        extra=\"\" # optionally add further command line arguments\n    log:\n        \"log/strling/index.log\"\n    wrapper:\n        \"master/bio/strling/index\""
    },
    {
      "name": "strling_merge",
      "input": {
        "bins": [
          "extract/A.bin",
          "extract/B.bin"
        ],
        "reference": "reference/genome.fasta",
        "fai": "reference/genome.fasta.fai"
      },
      "output": {
        "default": "merged/group-bounds.txt"
      },
      "log": {
        "default": "log/strling/merge/group.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/strling/merge"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule strling_merge:\n    input:\n        bins=[\"extract/A.bin\", \"extract/B.bin\"],\n        reference=\"reference/genome.fasta\",\n        fai=\"reference/genome.fasta.fai\",\n    output:\n        \"merged/group-bounds.txt\" # must end with \"-bounds.txt\"\n    params:\n        extra=\"\" # optionally add further command line arguments\n    log:\n        \"log/strling/merge/group.log\"\n    wrapper:\n        \"master/bio/strling/merge\""
    },
    {
      "name": "subsample",
      "input": {
        "r1": "{sample}.r1.fq",
        "r2": "{sample}.r2.fq"
      },
      "output": {
        "r1": "{sample}.subsampled.r1.fq",
        "r2": "{sample}.subsampled.r2.fq"
      },
      "log": {
        "default": "logs/subsample/{sample}.log"
      },
      "params": {
        "options": "--seed 15",
        "genome_size": "3mb",
        "coverage": 20
      },
      "wrapper": {
        "default": "master/bio/rasusa"
      },
      "input_types": [
        "Reads to subsample in FASTA/Q format. Input files can be named or unnamed."
      ],
      "output_types": [
        "File paths to write subsampled reads to. If using paired-end data, make sure there are two output files in the same order as the input."
      ],
      "rule": "rule subsample:\n    input:\n        r1=\"{sample}.r1.fq\",\n        r2=\"{sample}.r2.fq\",\n    output:\n        r1=\"{sample}.subsampled.r1.fq\",\n        r2=\"{sample}.subsampled.r2.fq\",\n    params:\n        options=\"--seed 15\",\n        genome_size=\"3mb\",  # required, unless `bases` is given\n        coverage=20,  # required, unless `bases is given\n        #bases=\"2gb\"\n    log:\n        \"logs/subsample/{sample}.log\",\n    wrapper:\n        \"master/bio/rasusa\"\n"
    },
    {
      "name": "tabix",
      "input": {
        "default": "{prefix}.vcf.gz"
      },
      "output": {
        "default": "{prefix}.vcf.gz.tbi"
      },
      "log": {
        "default": "logs/tabix/{prefix}.log"
      },
      "params": {
        "default": "-p vcf"
      },
      "wrapper": {
        "default": "master/bio/tabix/index"
      },
      "input_types": [
        "Bgzip compressed file (e.g. BED.gz, GFF.gz, or VCF.gz)"
      ],
      "output_types": [
        "Tabix index file"
      ],
      "rule": "rule tabix:\n    input:\n        \"{prefix}.vcf.gz\",\n    output:\n        \"{prefix}.vcf.gz.tbi\",\n    log:\n        \"logs/tabix/{prefix}.log\",\n    params:\n        # pass arguments to tabix (e.g. index a vcf)\n        \"-p vcf\",\n    wrapper:\n        \"master/bio/tabix/index\"\n"
    },
    {
      "name": "taxonkit_list_txt",
      "input": {
        "taxdump": "multiext('test-taxdump/', 'taxid.map', 'nodes.dmp', 'names.dmp', 'merged.dmp', 'delnodes.dmp')"
      },
      "output": {
        "default": "out/list/{sample}.txt"
      },
      "log": {
        "default": "logs/list/{sample}.log"
      },
      "params": {
        "command": "list",
        "extra": "--ids 36846609 --indent '\t' --show-name --show-rank"
      },
      "wrapper": {
        "default": "master/bio/taxonkit"
      },
      "input_types": [
        {
          "input": "input file(s)"
        },
        {
          "taxdump": "taxdump files"
        }
      ],
      "output_types": [
        {
          "taxdump": "output taxdump files"
        }
      ],
      "rule": "rule taxonkit_list_txt:\n    input:\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/list/{sample}.txt\",\n    log:\n        \"logs/list/{sample}.log\",\n    params:\n        command=\"list\",\n        extra=\"--ids 36846609 --indent '\\t' --show-name --show-rank\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_list_json:\n    input:\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/list/{sample}.json\",\n    log:\n        \"logs/list/{sample}.log\",\n    params:\n        command=\"list\",\n        extra=\"--ids 36846609 --show-name --show-rank\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_lineage:\n    input:\n        input=\"taxon_ids.txt\",\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/lineage/{sample}.txt\",\n    log:\n        \"logs/lineage/{sample}.log\",\n    params:\n        command=\"lineage\",\n        extra=\"--show-status-code\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_reformat:\n    input:\n        input=\"taxon_ids.txt\",\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/reformat/{sample}.txt\",\n    log:\n        \"logs/reformat/{sample}.log\",\n    params:\n        command=\"reformat\",\n        extra=\"--taxid-field 1\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_name2taxid:\n    input:\n        input=\"taxon_name.txt\",\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/name2taxid/{sample}.txt\",\n    log:\n        \"logs/name2taxid/{sample}.log\",\n    params:\n        command=\"name2taxid\",\n        extra=\"--show-rank\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_filter:\n    input:\n        input=\"taxon_ids.txt\",\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/filter/{sample}.txt\",\n    log:\n        \"logs/filter/{sample}.log\",\n    params:\n        command=\"filter\",\n        extra=\"--equal-to species\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_lca:\n    input:\n        input=\"taxon_ids.txt\",\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/lca/{sample}.txt\",\n    log:\n        \"logs/lca/{sample}.log\",\n    params:\n        command=\"lca\",\n        extra=\"--separator ','\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_create_taxdump:\n    input:\n        input=[\"lineages1.txt\", \"lineages2.txt\"],\n    output:\n        taxdump=multiext(\n            \"out/create-taxdump/{sample}/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    log:\n        \"logs/create-taxdump/{sample}.log\",\n    params:\n        command=\"create-taxdump\",\n        extra=\"--field-accession 1 --rank-names 'superkingdom,phylum,class,order,family,genus,species'\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_profile2cami:\n    input:\n        input=\"abundance.tsv\",\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/profile2cami/{sample}.txt\",\n    log:\n        \"logs/profile2cami/{sample}.log\",\n    params:\n        command=\"profile2cami\",\n        extra=\"--sample-id sample1 --taxonomy-id 2021-10-01\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n\n\nrule taxonkit_cami_filter:\n    input:\n        input=rules.taxonkit_profile2cami.output[0],\n        taxdump=multiext(\n            \"test-taxdump/\",\n            \"taxid.map\",\n            \"nodes.dmp\",\n            \"names.dmp\",\n            \"merged.dmp\",\n            \"delnodes.dmp\",\n        ),\n    output:\n        \"out/cami_filter/{sample}.tsv\",\n    log:\n        \"logs/cami_filter/{sample}.log\",\n    params:\n        command=\"cami-filter\",\n        extra=\"--taxids 2759\",\n    threads: 2\n    wrapper:\n        \"master/bio/taxonkit\"\n"
    },
    {
      "name": "test_DESeqDataSet_filtering",
      "input": {
        "dds": "dataset/dds.RDS"
      },
      "output": {
        "default": "dds_minimal.RDS"
      },
      "log": {
        "default": "logs/DESeqDataSet/txi.log"
      },
      "params": {
        "formula": "~condition",
        "factor": "condition",
        "reference_level": "A",
        "tested_level": "B",
        "min_counts": 0,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/deseq2/deseqdataset"
      },
      "input_types": [
        {
          "colData": "Path to the file describing the experiment design (TSV formatted file). First column contains sample names."
        },
        {
          "dds": "Path to the DESeqDataSet object (RDS formatted file) *OR*"
        },
        {
          "txi": "Path to the tximport/tximeta SummarizedExperiment object (RDS formatted file) *OR*"
        },
        {
          "se": "Path to the RangedSummarizedExperiment object (RDS formatted file) *OR*"
        },
        {
          "matrix": "Path to the R `matrix(...) ` containing counts. Sample names must be in rownames. (RDS formatted file) *OR*"
        },
        {
          "counts": "Path to the text matrix containing counts. Sample names should be in the first column. (TSV formatted file) *OR*"
        },
        {
          "htseq_dir": "Path to the directory containing HTSeq/FeatureCount count matrices *AND*"
        },
        {
          "sample_table": "Path to the table containing sample names and path to HTSeq/FeatureCount count matrices"
        }
      ],
      "output_types": [
        "Path to the DESeqDataSet object (RDS formatted file)"
      ],
      "rule": "rule test_DESeqDataSet_filtering:\n    input:\n        dds=\"dataset/dds.RDS\",\n    output:\n        \"dds_minimal.RDS\",\n    threads: 1\n    log:\n        \"logs/DESeqDataSet/txi.log\",\n    params:\n        formula=\"~condition\",  # Required R statistical formula\n        factor=\"condition\",  # Optionally used for relevel\n        reference_level=\"A\",  # Optionally used for relevel\n        tested_level=\"B\",  # Optionally used for relevel\n        min_counts=0,  # Optionally used to filter low counts\n        extra=\"\",  # Optional parameters provided to import function\n    wrapper:\n        \"master/bio/deseq2/deseqdataset\"\n\n\nrule test_DESeqDataSet_from_tximport:\n    input:\n        txi=\"dataset/txi.RDS\",\n        colData=\"coldata.tsv\",\n    output:\n        \"dds_txi.RDS\",\n    threads: 1\n    log:\n        \"logs/DESeqDataSet/txi.log\",\n    params:\n        formula=\"~condition\",  # Required R statistical formula\n        # factor=\"condition\", # Optionally used for relevel\n        # reference_level=\"A\", # Optionally used for relevel\n        # tested_level=\"B\", # Optionally used for relevel\n        # min_counts=0, # Optionally used to filter low counts\n        # extra=\"\", # Optional parameters provided to import function\n    wrapper:\n        \"master/bio/deseq2/deseqdataset\"\n\n\nrule test_DESeqDataSet_from_ranged_se:\n    input:\n        se=\"dataset/se.RDS\",\n    output:\n        \"dds_se.RDS\",\n    threads: 1\n    log:\n        \"logs/DESeqDataSet/se.log\",\n    params:\n        formula=\"~condition\",  # Required R statistical formula\n        # factor=\"condition\", # Optionally used for relevel\n        # reference_level=\"A\", # Optionally used for relevel\n        # tested_level=\"B\", # Optionally used for relevel\n        # min_counts=0, # Optionally used to filter low counts\n        # extra=\"\", # Optional parameters provided to import function\n    wrapper:\n        \"master/bio/deseq2/deseqdataset\"\n\n\nrule test_DESeqDataSet_from_r_matrix:\n    input:\n        matrix=\"dataset/matrix.RDS\",\n        colData=\"coldata.tsv\",\n    output:\n        \"dds_rmatrix.RDS\",\n    threads: 1\n    log:\n        \"logs/DESeqDataSet/r_matrix.log\",\n    params:\n        formula=\"~condition\",  # Required R statistical formula\n        # factor=\"condition\", # Optionally used for relevel\n        # reference_level=\"A\", # Optionally used for relevel\n        # tested_level=\"B\", # Optionally used for relevel\n        # min_counts=0, # Optionally used to filter low counts\n        # extra=\"\", # Optional parameters provided to import function\n    wrapper:\n        \"master/bio/deseq2/deseqdataset\"\n\n\nrule test_DESeqDataSet_from_tsv_matrix:\n    input:\n        counts=\"dataset/counts.tsv\",\n        colData=\"coldata.tsv\",\n    output:\n        \"dds_matrix.RDS\",\n    threads: 1\n    log:\n        \"logs/DESeqDataSet/txt_matrix.log\",\n    params:\n        formula=\"~condition\",  # Required R statistical formula\n        # factor=\"condition\", # Optionally used for relevel\n        # reference_level=\"A\", # Optionally used for relevel\n        # tested_level=\"B\", # Optionally used for relevel\n        # min_counts=0, # Optionally used to filter low counts\n        # extra=\"\", # Optional parameters provided to import function\n    wrapper:\n        \"master/bio/deseq2/deseqdataset\"\n\n\nrule test_DESeqDataSet_from_htseqcount:\n    input:\n        htseq_dir=\"dataset/htseq_dir\",\n        sample_table=\"sample_table.tsv\",\n    output:\n        \"dds_htseq.RDS\",\n    threads: 1\n    log:\n        \"logs/DESeqDataSet/txt_matrix.log\",\n    params:\n        formula=\"~condition\",  # Required R statistical formula\n        # factor=\"condition\", # Optionally used for relevel\n        # reference_level=\"A\", # Optionally used for relevel\n        # tested_level=\"B\", # Optionally used for relevel\n        # min_counts=0, # Optionally used to filter low counts\n        # extra=\"\", # Optional parameters provided to import function\n    wrapper:\n        \"master/bio/deseq2/deseqdataset\"\n"
    },
    {
      "name": "test_agat_config",
      "input": {},
      "output": {
        "default": "agat_config.yaml"
      },
      "log": {
        "default": "test_agat_config.log"
      },
      "params": {
        "command": "config"
      },
      "wrapper": {
        "default": "master/bio/agat"
      },
      "input_types": [
        "Named input files. Names will be used as argument values in the final command line."
      ],
      "output_types": [
        "Named output files. Names will be used as argument values in the final command line."
      ],
      "rule": "rule test_agat_config:\n    output:\n        \"agat_config.yaml\",\n    threads: 1\n    log:\n        \"test_agat_config.log\",\n    params:\n        command=\"config\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_levels:\n    output:\n        \"agat_levels.yaml\",\n    log:\n        \"test_agat_levels.log\",\n    params:\n        command=\"levels\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_bed2gff:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        bed=\"test.bed\",\n    output:\n        # The key here will be used as argument name in the final command line\n        gff=\"test_agat_convert_bed2gff.gff\",\n    log:\n        \"test_agat_convert_bed2gff.log\",\n    params:\n        command=\"agat_convert_bed2gff.pl\",\n        extra=\"\",  # Anything besides IO\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_embl2gff:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        embl=\"agat_convert_embl2gff_1.embl\",\n    output:\n        # The key here will be used as argument name in the final command line\n        gff=\"test_agat_convert_embl2gff.gff\",\n    log:\n        \"test_agat_convert_embl2gff.log\",\n    params:\n        command=\"agat_convert_embl2gff.pl\",\n        extra=\"\",  # Anything besides IO\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_genscan2gff:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        genscan=\"test.genscan\",\n    output:\n        # The key here will be used as argument name in the final command line\n        gff=\"test_agat_convert_genscan2gff.gff\",\n    log:\n        \"test_agat_convert_genscan2gff.log\",\n    params:\n        command=\"agat_convert_genscan2gff.pl\",\n        extra=\"\",  # Anything besides IO\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_mfannot2gff:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        mfannot=\"test.mfannot\",\n    output:\n        # The key here will be used as argument name in the final command line\n        gff=\"test_agat_convert_mfannot2gff.gff\",\n    log:\n        \"agat_convert_mfannot2gff.log\",\n    params:\n        # No optional non-file parameters with this subcommand.\n        command=\"agat_convert_mfannot2gff.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_minimap2_bam2gff_bam:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        i=\"test_minimap2.bam\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_convert_minimap2_bam2gff_bam.gff\",\n    log:\n        \"agat_convert_minimap2_bam2gff_bam.log\",\n    params:\n        # All non-file parameters are auto detected.\n        command=\"agat_convert_minimap2_bam2gff.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_minimap2_bam2gff_sam:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        i=\"test_minimap2.sam\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_convert_minimap2_bam2gff_sam.gff\",\n    log:\n        \"agat_convert_minimap2_bam2gff_sam.log\",\n    params:\n        # All non-file parameters are auto detected.\n        command=\"agat_convert_minimap2_bam2gff.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_sp_gff2bed:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_convert_sp_gff2bed.bed\",\n    log:\n        \"agat_convert_sp_gff2bed.log\",\n    params:\n        command=\"agat_convert_sp_gff2bed.pl\",\n        extra=\"\",  # Non file arguments (`--nc` or `--sub`).\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_sp_gff2gtf:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_convert_sp_gff2gtf.gtf\",\n    log:\n        \"agat_convert_sp_gff2gtf.log\",\n    params:\n        command=\"agat_convert_sp_gff2gtf.pl\",\n        extra=\"\",  # Non file arguments (`--gtf_version`).\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_sp_gff2tsv:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_convert_sp_gff2tsv.tsv\",\n    log:\n        \"agat_convert_sp_gff2tsv.log\",\n    params:\n        # No non-file parameters for this command\n        command=\"agat_convert_sp_gff2tsv.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_sp_gff2zff:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line\n        ann=\"test_agat_convert_sp_gff2zff.ann\",\n        dna=\"test_agat_convert_sp_gff2zff.dna\",\n    log:\n        \"agat_convert_sp_gff2zff.log\",\n    params:\n        # No non-file parameters for this command\n        command=\"agat_convert_sp_gff2zff.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_convert_sp_gxf2gxf:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_convert_sp_gxf2gxf.gff\",\n    log:\n        \"agat_convert_sp_gxf2gfx.log\",\n    params:\n        command=\"agat_convert_sp_gxf2gxf.pl\",\n        extra=\"\",  # Non file arguments (`-v`).\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_Prokka_inferNameFromAttributes:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_Prokka_inferNameFromAttributes.gff\",\n    log:\n        \"agat_sp_Prokka_inferNameFromAttributes.log\",\n    params:\n        command=\"agat_sp_Prokka_inferNameFromAttributes.pl\",\n        extra=\"\",  # Non file arguments (`--force`).\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_add_intergenic_regions:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_add_intergenic_regions.gff\",\n    log:\n        \"test_agat_sp_add_intergenic_regions.log\",\n    params:\n        command=\"agat_sp_add_intergenic_regions.pl\",\n        extra=\"\",  # Non file arguments (`--verbose`).\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_add_introns:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_add_introns.gff\",\n    log:\n        \"test_agat_sp_add_introns.log\",\n    params:\n        # No non-file arguments.\n        command=\"agat_sp_add_introns.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_add_splice_sites:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_add_splice_sites.gff\",\n    log:\n        \"test_agat_sp_add_splice_sites.log\",\n    params:\n        # No non-file arguments.\n        command=\"agat_sp_add_splice_sites.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_add_start_and_stop:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_add_start_and_stop.gff\",\n    log:\n        \"test_agat_sp_add_start_and_stop.log\",\n    params:\n        extra=\"\",  # Non-file arguments (e.g. `--codon`, `--extend`, `-v`, or `--na`)\n        command=\"agat_sp_add_start_and_stop.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_alignment_output_style:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_alignment_output_style.gff\",\n    log:\n        \"test_agat_sp_alignment_output_style.log\",\n    params:\n        extra=\"\",  # Non-file arguments (e.g. `--ct`, or `-v`)\n        command=\"agat_sp_alignment_output_style.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_clipN_seqExtremities_and_fixCoordinates:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line\n        og=\"test_agat_sp_clipN_seqExtremities_and_fixCoordinates.gff\",\n        of=\"test_agat_sp_clipN_seqExtremities_and_fixCoordinates.fasta\",\n    log:\n        \"test_agat_sp_clipN_seqExtremities_and_fixCoordinates.log\",\n    params:\n        extra=\"\",  # Non-file arguments (e.g. `--of`, or `--og`)\n        command=\"agat_sp_clipN_seqExtremities_and_fixCoordinates.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_compare_two_annotations:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff1=\"annotation.gff\",\n        gff2=\"prokka_fragmented_genes.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        # This subcommand returns a file per case, which names are build based\n        # on the comparison result as well as a report.\n        out=directory(\"test_agat_sp_compare_two_annotation\"),\n    log:\n        \"test_agat_sp_compare_two_annotations.log\",\n    params:\n        extra=\"\",  # Non-file arguments (`-v`)\n        command=\"agat_sp_compare_two_annotations.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_complement_annotations:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        ref=\"annotation.gff\",\n        add=\"prokka_fragmented_genes.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        out=\"test_agat_sp_complement_annotations.gff\",\n    log:\n        \"test_agat_sp_complement_annotations.log\",\n    params:\n        extra=\"\",  # Non-file arguments (`--size_min`)\n        command=\"agat_sp_complement_annotations.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_ensembl_output_style:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_ensembl_output_style.gff\",\n    log:\n        \"test_agat_sp_ensembl_output_style.log\",\n    params:\n        extra=\"\",  # Non-file arguments (`--ct`, or `-v`)\n        command=\"agat_sp_ensembl_output_style.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_extract_attributes:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        Parent=\"test_agat_sp_extract_attributes_Parent.txt\",\n        ID=\"test_agat_sp_extract_attributes_ID.txt\",\n    log:\n        \"test_agat_sp_extract_attributes.log\",\n    params:\n        # Non-file arguments besides `--att` (e.g. `-p`, `--merge`, or `-d`)\n        extra=\"-d\",\n        command=\"agat_sp_extract_attributes.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_extract_sequences:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_extract_sequences.fasta\",\n    log:\n        \"test_agat_sp_extract_attributes.log\",\n    params:\n        # Non-file arguments (e.g. `--asc`, `--cdna`, `--cfs`, ...)\n        extra=\"-p -t cds\",\n        command=\"agat_sp_extract_sequences.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_by_ORF_size:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # Matched = ORF size satisfying `--test` and `--size` criteria\n        matched=\"test_agat_sp_filter_by_ORF_size_matched.gff\",\n        # Unmatched = ORF size *NOT* satisfying `--test` and `--size` criteria\n        unmatched=\"test_agat_sp_filter_by_ORF_size_unmatched.gff\",\n    log:\n        \"test_agat_sp_filter_by_ORF_size.log\",\n    params:\n        # Non-file arguments (e.g. `--size`, `--test`, or `-v`)\n        extra=\"\",\n        command=\"agat_sp_filter_by_ORF_size.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_by_locus_distance:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        outfile=\"test_agat_sp_filter_by_locus_distance.gff\",\n    log:\n        \"test_agat_sp_filter_by_locus_distance.log\",\n    params:\n        # Non-file arguments (e.g. `-d`, or `--add_flag`)\n        extra=\"\",\n        command=\"agat_sp_filter_by_locus_distance.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_feature_by_attribute_presence:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_filter_feature_by_attribute_presence.gff\",\n    log:\n        \"test_agat_sp_filter_feature_by_attribute_presence.log\",\n    params:\n        # Non-file arguments (`--type`, `--flip` or `--att`)\n        extra=\"--type gene --att Parent\",\n        command=\"agat_sp_filter_feature_by_attribute_presence.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_feature_by_attribute_value:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_filter_feature_by_attribute_value.gff\",\n    log:\n        \"test_agat_sp_filter_feature_by_attribute_value.log\",\n    params:\n        # Non-file arguments (e.g. `--type`, `--value`, `--value_insensitive`...)\n        extra=\"--type exon --attribute constitutive --value 1\",\n        command=\"agat_sp_filter_feature_by_attribute_value.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_feature_from_keep_list:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        keep_list=\"keep_list.txt\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_filter_feature_from_keep_list.gff\",\n    log:\n        \"test_agat_sp_filter_feature_from_keep_list.log\",\n    params:\n        # Non-file arguments (`--type`, or `-v`)\n        extra=\"-v\",\n        command=\"agat_sp_filter_feature_from_keep_list.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_feature_from_kill_list:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        kill_list=\"kill_list.txt\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_filter_feature_from_kill_list.gff\",\n    log:\n        \"test_agat_sp_filter_feature_from_kill_list.log\",\n    params:\n        # Non-file arguments (`--type`, or `-v`)\n        extra=\"-v\",\n        command=\"agat_sp_filter_feature_from_kill_list.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_gene_by_intron_numbers:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_filter_gene_by_intron_numbers.gff\",\n    log:\n        \"test_agat_sp_filter_gene_by_intron_numbers.log\",\n    params:\n        # Non-file arguments (`--number`, `-v`, or `--test`)\n        extra=\"--test '>=' --nb 3\",\n        command=\"agat_sp_filter_gene_by_intron_numbers.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_gene_by_length:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line\n        o=\"test_agat_sp_filter_gene_by_length.gff\",\n    log:\n        \"test_agat_sp_filter_gene_by_length.log\",\n    params:\n        # Non-file arguments (`--size`, `-v`, or `--test`)\n        extra=\"--test '>=' --size 3\",\n        command=\"agat_sp_filter_gene_by_length.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_incomplete_gene_coding_models:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line\n        outfile=\"test_agat_sp_filter_incomplete_gene_coding_models.gff\",\n    log:\n        \"test_agat_sp_filter_incomplete_gene_coding_models.log\",\n    params:\n        # Non-file arguments (e.g. `--codon`, `--add_flag`, `--skip_start_check`, ...)\n        extra=\"-v\",\n        command=\"agat_sp_filter_incomplete_gene_coding_models.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_filter_record_by_coordinates:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        coordinates=\"coordinates.tsv\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        # The directory contains a file per interval (if any record exists within),\n        # a GFF with records belonging to none of the intervald given in coordinates,\n        # and a text report.\n        o=directory(\"test_agat_sp_filter_record_by_coordinates\"),\n    log:\n        \"test_agat_sp_filter_record_by_coordinates.log\",\n    params:\n        # Non-file arguments (`--exclude` or `-v`)\n        extra=\"-v\",\n        command=\"agat_sp_filter_record_by_coordinates.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_fix_cds_phases:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        o=\"test_agat_sp_fix_cds_phases.gff\",\n    log:\n        \"test_agat_sp_fix_cds_phases.log\",\n    params:\n        # Non-file arguments (`-v`)\n        extra=\"\",\n        command=\"agat_sp_fix_cds_phases.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_fix_features_locations_duplicated:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        outfile=\"test_agat_sp_fix_features_locations_duplicated.gff\",\n    log:\n        \"test_agat_sp_fix_features_locations_duplicated.log\",\n    params:\n        # Non-file arguments (`-v`, or `--model`)\n        extra=\"\",\n        command=\"agat_sp_fix_features_locations_duplicated.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_fix_fusion:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # Optional file contains all features in the GFF\n        all=\"test_agat_sp_fix_fusion_all.gff\",\n        # Optional file only contains features that were modified by agat\n        only_modified=\"test_agat_sp_fix_fusion_modified.gff\",\n        # Optional file only contains features that were *NOT* modified by agat\n        intact=\"test_agat_sp_fix_fusion_intact.gff\",\n        # An optional report over the number of modified/intact features\n        report=\"test_agat_sp_fix_fusion_report.txt\",\n    log:\n        \"test_agat_sp_fix_fusion.log\",\n    params:\n        # Non-file arguments (`--codon`, `--threshold`, `--stranded`, or `-v`)\n        extra=\"\",\n        command=\"agat_sp_fix_fusion.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_fix_longest_ORF:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # Optional file contains all features in the GFF\n        all=\"test_agat_sp_fix_longest_ORF_all.gff\",\n        # Optional file only contains features that were modified by agat\n        only_modified=\"test_agat_sp_fix_longest_ORF_modified.gff\",\n        # Optional file only contains features that were *NOT* modified by agat\n        intact=\"test_agat_sp_fix_longest_ORF_intact.gff\",\n        # An optional report over the number of modified/intact features\n        report=\"test_agat_sp_fix_longest_ORF_report.txt\",\n    log:\n        \"test_agat_sp_fix_longest_ORF.log\",\n    params:\n        # Non-file arguments (`--codon`, `--split`, `--stranded`, or `-v`)\n        extra=\"\",\n        command=\"agat_sp_fix_longest_ORF.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_fix_overlaping_genes:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        outfile=\"test_agat_sp_fix_overlaping_genes.gff\",\n    log:\n        \"test_agat_sp_fix_overlaping_genes.log\",\n    params:\n        # Non-file arguments (`--merge` or `--verbose`)\n        extra=\"\",\n        command=\"agat_sp_fix_overlaping_genes.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_fix_small_exon_from_extremities:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        outfile=\"test_agat_sp_fix_small_exon_from_extremities.gff\",\n    log:\n        \"test_agat_sp_fix_small_exon_from_extremities.log\",\n    params:\n        # Non-file arguments (`--merge`, `--size`, `--codon`, or `-v`)\n        extra=\"\",\n        command=\"agat_sp_fix_small_exon_from_extremities.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_flag_premature_stop_codons:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_flag_premature_stop_codons.gff\",\n    log:\n        \"test_agat_sp_flag_premature_stop_codons.log\",\n    params:\n        extra=\"\",  # Non-file argument: `--codon`\n        command=\"agat_sp_flag_premature_stop_codons.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_flag_short_introns:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_flag_short_introns.gff\",\n    log:\n        \"test_agat_sp_flag_short_introns.log\",\n    params:\n        # Non-file parameters (`--intron_size` or `-v`)\n        extra=\"\",\n        command=\"agat_sp_flag_short_introns.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_functional_statistics:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        # This directory contains sub-directory for each type of features available\n        # in the GFF/GTF file, as long as a report\n        o=directory(\"test_agat_sp_functional_statistics\"),\n    log:\n        \"test_agat_sp_functional_statistics.log\",\n    params:\n        # Non-file parameters (`--gs`)\n        extra=\"\",\n        command=\"agat_sp_functional_statistics.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_keep_longest_isoform:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        o=\"test_agat_sp_keep_longest_isoform.gff\",\n    log:\n        \"test_agat_sp_keep_longest_isoform.log\",\n    params:\n        # No non-file parameters allowed\n        command=\"agat_sp_keep_longest_isoform.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_kraken_assess_liftover:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gtf=\"test_kraken.gtf\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_kraken_assess_liftover.gff\",\n    log:\n        \"test_agat_sp_kraken_assess_liftover.log\",\n    params:\n        # Non-file parameters (`--threshold` or `--verbose`)\n        extra=\"\",\n        command=\"agat_sp_kraken_assess_liftover.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_list_short_introns:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_list_short_introns.gff\",\n    log:\n        \"test_agat_sp_list_short_introns.log\",\n    params:\n        # Non-file parameter: `--size`\n        extra=\"\",\n        command=\"agat_sp_list_short_introns.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_manage_IDs:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_manage_IDs.gff\",\n    log:\n        \"test_agat_sp_manage_IDs.log\",\n    params:\n        # Non-file parameters (e.g. `--gap`, `--ensembl`, `--prefix`, ...)\n        extra=\"\",\n        command=\"agat_sp_manage_IDs.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_manage_UTRs:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # Optional path to PDF histogram of 5'UTR with at least <n> exons\n        five_prime_utr_overORequal=\"test_agat_sp_manage_UTRs_five_prime_utr_overORequal.pdf\",\n        # Optional path to PDF histogram of 5'UTR with less than <n> exons\n        five_prime_utr_under=\"test_agat_sp_manage_UTRs_five_prime_utr_under.pdf\",\n        # Optional path to PDF histogram of 3'UTR with at least <n> exons\n        three_prime_utr_overORequal=\"test_agat_sp_manage_UTRs_three_prime_utr_overORequal.pdf\",\n        # Optional path to PDF histogram of 3'UTR with at least <n> exons\n        three_prime_utr_under=\"test_agat_sp_manage_UTRs_three_prime_utr_under.pdf\",\n        # Optional path to PDF histogram of both 3/5'UTR with at least <n> exons\n        # both_utr_overORequal=\"test_agat_sp_manage_UTRs_both_utr_overORequal.pdf\",\n        # Optional path to PDF histogram of both 3/5'UTR with at least <n> exons\n        # both_utr_under=\"test_agat_sp_manage_UTRs_both_utr_under.pdf\",\n        # Optional path to analysis report\n        report=\"test_agat_sp_manage_UTRs_report.txt\",\n    log:\n        \"test_agat_sp_manage_UTRs.log\",\n    params:\n        # Non-file parameters (e.g. `--number`, `--three`, `--five`, or `--both`)\n        # The parameter `--plot` is automatically infered\n        extra=\"--three --five -n 6\",\n        command=\"agat_sp_manage_UTRs.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_manage_attributes:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_manage_attributes.gff\",\n    log:\n        \"test_agat_sp_manage_attributes.log\",\n    params:\n        # Non-file parameters (`--type`, `--tag`, `--add`, `--cp`, or `--overwrite`)\n        extra=\"--att biotype\",\n        command=\"agat_sp_manage_attributes.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_manage_functional_annotation:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sp_manage_functional_annotation/02413F.gff\",\n        # Optional path to blast, interpro, and reference fasta\n        blast=\"agat_sp_manage_functional_annotation/02413F_blast.out\",\n        db=\"agat_sp_manage_functional_annotation/uniprot_sprot_test.fasta\",\n        interpro=\"agat_sp_manage_functional_annotation/02413F_interpro.tsv\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        gff=\"test_agat_sp_manage_functional_annotation.gff\",\n        # Global text report\n        report=\"test_agat_sp_manage_functional_annotation.report.txt\",\n        # Warnings and non-blocking format errors\n        error=\"test_agat_sp_manage_functional_annotation.error.txt\",\n        # Duplicates blast sequences, requires blast and db\n        duplicates=\"test_agat_sp_manage_functional_annotation.duplicates.tsv\",\n        # Conserved protein domains database terms, requires all optional input\n        cdd=\"test_agat_sp_manage_functional_annotation.cdd.tsv\",\n        # Gene onthology database terms, requires all optional input\n        go=\"test_agat_sp_manage_functional_annotation.go.tsv\",\n        # Interpro domain database terms, requires all optional input\n        interpro=\"test_agat_sp_manage_functional_annotation.interpro.tsv\",\n        # MobiDB Lite database terms, requires all optional input\n        mobidb=\"test_agat_sp_manage_functional_annotation.mobidblite.tsv\",\n        # Panther database terms, requires all optional input\n        panther=\"test_agat_sp_manage_functional_annotation.panther.tsv\",\n        # Superfamily database terms, requires all optional input\n        superfamily=\"test_agat_sp_manage_functional_annotation.superfamily.tsv\",\n    log:\n        \"test_agat_sp_manage_functional_annotation.log\",\n    params:\n        # Non-file parameters (e.g. `--blast_evalue`, `--pe`, `--clean_ontology`, ...)\n        # The parameter `--plot` is automatically infered.\n        extra=\"\",\n        command=\"agat_sp_manage_functional_annotation.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_manage_introns:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # Optional path to intron report\n        report=\"test_agat_sp_manage_introns_report.txt\",\n        # Optional path to cds histogram (triggers the `--plot` argument)\n        cds_pdf=\"test_agat_sp_manage_introns_cds.pdf\",\n        # Optional path to exon histogram (triggers the `--plot` argument)\n        exon_pdf=\"test_agat_sp_manage_introns_exons.pdf\",\n        # Optional path to 3'UTR histogram (triggers the `--plot` argument)\n        # three_prime_utr_pdf=\"test_agat_sp_manage_introns_exons_3p.pdf\",\n        # Optional path to 5'UTR histogram (triggers the `--plot` argument)\n        five_prime_utr_pdf=\"test_agat_sp_manage_introns_exons_5p.pdf\",\n    log:\n        \"test_agat_sp_manage_introns.log\",\n    params:\n        # Non-file parameters (`--p`, `--window`)\n        # The parameter `--plot` is automatically infered.\n        extra=\"\",\n        command=\"agat_sp_manage_introns.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_merge_annotations:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=[\"prokka_fragmented_genes.gff\", \"annotation.gff\"],\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_merge_annotations.gff\",\n    log:\n        \"test_agat_sp_merge_annotations.log\",\n    params:\n        # No non-file parameters\n        command=\"agat_sp_merge_annotations.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_move_attributes_within_records:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        out=\"test_agat_sp_move_attributes_within_records.gff\",\n    log:\n        \"test_agat_sp_move_attributes_within_records.log\",\n    params:\n        # Non-file parameters (`--fp`, `--fc`, `--attribute`, or `-v`)\n        extra=\"--feature_copy mRNA  --feature_paste CDS\",\n        command=\"agat_sp_move_attributes_within_records.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_prokka_fix_fragmented_gene_annotations:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"prokka_fragmented_genes.gff\",\n        fasta=\"prokka_cav_10DC88.fa\",\n        db=\"prokka_bacteria_sprot.fa\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        # The output directory contains a `report.txt` and additional files\n        # depending on the content of input file(s).\n        out=directory(\"test_agat_sp_prokka_fix_fragmented_gene_annotations\"),\n    log:\n        \"test_agat_sp_prokka_fix_fragmented_gene_annotations.log\",\n    params:\n        # Non-file parameters:\n        # `--frags`, `--pseudo`, `--hmap_size`, `--ct`, `--skip_hmap`, or `-v`\n        extra=\"--skip_hamap\",  # To speed up tests\n        command=\"agat_sp_prokka_fix_fragmented_gene_annotations.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_sensitivity_specificity:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff1=\"prokka_fragmented_genes.gff\",\n        gff2=\"annotation.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        outfile=\"test_agat_sp_sensitivity_specificity.txt\",\n    log:\n        \"test_agat_sp_sensitivity_specificity.log\",\n    params:\n        # Non-file parameters (`-v`)\n        extra=\"\",\n        command=\"agat_sp_sensitivity_specificity.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_separate_by_record_type:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # The key here will be used as argument name in the final command line.\n        # The output directory contains up to one file per record type among the\n        # huge list of records available in `agat levels`.\n        o=directory(\"test_agat_sp_separate_by_record_type\"),\n    log:\n        \"test_agat_sp_separate_by_record_type.log\",\n    params:\n        # No non-file parameters\n        command=\"agat_sp_separate_by_record_type.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sp_statistics:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # Optional Path to text report\n        report=\"test_agat_sp_statistics.txt\",\n        # Optional path to yaml report (triggers the `--yaml` argument)\n        yaml=\"test_agat_sp_statistics.yaml\",\n        # Optional path to directory containing multiple plots, corresponding\n        # to each level present in the input GFF file and described by the\n        # `agat levels` command. Triggers `-p` argument.\n        plot=directory(\"test_agat_sp_statistics_plots\"),\n    log:\n        \"test_agat_sp_statistics.log\",\n    params:\n        # Non-file parameters: `--gs`, or `--verbose`)\n        # All other non-file parameters are automatically infered\n        extra=\"--gs 432709230\",\n        command=\"agat_sp_statistics.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_add_attributes_from_tsv:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n        tsv=\"agat_sq_add_attributes_from_tsv.tsv\",\n    output:\n        # Optional Path to text report\n        o=\"test_agat_sq_add_attributes_from_tsv.gff\",\n    log:\n        \"test_agat_sq_add_attributes_from_tsv.log\",\n    params:\n        # Non-file parameters: `--vebose`\n        # All other parameters are automatically included\n        extra=\"\",\n        command=\"agat_sq_add_attributes_from_tsv.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_add_hash_tag:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # Optional Path to text report\n        o=\"test_agat_sq_add_hash_tag.gff\",\n    log:\n        \"test_agat_sq_add_hash_tag.log\",\n    params:\n        extra=\"--interval 1\",\n        command=\"agat_sq_add_hash_tag.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_add_locus_tag:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"agat_sq_add_attributes_from_tsv.gff\",\n    output:\n        # Optional Path to text report\n        o=\"test_agat_sq_add_locus_tag.gff\",\n    log:\n        \"test_agat_sq_add_locus_tag.log\",\n    params:\n        # Non-file parameters, eg: `--type`, `--lo`, `--li`, `--of` or `--quiet`\n        extra=\"\",\n        command=\"agat_sq_add_locus_tag.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_filter_feature_from_fasta:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n        fasta=\"sequence.fa\",\n    output:\n        # Optional Path to text report\n        o=\"test_agat_sq_filter_feature_from_fasta.gff\",\n    log:\n        \"test_agat_sq_filter_feature_from_fasta.log\",\n    params:\n        # Only verbosity parameter is expected, other ones are automatically filled\n        extra=\"--verbose\",\n        command=\"agat_sq_filter_feature_from_fasta.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_list_attributes:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # Optional Path to attributes\n        outfile=\"test_agat_sq_list_attributes.txt\",\n    log:\n        \"test_agat_sq_list_attributes.log\",\n    params:\n        # Only `-p`, `-t` or `-l`, other options are automatically infered\n        extra=\"-p level2,cds,exon\",\n        command=\"agat_sq_list_attributes.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_manage_IDs:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # Optional Path to ids\n        o=\"test_agat_sq_manage_IDs.txt\",\n    log:\n        \"test_agat_sq_manage_IDs.log\",\n    params:\n        # Only `--of`, all other parameters are infered\n        extra=\"--of 2\",\n        command=\"agat_sq_manage_IDs.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_manage_attributes:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"annotation.gff\",\n    output:\n        # Optional Path to GFF\n        outfile=\"test_agat_sq_manage_attributes.gff\",\n    log:\n        \"test_agat_sq_manage_attributes.log\",\n    params:\n        # One of `--type`, `--tag` `--add`, `--vp`,\n        # `--overwrite`, `--value` or `--strategy`\n        extra=\"--tag locus_tag,product,name/NewName --type level2,cds,exon\",\n        command=\"agat_sq_manage_attributes.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_mask:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"prokka_fragmented_genes.gff\",\n        fasta=\"prokka_cav_10DC88.fa\",\n    output:\n        # Path to masked GFF/GTF\n        o=\"test_agat_sq_mask.gff\",\n    log:\n        \"test_agat_sq_mask.log\",\n    params:\n        # Only `--sm` or `--hm` (mutually exclusive), all other parameters are infered.\n        extra=\"--hm\",\n        command=\"agat_sq_mask.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_remove_redundant_entries:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"prokka_fragmented_genes.gff\",\n    output:\n        # Path to GFF entries\n        o=\"test_agat_sq_remove_redundant_entries.gff\",\n    log:\n        \"test_agat_sq_remove_redundant_entries.log\",\n    params:\n        # All parameters are filled automatically\n        command=\"agat_sq_remove_redundant_entries.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_repeats_analyzer:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"prokka_fragmented_genes.gff\",\n        # Optional path to fasta sequence, see params.extra\n        genome=\"prokka_cav_10DC88.fa\",\n    output:\n        # Path to repeats\n        o=\"test_agat_sq_repeats_analyzer.gff\",\n    log:\n        \"test_agat_sq_repeats_analyzer.log\",\n    params:\n        # If no fasta file is provided in `input.genome`, then provide the genome size\n        # through optional parameter below:\n        # extra=\"--genome 125\",\n        command=\"agat_sq_repeats_analyzer.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_reverse_complement:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"prokka_fragmented_genes.gff\",\n        fasta=\"prokka_cav_10DC88.fa\",\n    output:\n        # Path to revert complement\n        o=\"test_agat_sq_reverse_complement.gff\",\n    log:\n        \"test_agat_sq_reverse_complement.log\",\n    params:\n        # Only verbosity parameter is allowed, other ones are automatically filled\n        extra=\"--verbose\",\n        command=\"agat_sq_reverse_complement.pl\",\n    wrapper:\n        \"master/bio/agat\"\n\n\nrule test_agat_sq_rfam_analyzer:\n    input:\n        # The key here will be used as argument name in the final command line\n        # config=\"\", # Optional path to configuration file\n        gff=\"prokka_fragmented_genes.gff\",\n        genome=\"prokka_cav_10DC88.fa\",\n    output:\n        # Optional Path to ids\n        o=\"test_agat_sq_rfam_analyzer.tsv\",\n    log:\n        \"test_agat_sq_rfam_analyzer.log\",\n    params:\n        # If no fasta file is provided in `input.genome`, then provide the genome size\n        # through optional parameter below:\n        # extra=\"--genome 125\",\n        command=\"agat_sq_rfam_analyzer.pl\",\n    wrapper:\n        \"master/bio/agat\"\n"
    },
    {
      "name": "test_bowtie2",
      "input": {
        "sample": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "idx": "multiext('index/genome', '.1.bt2', '.2.bt2', '.3.bt2', '.4.bt2', '.rev.1.bt2', '.rev.2.bt2')"
      },
      "output": {
        "default": "mapped/{sample}.bam"
      },
      "log": {
        "default": "logs/bowtie2/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bowtie2/align"
      },
      "input_types": [
        {
          "sample": "FASTQ file(s)"
        },
        {
          "idx": "Bowtie2 indexed reference index"
        },
        {
          "ref": "Optional path to genome sequence (FASTA)"
        },
        {
          "ref_fai": "Optional path to reference genome sequence index (FAI)"
        }
      ],
      "output_types": [
        "SAM/BAM/CRAM file. This must be the first output file in the output file list.",
        {
          "idx": "Optional path to bam index."
        },
        {
          "metrics": "Optional path to metrics file."
        },
        {
          "unaligned": "Optional path to unaligned unpaired reads."
        },
        {
          "unpaired": "Optional path to unpaired reads that aligned at least once."
        },
        {
          "unconcordant": "Optional path to pairs that didn't align concordantly."
        },
        {
          "concordant": "Optional path to pairs that aligned concordantly at least once."
        }
      ],
      "rule": "rule test_bowtie2:\n    input:\n        sample=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        idx=multiext(\n            \"index/genome\",\n            \".1.bt2\",\n            \".2.bt2\",\n            \".3.bt2\",\n            \".4.bt2\",\n            \".rev.1.bt2\",\n            \".rev.2.bt2\",\n        ),\n        # ref=\"genome.fasta\", #Required for CRAM output\n    output:\n        \"mapped/{sample}.bam\",\n        # idx=\"\",\n        # metrics=\"\",\n        # unaligned=\"\",\n        # unpaired=\"\",\n        # unconcordant=\"\",\n        # concordant=\"\",\n    log:\n        \"logs/bowtie2/{sample}.log\",\n    params:\n        extra=\"\",  # optional parameters\n    threads: 8  # Use at least two threads\n    wrapper:\n        \"master/bio/bowtie2/align\"\n\n\nuse rule test_bowtie2 as test_bowtie2_se_gz with:\n    input:\n        sample=[\"reads/{sample}.1.fastq.gz\"],\n        idx=multiext(\n            \"index/genome\",\n            \".1.bt2\",\n            \".2.bt2\",\n            \".3.bt2\",\n            \".4.bt2\",\n            \".rev.1.bt2\",\n            \".rev.2.bt2\",\n        ),\n    output:\n        \"mapped_se_gz/{sample}.bam\",\n\n\nrule test_bowtie2_index:\n    input:\n        sample=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        idx=multiext(\n            \"index/genome\",\n            \".1.bt2\",\n            \".2.bt2\",\n            \".3.bt2\",\n            \".4.bt2\",\n            \".rev.1.bt2\",\n            \".rev.2.bt2\",\n        ),\n    output:\n        \"mapped_idx/{sample}.bam\",\n        idx=\"mapped_idx/{sample}.bam.bai\",\n        metrics=\"mapped_idx/{sample}.metrics.txt\",\n        unaligned=\"mapped_idx/{sample}.unaligned.sam\",\n        unpaired=\"mapped_idx/{sample}.unpaired.sam\",\n        # unconcordant=\"\",\n        # concordant=\"\",\n    log:\n        \"logs/bowtie2/{sample}.log\",\n    params:\n        extra=\"\",  # optional parameters\n    threads: 8  # Use at least two threads\n    wrapper:\n        \"master/bio/bowtie2/align\"\n\n\nrule test_bowtie2_cram:\n    input:\n        sample=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        idx=multiext(\n            \"index/genome\",\n            \".1.bt2\",\n            \".2.bt2\",\n            \".3.bt2\",\n            \".4.bt2\",\n            \".rev.1.bt2\",\n            \".rev.2.bt2\",\n        ),\n        ref=\"genome.fasta\",\n    output:\n        \"mapped_idx/{sample}.cram\",\n        # idx=\"\",\n        # metrics=\"\",\n        # unaligned=\"\",\n        # unpaired=\"\",\n        # unconcordant=\"\",\n        # concordant=\"\",\n    log:\n        \"logs/bowtie2/{sample}.log\",\n    params:\n        extra=\"\",  # optional parameters\n    threads: 8  # Use at least two threads\n    wrapper:\n        \"master/bio/bowtie2/align\"\n"
    },
    {
      "name": "test_bustools_count",
      "input": {
        "bus": "file.bus",
        "ecmap": "matrix.ec",
        "txnames": "transcripts.txt",
        "genemap": "t2g.txt"
      },
      "output": {
        "default": "multiext('buscount', '.barcodes.txt', '.CUPerCell.txt', '.cu.txt', '.genes.txt', '.hist.txt', '.mtx')"
      },
      "log": {
        "default": "bustools.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bustools/count"
      },
      "input_types": [
        {
          "bus": "Single bus-file, or List of bus-files"
        },
        {
          "genemap": "Transcript to gene mapping"
        },
        {
          "txnames": "List of transcripts"
        },
        {
          "ecmap": "Equivalence classes for transcripts"
        }
      ],
      "output_types": [
        "barcodes, equivalence classes, and count matrix"
      ],
      "rule": "rule test_bustools_count:\n    input:\n        bus=\"file.bus\",\n        ecmap=\"matrix.ec\",\n        txnames=\"transcripts.txt\",\n        genemap=\"t2g.txt\",\n    output:\n        multiext(\n            \"buscount\",\n            \".barcodes.txt\",\n            \".CUPerCell.txt\",\n            \".cu.txt\",\n            \".genes.txt\",\n            \".hist.txt\",\n            \".mtx\",\n        ),\n    threads: 1\n    params:\n        extra=\"\",\n    log:\n        \"bustools.log\",\n    wrapper:\n        \"master/bio/bustools/count\"\n"
    },
    {
      "name": "test_bustools_sort",
      "input": {
        "default": "file.bus"
      },
      "output": {
        "default": "sorted.bus"
      },
      "log": {
        "default": "bustools.log"
      },
      "params": {
        "extra": "--umi"
      },
      "wrapper": {
        "default": "master/bio/bustools/sort"
      },
      "input_types": [
        "Path to bus file, or list of bus files"
      ],
      "output_types": [
        "Path to bus file"
      ],
      "rule": "rule test_bustools_sort:\n    input:\n        \"file.bus\",\n    output:\n        \"sorted.bus\",\n    threads: 1\n    resources:\n        mem_mb=765,\n    params:\n        extra=\"--umi\",\n    log:\n        \"bustools.log\",\n    wrapper:\n        \"master/bio/bustools/sort\"\n"
    },
    {
      "name": "test_bustools_text",
      "input": {
        "default": "file.bus"
      },
      "output": {
        "default": "file.tsv"
      },
      "log": {
        "default": "logs/bustools.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/bustools/text"
      },
      "input_types": [
        "list of bus files"
      ],
      "output_types": [
        "Path to TSV output"
      ],
      "rule": "rule test_bustools_text:\n    input:\n        \"file.bus\",\n    output:\n        \"file.tsv\",\n    threads: 1\n    params:\n        extra=\"\",\n    log:\n        \"logs/bustools.log\",\n    wrapper:\n        \"master/bio/bustools/text\"\n\n\nrule test_bustools_text_list:\n    input:\n        [\"file.bus\", \"file2.bus\"],\n    output:\n        \"file2.tsv\",\n    threads: 1\n    params:\n        extra=\"--flags --pad\",\n    log:\n        \"logs/bustools.log\",\n    wrapper:\n        \"master/bio/bustools/text\"\n"
    },
    {
      "name": "test_bwameth_index_mem",
      "input": {
        "default": "genome.fasta"
      },
      "output": {
        "default": "multiext('genome.fasta.bwameth', '.c2t', '.c2t.amb', '.c2t.ann', '.c2t.bwt', '.c2t.pac', '.c2t.sa')"
      },
      "log": {
        "default": "bwameth_index.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/bwameth/index"
      },
      "input_types": [
        "Path to reference fasta file."
      ],
      "output_types": [
        "List of paths to index files."
      ],
      "rule": "rule test_bwameth_index_mem:\n    input:\n        \"genome.fasta\",\n    output:\n        multiext(\n            \"genome.fasta.bwameth\",\n            \".c2t\",\n            \".c2t.amb\",\n            \".c2t.ann\",\n            \".c2t.bwt\",\n            \".c2t.pac\",\n            \".c2t.sa\",\n        ),\n    cache: True  # save space and time with between workflow caching (see docs)\n    threads: 1\n    log:\n        \"bwameth_index.log\",\n    wrapper:\n        \"master/bio/bwameth/index\"\n\n\nrule test_bwameth_index_mem2:\n    input:\n        \"genome.fasta\",\n    output:\n        multiext(\n            \"genome.fasta.bwameth\",\n            \".c2t\",\n            \".c2t.amb\",\n            \".c2t.ann\",\n            \".c2t.bwt.2bit.64\",\n            \".c2t.pac\",\n            \".c2t.0123\",\n        ),\n    cache: True  # save space and time with between workflow caching (see docs)\n    threads: 1\n    log:\n        \"bwameth_index.log\",\n    wrapper:\n        \"master/bio/bwameth/index\"\n"
    },
    {
      "name": "test_bwameth_mem",
      "input": {
        "ref": "mem/genome.fasta",
        "idx": "multiext('mem/genome.fasta.bwameth', '.c2t', '.c2t.amb', '.c2t.ann', '.c2t.bwt', '.c2t.pac', '.c2t.sa')",
        "fq": [
          "A.fastq"
        ]
      },
      "output": {
        "default": "A.mem.bam"
      },
      "log": {
        "default": "test_bwameth_mem.log"
      },
      "params": {
        "extra": "",
        "sort": "none",
        "sort_order": "coordinate",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/bwameth/memx"
      },
      "input_types": [
        {
          "idx": "List of paths to indexed reference files"
        },
        {
          "fq": "List of path to fastq files"
        },
        {
          "ref": "Path to reference fasta file"
        }
      ],
      "output_types": [
        "Path to mapped reads (SAM/BAM/CRAM)"
      ],
      "rule": "rule test_bwameth_mem:\n    input:\n        ref=\"mem/genome.fasta\",\n        idx=multiext(\n            \"mem/genome.fasta.bwameth\",\n            \".c2t\",\n            \".c2t.amb\",\n            \".c2t.ann\",\n            \".c2t.bwt\",\n            \".c2t.pac\",\n            \".c2t.sa\",\n        ),\n        fq=[\"A.fastq\"],\n    output:\n        \"A.mem.bam\",\n    threads: 2\n    params:\n        extra=\"\",  # Optional parameters for bwameth.py, besides IO and threading\n        sort=\"none\",  # Either `none` (default), `samtools`, or `picard`\n        sort_order=\"coordinate\",  # Either `coordinate` (default) or `queryname`\n        sort_extra=\"\",  # Optional parameters for sambamba/samtools/picard. Ignored if `sort` is equal to `none`.\n    log:\n        \"test_bwameth_mem.log\"\n    wrapper:\n        \"master/bio/bwameth/memx\"\n\n\nrule test_bwameth_mem2:\n    input:\n        ref=\"mem2/genome.fasta\",\n        idx=multiext(\n            \"mem2/genome.fasta.bwameth\",\n            \".c2t\",\n            \".c2t.amb\",\n            \".c2t.ann\",\n            \".c2t.bwt.2bit.64\",\n            \".c2t.pac\",\n            \".c2t.0123\",\n        ),\n        fq=[\"A.fastq\"],\n    output:\n        \"A.mem2.bam\",\n    threads: 2\n    params:\n        extra=\"\",  # Optional parameters for bwameth.py, besides IO and threading\n        sort=\"none\",  # Either `none` (default), `samtools`, or `picard`\n        sort_order=\"coordinate\",  # Either `coordinate` (default) or `queryname`\n        sort_extra=\"\",  # Optional parameters for sambamba/samtools/picard. Ignored if `sort` is equal to `none`.\n    log:\n        \"test_bwameth_mem2.log\"\n    wrapper:\n        \"master/bio/bwameth/memx\"\n\n\nrule test_bwameth_mem_sort_picard:\n    input:\n        ref=\"mem/genome.fasta\",\n        idx=multiext(\n            \"mem/genome.fasta.bwameth\",\n            \".c2t\",\n            \".c2t.amb\",\n            \".c2t.ann\",\n            \".c2t.bwt\",\n            \".c2t.pac\",\n            \".c2t.sa\",\n        ),\n        fq=[\"A.fastq\"],\n    output:\n        \"A.picard_sort.bam\",\n    threads: 2\n    params:\n        extra=\"\",  # Optional parameters for bwameth.py, besides IO and threading\n        sort=\"picard\",  # Either `none` (default), `samtools`, or `picard`\n        sort_order=\"coordinate\",  # Either `coordinate` (default) or `queryname`\n        sort_extra=\"\",  # Optional parameters for sambamba/samtools/picard. Ignored if `sort` is equal to `none`.\n    log:\n        \"test_bwameth_mem_sort_picard.log\"\n    wrapper:\n        \"master/bio/bwameth/memx\"\n\n\nrule test_bwameth_mem_sort_samtools:\n    input:\n        ref=\"mem/genome.fasta\",\n        idx=multiext(\n            \"mem/genome.fasta.bwameth\",\n            \".c2t\",\n            \".c2t.amb\",\n            \".c2t.ann\",\n            \".c2t.bwt\",\n            \".c2t.pac\",\n            \".c2t.sa\",\n        ),\n        fq=[\"A.fastq\"],\n    output:\n        \"A.samtools_sort.bam\",\n    threads: 2\n    params:\n        extra=\"\",  # Optional parameters for bwameth.py, besides IO and threading\n        sort=\"samtools\",  # Either `none` (default), `samtools`, or `picard`\n        sort_order=\"coordinate\",  # Either `coordinate` (default) or `queryname`\n        sort_extra=\"\",  # Optional parameters for sambamba/samtools/picard. Ignored if `sort` is equal to `none`.\n    log:\n        \"test_bwameth_mem_sort_samtools.log\"\n    wrapper:\n        \"master/bio/bwameth/memx\"\n"
    },
    {
      "name": "test_cnv_facets_bam",
      "input": {
        "tumor": "T.sample.bam",
        "normal": "N.sample.bam",
        "vcf": "common.sample.vcf.gz"
      },
      "output": {
        "vcf": "CNV_bam.vcf.gz",
        "cnv": "genome_bam.cnv.png",
        "hist": "cnv_bam.hist.pdf",
        "spider": "qc_bam.spider.pdf"
      },
      "log": {
        "default": "logs/cnv_facets_bam.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/cnv_facets"
      },
      "input_types": [
        {
          "tumor": "Path to tumor aligned reads. (BAM, required if `pileup` is empty)"
        },
        {
          "normal": "Path to normal aligned reads. (BAM, required if `pileup` is empty)"
        },
        {
          "vcf": "Path to common, polymorphic SNPs. (pbgzip VCF)"
        },
        {
          "pileup": "Path to pileup variants. (pbgzip CSV, replaces `tumor` and `normal`)"
        }
      ],
      "output_types": [
        {
          "vcf": "Path to copy number variants. (pbgzip VCF)"
        },
        {
          "cnv": "Path to a summary plot of CNVs across the genome. (PNG)"
        },
        {
          "hist": "Path to histograms of the distribution of read depth across all the position in the tumour and normal sample, before and after filtering positions. (PDF)"
        },
        {
          "spider": "Path to a diagnostic plot to check how well the copy number fits work (PDF)"
        }
      ],
      "rule": "rule test_cnv_facets_bam:\n    input:\n        tumor=\"T.sample.bam\",\n        normal=\"N.sample.bam\",\n        vcf=\"common.sample.vcf.gz\",\n    output:\n        vcf=\"CNV_bam.vcf.gz\",\n        cnv=\"genome_bam.cnv.png\",\n        hist=\"cnv_bam.hist.pdf\",\n        spider=\"qc_bam.spider.pdf\",\n    log:\n        \"logs/cnv_facets_bam.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/cnv_facets\"\n\n\nrule test_cnv_facets_pileup:\n    input:\n        pileup=\"pileup.csv.gz\",\n        vcf=\"common.sample.vcf.gz\",\n    output:\n        vcf=\"CNV_pileup.vcf.gz\",\n        cnv=\"genome_pileup.cnv.png\",\n        hist=\"cnv_pileup.hist.pdf\",\n        spider=\"qc_pileup.spider.pdf\",\n    log:\n        \"logs/cnv_facets_bam.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/cnv_facets\"\n"
    },
    {
      "name": "test_deeptools_alignment_sieve",
      "input": {
        "aln": "a.bam"
      },
      "output": {
        "default": "filtered.bam"
      },
      "log": {
        "default": "logs/deeptools.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/deeptools/alignmentsieve"
      },
      "input_types": [
        {
          "aln": "Path to BAM/CRAM formatted alignments. Bam filesm ust be indexed."
        }
      ],
      "output_types": [
        "Path to filtered bam alignments or bedpe intervals."
      ],
      "rule": "rule test_deeptools_alignment_sieve:\n    input:\n        aln=\"a.bam\",\n    output:\n        \"filtered.bam\",\n    threads: 1\n    log:\n        \"logs/deeptools.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/deeptools/alignmentsieve\"\n"
    },
    {
      "name": "test_deeptools_bamcoverage",
      "input": {
        "bam": "a.sorted.bam",
        "bai": "a.sorted.bam.bai"
      },
      "output": {
        "default": "a.coverage.bw"
      },
      "log": {
        "default": "logs/coverage.log"
      },
      "params": {
        "effective_genome_size": 1000,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/deeptools/bamcoverage"
      },
      "input_types": [
        {
          "bam": "Path to alignment (BAM) file"
        },
        {
          "blacklist": "Path to optional blacklist region file (BED)"
        }
      ],
      "output_types": [
        "Path to coverage file"
      ],
      "rule": "rule test_deeptools_bamcoverage:\n    input:\n        bam=\"a.sorted.bam\",\n        bai=\"a.sorted.bam.bai\",\n        # Optional path to a blacklist bed file\n        # blacklist=\"\",\n    output:\n        \"a.coverage.bw\",\n    params:\n        effective_genome_size=1000,\n        extra=\"\",\n    log:\n        \"logs/coverage.log\",\n    wrapper:\n        \"master/bio/deeptools/bamcoverage\"\n\n\nrule test_deeptools_bamcoverage_default_eff_len:\n    input:\n        bam=\"a.sorted.bam\",\n        bai=\"a.sorted.bam.bai\",\n    output:\n        \"a.coverage_code.bw\",\n    params:\n        genome=\"GRCm38\",\n        read_length=200,\n    log:\n        \"logs/coverage_efault_eff_len.log\",\n    wrapper:\n        \"master/bio/deeptools/bamcoverage\"\n\n\nrule test_deeptools_bamcoverage_no_params:\n    input:\n        bam=\"a.sorted.bam\",\n        bai=\"a.sorted.bam.bai\",\n    output:\n        \"a.coverage_no_params.bw\",\n    log:\n        \"logs/coverage.log\",\n    wrapper:\n        \"master/bio/deeptools/bamcoverage\"\n"
    },
    {
      "name": "test_deeptools_multibwsummary_bins",
      "input": {
        "bw": [
          "a.bw",
          "b.bw"
        ],
        "blacklist": "blacklist.bed"
      },
      "output": {
        "npz": "bins.npz",
        "counts": "bins.counts"
      },
      "log": {
        "default": "bins.logs"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/deeptools/multibigwigsummary"
      },
      "input_types": [
        {
          "bw": "Path to a bigwig file, or a list of bigwig files."
        },
        {
          "blacklist": "Optional path to a BED file covering regions to exclude."
        },
        {
          "bed": "Path to a bed file to limit the analysis of regions. This triggers the subcommand `BED-file`. Leave empty to run the `bins` subcommand."
        }
      ],
      "output_types": [
        {
          "npz": "Path to the compressed matrix file."
        },
        {
          "counts": "Path to average scores per region for each bigwig."
        }
      ],
      "rule": "rule test_deeptools_multibwsummary_bins:\n    input:\n        bw=[\"a.bw\", \"b.bw\"],\n        blacklist=\"blacklist.bed\", # Optional\n    output:\n        npz=\"bins.npz\",\n        counts=\"bins.counts\",\n    threads: 1\n    params:\n        extra=\"\",\n    log:\n        \"bins.logs\"\n    wrapper:\n        \"master/bio/deeptools/multibigwigsummary\"\n\nrule test_deeptools_multibwsummary_bed:\n    input:\n        bw=[\"a.bw\", \"b.bw\"],\n        bed=\"intervals.bed\",\n        # blacklist=\"\", # Optional\n    output:\n        npz=\"bed.npz\",\n        counts=\"bed.counts\",\n    threads: 1\n    params:\n        extra=\"\",\n    log:\n        \"bins.logs\"\n    wrapper:\n        \"master/bio/deeptools/multibigwigsummary\"\n\n\n\n"
    },
    {
      "name": "test_deeptools_plot_correlation",
      "input": {
        "default": "bins.npz"
      },
      "output": {
        "plot": "bins.svg",
        "counts": "counts.tsv"
      },
      "log": {
        "default": "corr.log"
      },
      "params": {
        "extra": "--skipZeros",
        "correlation": "spearman",
        "plot": "heatmap"
      },
      "wrapper": {
        "default": "master/bio/deeptools/plotcorrelation"
      },
      "input_types": [
        "Path to compressed matrix file"
      ],
      "output_types": [
        {
          "plot": "Path to scatterplot/heatmap. The available formats are `.png`, `.eps`, `.pdf` and `.svg`"
        },
        {
          "matrix": "Optional path to pairwise correlation values (TSV)"
        }
      ],
      "rule": "rule test_deeptools_plot_correlation:\n    input:\n        \"bins.npz\",\n    output:\n        plot=\"bins.svg\",\n        counts=\"counts.tsv\",  # Optional output file\n    threads: 1\n    params:\n        extra=\"--skipZeros\",  # Any optional parameters besides IO and --plotFileFormat\n        correlation=\"spearman\",  # either spearman or pearson\n        plot=\"heatmap\",  # either heatmap or scatterplot\n    log:\n        \"corr.log\",\n    wrapper:\n        \"master/bio/deeptools/plotcorrelation\"\n"
    },
    {
      "name": "test_deeptools_plot_pca",
      "input": {
        "default": "bins.npz"
      },
      "output": {
        "plot": "pca.svg",
        "matrix": "pca.tab"
      },
      "log": {
        "default": "pca.log"
      },
      "params": {
        "extra": "--ntop 0"
      },
      "wrapper": {
        "default": "master/bio/deeptools/plotpca"
      },
      "input_types": [
        "Path to compressed matrix file"
      ],
      "output_types": [
        {
          "plot": "Path to PCA plot. The available options are `.png`, `.eps`, `.pdf` and `.svg`."
        },
        {
          "matrix": "Optional path to the data underlying the plot."
        }
      ],
      "rule": "rule test_deeptools_plot_pca:\n    input:\n        \"bins.npz\",\n    output:\n        plot=\"pca.svg\",\n        matrix=\"pca.tab\",  # Optional\n    threads: 1\n    params:\n        extra=\"--ntop 0\",\n    log:\n        \"pca.log\",\n    wrapper:\n        \"master/bio/deeptools/plotpca\"\n"
    },
    {
      "name": "test_deeptools_plotcoverage",
      "input": {
        "bams": [
          "a.bam"
        ],
        "bais": [
          "a.bam.bai"
        ]
      },
      "output": {
        "plot": "coverage.png",
        "raw_counts": "coverage.raw",
        "metrics": "coverage.metrics"
      },
      "log": {
        "default": "logs/deeptools/coverage.log"
      },
      "params": {
        "extra": "--coverageThresholds 1"
      },
      "wrapper": {
        "default": "master/bio/deeptools/plotcoverage"
      },
      "input_types": [
        {
          "bams": "Path to alignment (BAM)"
        },
        {
          "bed": "Path to region file (BED)"
        },
        {
          "blacklist": "Path to blacklisted regions (BED)"
        }
      ],
      "output_types": [
        {
          "raw_counts": "Raw coverage plot"
        },
        {
          "metrics": "Raw coverage metrics"
        },
        {
          "plot": "Path to image"
        }
      ],
      "rule": "rule test_deeptools_plotcoverage:\n    input:\n        # Optional blacklisted regions\n        # blacklist=\"\",\n        # Optional region file\n        # bed=\"\",\n        bams=[\"a.bam\"],\n        bais=[\"a.bam.bai\"],\n    output:\n        plot=\"coverage.png\",\n        # Optional raw counts\n        raw_counts=\"coverage.raw\",\n        # Optional metrics\n        metrics=\"coverage.metrics\",\n    params:\n        extra=\"--coverageThresholds 1\",\n    log:\n        \"logs/deeptools/coverage.log\"\n    wrapper:\n        \"master/bio/deeptools/plotcoverage\"\n"
    },
    {
      "name": "test_deseq2_wald_apeglm",
      "input": {
        "dds": "dds.RDS"
      },
      "output": {
        "wald_rds": "wald_apeglm.RDS",
        "wald_tsv": "dge_apeglm.tsv",
        "deseq2_result_dir": "directory('deseq_results_apeglm')",
        "normalized_counts_table": "counts_apeglm.tsv",
        "normalized_counts_rds": "counts_apeglm.RDS"
      },
      "log": {
        "default": "logs/deseq2_apeglm.log"
      },
      "params": {
        "deseq_extra": "",
        "shrink_extra": "type='apeglm'",
        "results_extra": "",
        "contrast": [
          "condition",
          "A",
          "B"
        ]
      },
      "wrapper": {
        "default": "master/bio/deseq2/wald"
      },
      "input_types": [
        {
          "dds": "Path to RDS-formatted DESeq2-object"
        }
      ],
      "output_types": [
        {
          "wald_rds": "Optional path to wald test results (RDS formatted)"
        },
        {
          "wald_tsv": "Optional path to wald test results (TSV formatted). Required optional parameter `contrast` (see below)"
        },
        {
          "deseq2_result_dir": "Optional path to a directory that shall contain all DESeq2 results for each comparison (each file is TSV formatted)"
        },
        {
          "normalized_counts_table": "Optional path to normalized counts (TSV formatted)"
        },
        {
          "normalized_counts_rds": "Optional path to normalized counts (RDS formatted)"
        }
      ],
      "rule": "rule test_deseq2_wald_apeglm:\n    input:\n        dds=\"dds.RDS\",\n    output:\n        wald_rds=\"wald_apeglm.RDS\",\n        wald_tsv=\"dge_apeglm.tsv\",\n        deseq2_result_dir=directory(\"deseq_results_apeglm\"),\n        normalized_counts_table=\"counts_apeglm.tsv\",\n        normalized_counts_rds=\"counts_apeglm.RDS\",\n    params:\n        deseq_extra=\"\",\n        # Optional parameters for `lfcShrink` besides dds, parallel, contrast, and coef\n        shrink_extra=\"type='apeglm'\",\n        results_extra=\"\",\n        contrast=[\"condition\", \"A\", \"B\"],\n    threads: 1\n    log:\n        \"logs/deseq2_apeglm.log\",\n    wrapper:\n        \"master/bio/deseq2/wald\"\n\n\nrule test_deseq2_wald_ashr:\n    input:\n        dds=\"dds.RDS\",\n    output:\n        wald_rds=\"wald_ashr.RDS\",\n        wald_tsv=\"dge_ashr.tsv\",\n        deseq2_result_dir=directory(\"deseq_results_ashr\"),\n        normalized_counts_table=\"counts_ashr.tsv\",\n        normalized_counts_rds=\"counts_ashr.RDS\",\n    params:\n        deseq_extra=\"\",\n        # Optional parameters for `lfcShrink` besides dds, parallel, contrast, and coef\n        shrink_extra=\"type='ashr'\",\n        results_extra=\"\",\n        contrast=[\"condition\", \"A\", \"B\"],\n    threads: 1\n    log:\n        \"logs/deseq2_ashr.log\",\n    wrapper:\n        \"master/bio/deseq2/wald\"\n\n\nrule test_deseq2_wald_normal:\n    input:\n        dds=\"dds.RDS\",\n    output:\n        wald_rds=\"wald_normal.RDS\",\n        wald_tsv=\"dge_normal.tsv\",\n        deseq2_result_dir=directory(\"deseq_results_normal\"),\n        normalized_counts_table=\"counts_normal.tsv\",\n        normalized_counts_rds=\"counts_normal.RDS\",\n    params:\n        deseq_extra=\"\",\n        # Optional parameters for `lfcShrink` besides dds, parallel, contrast, and coef\n        shrink_extra=\"type='normal'\",\n        results_extra=\"\",\n        contrast=[\"condition\", \"A\", \"B\"],\n    threads: 1\n    log:\n        \"logs/deseq2_normal.log\",\n    wrapper:\n        \"master/bio/deseq2/wald\"\n\nrule test_deseq2_wald_contrast_2_factors:\n    input:\n        dds=\"dds.RDS\",\n    output:\n        wald_rds=\"wald_2f.RDS\",\n        wald_tsv=\"dge_2f.tsv\",\n        deseq2_result_dir=directory(\"deseq_results_2f\"),\n        normalized_counts_table=\"counts_2f.tsv\",\n        normalized_counts_rds=\"counts_2f.RDS\",\n    params:\n        deseq_extra=\"\",\n        # Optional parameters for `lfcShrink` besides dds, parallel, contrast, and coef\n        shrink_extra=\"type='apeglm'\",\n        results_extra=\"\",\n        contrast=[\"A\", \"B\"],\n    threads: 1\n    log:\n        \"logs/deseq2_2f.log\",\n    wrapper:\n        \"master/bio/deseq2/wald\"\n\n\nrule test_deseq2_wald_contrast_1_string:\n    input:\n        dds=\"dds.RDS\",\n    output:\n        wald_rds=\"wald_1s.RDS\",\n        wald_tsv=\"dge_1s.tsv\",\n        deseq2_result_dir=directory(\"deseq_results_1s\"),\n        normalized_counts_table=\"counts_1s.tsv\",\n        normalized_counts_rds=\"counts_1s.RDS\",\n    params:\n        deseq_extra=\"\",\n        # Optional parameters for `lfcShrink` besides dds, parallel, contrast, and coef\n        shrink_extra=\"type='apeglm'\",\n        results_extra=\"\",\n        contrast=[\"condition_B_vs_A\"],\n    threads: 1\n    log:\n        \"logs/deseq2_1s.log\",\n    wrapper:\n        \"master/bio/deseq2/wald\"\n"
    },
    {
      "name": "test_enhanced_volcano_tsv",
      "input": {
        "default": "table.tsv"
      },
      "output": {
        "default": "volcano_tsv.png"
      },
      "log": {
        "default": "logs/enhanced-volcano/tsv.log"
      },
      "params": {
        "extra": "lab='Gene_id', x='ShrinkedFC', y='adjusted_pvalues'",
        "width": 1024,
        "height": 768
      },
      "wrapper": {
        "default": "master/bio/enhancedvolcano"
      },
      "input_types": [
        "Path to a TSV/CSV table (separator are inferred from file extension) or a RDS formatted object convertible into a `data.frame`."
      ],
      "output_types": [
        "Path to SVG or PNG formatted Volcano plot"
      ],
      "rule": "rule test_enhanced_volcano_tsv:\n    input:\n        \"table.tsv\",\n    output:\n        \"volcano_tsv.png\",\n    threads: 1\n    log:\n        \"logs/enhanced-volcano/tsv.log\",\n    params:\n        extra=\"lab='Gene_id', x='ShrinkedFC', y='adjusted_pvalues'\",\n        width=1024,  # Optional PNG width\n        height=768,  # Optional PNG height\n    wrapper:\n        \"master/bio/enhancedvolcano\"\n\n\nrule test_enhanced_volcano_csv:\n    input:\n        \"table.csv\",\n    output:\n        \"volcano_csv.svg\",\n    threads: 1\n    log:\n        \"logs/enhanced-volcano/csv.log\",\n    params:\n        extra=\"lab='Gene_id', x='ShrinkedFC', y='adjusted_pvalues'\",\n        # width=7,  # Optional PNG width\n        # height=7,  # Optional PNG height\n    wrapper:\n        \"master/bio/enhancedvolcano\"\n\n\nrule test_enhanced_volcano_rds:\n    input:\n        \"table.RDS\",\n    output:\n        \"volcano_rds.svg\",\n    threads: 1\n    log:\n        \"logs/enhanced-volcano/rds.log\",\n    params:\n        extra=\"lab='Gene_id', x='ShrinkedFC', y='adjusted_pvalues'\",\n        # width=7,  # Optional PNG width\n        # height=7,  # Optional PNG height\n    wrapper:\n        \"master/bio/enhancedvolcano\"\n"
    },
    {
      "name": "test_gatk_calculate_contamination",
      "input": {
        "tumor": "pileups.table"
      },
      "output": {
        "default": "contamination.table"
      },
      "log": {
        "default": "logs/gatk/contamination.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/calculatecontamination"
      },
      "input_types": [
        {
          "tumor": "Path to pileup table from GATK GetPileupSummaries"
        },
        {
          "normal": "Optional path to noram pileup table"
        }
      ],
      "output_types": [
        "Path to contamination table"
      ],
      "rule": "rule test_gatk_calculate_contamination:\n    input:\n        tumor=\"pileups.table\",\n        # normal=\"normal.pileups.table\",\n    output:\n        \"contamination.table\",\n    threads: 1\n    resources:\n        mem_mb=1024,\n    log:\n        \"logs/gatk/contamination.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/gatk/calculatecontamination\"\n"
    },
    {
      "name": "test_gatk_get_pileup_summaries",
      "input": {
        "bam": "mapped/a.bam",
        "intervals": "genome/intervals.bed",
        "variants": "genome/variants.vcf.gz"
      },
      "output": {
        "default": "summaries.table"
      },
      "log": {
        "default": "logs/summary.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/getpileupsummaries"
      },
      "input_types": [
        {
          "bam": "Path to bam file (sorted and indexed)"
        },
        {
          "intervals": "Path to one or more BED genomic intervals over which to operate"
        },
        {
          "variants": "Path to a VCF containing allele frequencies (pbgzipped and tabix indexed)"
        }
      ],
      "output_types": [
        "Path to output table"
      ],
      "rule": "rule test_gatk_get_pileup_summaries:\n    input:\n        bam=\"mapped/a.bam\",\n        intervals=\"genome/intervals.bed\",\n        variants=\"genome/variants.vcf.gz\",\n    output:\n        \"summaries.table\",\n    threads: 1\n    resources:\n        mem_mb=1024,\n    params:\n        extra=\"\",\n    log:\n        \"logs/summary.log\",\n    wrapper:\n        \"master/bio/gatk/getpileupsummaries\"\n"
    },
    {
      "name": "test_gatk_learnreadorientationmodel",
      "input": {
        "f1r2": "f1r2.tar.gz"
      },
      "output": {
        "default": "artifacts_prior.tar.gz"
      },
      "log": {
        "default": "learnreadorientationbias.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gatk/learnreadorientationmodel"
      },
      "input_types": [
        {
          "f1r2": "Path to one or multiple f1r2 files"
        }
      ],
      "output_types": [
        "Path to tar.gz of artifact prior tables"
      ],
      "rule": "rule test_gatk_learnreadorientationmodel:\n    input:\n        f1r2=\"f1r2.tar.gz\",\n    output:\n        \"artifacts_prior.tar.gz\",\n    resources:\n        mem_mb=1024,\n    params:\n        extra=\"\",\n    log:\n        \"learnreadorientationbias.log\",\n    wrapper:\n        \"master/bio/gatk/learnreadorientationmodel\"\n\nrule test_gatk_learnreadorientationmodel_multiple_input:\n    input:\n        f1r2=[\"f1r2.tar.gz\", \"f1r2.2.tar.gz\"],\n    output:\n        \"artifacts_prior_multi.tar.gz\",\n    resources:\n        mem_mb=1024,\n    params:\n        extra=\"\",\n    log:\n        \"learnreadorientationbias_multi.log\",\n    wrapper:\n        \"master/bio/gatk/learnreadorientationmodel\"\n\n"
    },
    {
      "name": "test_genePredToBed",
      "input": {
        "default": "annotation.genePred"
      },
      "output": {
        "default": "annotation.bed"
      },
      "log": {
        "default": "ucsc.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/ucsc/genePredToBed"
      },
      "input_types": [
        "Path to a genePred file"
      ],
      "output_types": [
        "Path to the output bed12 file"
      ],
      "rule": "rule test_genePredToBed:\n    input:\n        \"annotation.genePred\",\n    output:\n        \"annotation.bed\",\n    params:\n        extra=\"\",\n    log:\n        \"ucsc.log\",\n    wrapper:\n        \"master/bio/ucsc/genePredToBed\"\n"
    },
    {
      "name": "test_gffread_gtf",
      "input": {
        "fasta": "genome.fasta",
        "annotation": "annotation.gtf"
      },
      "output": {
        "records": "annotation.gff",
        "transcript_fasta": "transcripts.fa",
        "cds_fasta": "cds.fa"
      },
      "log": {
        "default": "logs/gffread_gtf.log"
      },
      "params": {
        "fasta_flag": "-w",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/gffread"
      },
      "input_types": [
        {
          "fasta": "FASTA genome file."
        },
        {
          "annotation": "GTF/GTF/BED genome annotation."
        },
        {
          "ids": "Records/transcript to keep (optional)."
        },
        {
          "nids": "Records/transcripts to discard (optional)."
        },
        {
          "seq_info": "Sequence information, a TSV formatted text file containing `<seq-name> <seq-length> <seq-description>` (optional)."
        },
        {
          "sort_by": "Text file containing the ordered list of reference sequences (optional)."
        },
        {
          "attr": "Text file containing comma-separated list of annotation attributes to keep (optional)."
        },
        {
          "chr_replace": "TSV-formatted text file containing `<original_ref_ID> <new_ref_ID>` (optional)."
        }
      ],
      "output_types": [
        {
          "records": "Genome annotation (optional)."
        },
        {
          "transcript_fasta": "FASTA containing `-w` output (optional)."
        },
        {
          "cds_fasta": "FASTA containing `-x` output (optional)."
        },
        {
          "protein_fasta": "FASTA containing `-y` output (optional)."
        },
        {
          "dupinfo": "Clustering/merging information (optional)."
        }
      ],
      "rule": "rule test_gffread_gtf:\n    input:\n        fasta=\"genome.fasta\",\n        annotation=\"annotation.gtf\",\n        # ids=\"\",  # Optional path to records to keep\n        # nids=\"\",  # Optional path to records to drop\n        # seq_info=\"\",  # Optional path to sequence information\n        # sort_by=\"\",  # Optional path to the ordered list of reference sequences\n        # attr=\"\",  # Optional annotation attributes to keep.\n        # chr_replace=\"\",  # Optional path to <original_ref_ID> <new_ref_ID>\n    output:\n        # All optional, select based on desired output\n        records=\"annotation.gff\",\n        transcript_fasta=\"transcripts.fa\",  # Path containing gffread -w output\n        cds_fasta=\"cds.fa\",  # Path containing gffread -x output\n        # dupinfo=\"\",  # Path to clustering/merging information\n    threads: 1\n    log:\n        \"logs/gffread_gtf.log\",\n    params:\n        fasta_flag=\"-w\",\n        extra=\"\",\n    wrapper:\n        \"master/bio/gffread\"\n\n\nrule test_gffread_gff:\n    input:\n        fasta=\"genome.fasta\",\n        annotation=\"annotation.gff3\",\n    output:\n        protein_fasta=\"proteins.fa\",  # Path containing gffread -y output\n    threads: 1\n    log:\n        \"logs/gffread_gff.log\",\n    params:\n        extra=\"-S\",\n    wrapper:\n        \"master/bio/gffread\"\n"
    },
    {
      "name": "test_goleft_indexcov",
      "input": {
        "aln": "sample.bam",
        "fai": "genome.fai"
      },
      "output": {
        "bed": "regions.bed.gz",
        "ped": "indexcov.ped",
        "roc": "indexcov.roc",
        "html": "directory('report')"
      },
      "log": {
        "default": "indexcov.log"
      },
      "params": {
        "extra": "-e"
      },
      "wrapper": {
        "default": "master/bio/goleft/indexcov"
      },
      "input_types": [
        {
          "aln": "Path to indexed BAM/CRAM file"
        },
        {
          "fai": "Path to fasta sequence index"
        }
      ],
      "output_types": [
        {
          "html": "Optional path to HTML report"
        },
        {
          "bed": "Optional path to coverage bed"
        },
        {
          "ped": "Optional path to pedigree file"
        },
        {
          "roc": "Optional path to coverage curves"
        }
      ],
      "rule": "rule test_goleft_indexcov:\n    input:\n        aln=\"sample.bam\",\n        fai=\"genome.fai\",\n    output:\n        bed=\"regions.bed.gz\",\n        ped=\"indexcov.ped\",\n        roc=\"indexcov.roc\",\n        html=directory(\"report\"),\n    log:\n        \"indexcov.log\",\n    params:\n        extra=\"-e\",\n    wrapper:\n        \"master/bio/goleft/indexcov\"\n"
    },
    {
      "name": "test_gseapy_enrichr",
      "input": {
        "gene_list": "genes_list.txt"
      },
      "output": {
        "enrichr_dir": "directory('KEGG_2016')"
      },
      "log": {
        "wrapper": "logs/gseapy/wrapper.enrichr.log",
        "gseapy": "logs/gseapy/enrichr.log"
      },
      "params": {
        "extra": {
          "cutoff": 1
        },
        "gene_sets": [
          "KEGG_2016"
        ]
      },
      "wrapper": {
        "default": "master/bio/gseapy/gsea"
      },
      "input_types": [
        {
          "gmt": "Optional path to gene sets (GMT formatted). If no GMT file is provided, then a `gene_sets` value must be given in `params`."
        },
        {
          "expr": "Path to expression table, required for `gsea` and `ssgsea`. (RNK formatted)"
        },
        {
          "cls": "Path to categorical class file, required for `gsea`. (CLS formatted)"
        },
        {
          "rank": "Path to pre-ranked genes, required for `prerank`. (TSV/CSV formatted)"
        },
        {
          "gene_list": "Path to gene list file, required for `enrichr`. (TXT/TSV/CSV formatted)"
        },
        {
          "background": "Optional path to a background file for `enrichr`. (TXT/TSV/CSV formatted)"
        }
      ],
      "output_types": [
        {
          "outdir": "Path to output directory"
        },
        {
          "pkl": "Path to serialized results (Pickle)"
        }
      ],
      "rule": "rule test_gseapy_enrichr:\n    input:\n        gene_list=\"genes_list.txt\",\n        # gmt=\"\", Optional path to a GMT file\n    output:\n        enrichr_dir=directory(\"KEGG_2016\"),\n    threads: 1\n    params:\n        extra={\"cutoff\": 1},\n        gene_sets=[\"KEGG_2016\"],  # Optional list of gene sets available on biomart\n    log:\n        wrapper=\"logs/gseapy/wrapper.enrichr.log\",\n        gseapy=\"logs/gseapy/enrichr.log\",\n    wrapper:\n        \"master/bio/gseapy/gsea\"\n\n\nrule test_gseapy_gsea:\n    input:\n        expr=\"genes_expr.tsv\",\n        cls=\"sample_class.cls\",\n        gmt=\"geneset.gmt\",\n    output:\n        gmt=\"gene_sets.gmt\",\n        csv=\"gsea.results.csv\",\n    threads: 1\n    params:\n        extra={\n            \"min_size\": 1,\n        },\n        # gene_sets = [\"\"] # Optional list of gene sets available on biomart\n    log:\n        wrapper=\"logs/gseapy/wrapper.gsea.log\",\n        gseapy=\"logs/gseapy/gsea.log\",\n    wrapper:\n        \"master/bio/gseapy/gsea\"\n\n\nrule test_gseapy_ssgsea:\n    input:\n        expr=\"genes_expr.tsv\",\n        gmt=\"geneset.gmt\",\n    output:\n        gmt=\"gene_sets.gmt\",\n        csv=\"ssgsea.results.csv\",\n    threads: 1\n    params:\n        extra={\n            \"min_size\": 1,\n        },\n        # gene_sets = [\"\"] # Optional list of gene sets available on biomart\n    log:\n        wrapper=\"logs/gseapy/wrapper.ssgsea.log\",\n        gseapy=\"logs/gseapy/ssgsea.log\",\n    wrapper:\n        \"master/bio/gseapy/gsea\"\n\n\nrule test_gseapy_prerank:\n    input:\n        rank=\"genes.rnk\",\n        gmt=\"geneset.gmt\",\n    output:\n        gmt=\"gene_sets.gmt\",\n        csv=\"prerank.results.csv\",\n        prerank=directory(\"prerank_results_dir\"),\n    threads: 1\n    params:\n        extra={\n            \"min_size\": 1,\n        },\n        # gene_sets = [\"\"] # Optional list of gene sets available on biomart\n    log:\n        wrapper=\"logs/gseapy/wrapper.prerank.log\",\n        gseapy=\"logs/gseapy/prerank.log\",\n    wrapper:\n        \"master/bio/gseapy/gsea\"\n"
    },
    {
      "name": "test_immunedeconv",
      "input": {
        "expr": "dataset.RDS"
      },
      "output": {
        "default": "deconv.csv"
      },
      "log": {
        "default": "logs/immunedeconv/csv.log"
      },
      "params": {
        "method": "deconvolute",
        "extra": "method='epic'"
      },
      "wrapper": {
        "default": "master/bio/immunedeconv"
      },
      "input_types": [
        {
          "expr": "Path to gene expression matrix (RDS, CSV, or TSV formatted)."
        },
        {
          "signature": "Optional path to custom cell-type signatures."
        },
        {
          "cibersort_bin": "Path to CIBERSORT binary, required for CIBERSORT deconvolution."
        },
        {
          "cibersort_mat": "Path to CIBERSORT signatures matrix, required for CIBERSORT deconvolution."
        }
      ],
      "output_types": [
        "Path to deconvolution result (RDS, CSV, or TSV formatted)."
      ],
      "rule": "rule test_immunedeconv:\n    input:\n        expr=\"dataset.RDS\",\n        # signature=\"\",  # Path to custom signatures.\n        # cibersort_bin=\"\",  # Path to CIBERSORT binary.\n        # cibersort_mat=\"\",  # Path to CIBERSORT matrix.\n    output:\n        \"deconv.csv\", # Available formats are: RDS, csv or tsv\n    threads: 1\n    params:\n        method=\"deconvolute\",\n        extra=\"method='epic'\",\n    log:\n        \"logs/immunedeconv/csv.log\",\n    wrapper:\n        \"master/bio/immunedeconv\"\n"
    },
    {
      "name": "test_mashmap",
      "input": {
        "ref": "reference.fasta.gz",
        "query": "read.fasta.gz"
      },
      "output": {
        "default": "mashmap.out"
      },
      "log": {
        "default": "logs/mashmap.log"
      },
      "params": {
        "extra": "-s 1000 --pi 99"
      },
      "wrapper": {
        "default": "master/bio/mashmap"
      },
      "input_types": [
        {
          "ref": "Path to reference file"
        },
        {
          "query": "Path to query file (fasta, fastq)"
        }
      ],
      "output_types": [
        "Path to the alignment file"
      ],
      "rule": "rule test_mashmap:\n    input:\n        ref=\"reference.fasta.gz\",  # This can be a txt file with a path to a fasta-file per line\n        query=\"read.fasta.gz\",\n    output:\n        \"mashmap.out\",\n    threads: 2\n    params:\n        extra=\"-s 1000 --pi 99\",\n    log:\n        \"logs/mashmap.log\",\n    wrapper:\n        \"master/bio/mashmap\"\n"
    },
    {
      "name": "test_methyldackel_extract_fraction",
      "input": {
        "ref": "chgchh.fa",
        "aln": "chgchh_aln.bam",
        "aln_bai": "chgchh_aln.bam.bai",
        "bw": "chgchh.bw"
      },
      "output": {
        "cpg": "cpg.meth.bg",
        "chh": "chh.meth.bg",
        "chg": "chg.meth.bg"
      },
      "log": {
        "default": "logs/md_extract/meth.log"
      },
      "params": {
        "extra": "--fraction"
      },
      "wrapper": {
        "default": "master/bio/methyldackel/extract"
      },
      "input_types": [
        {
          "ref": "Path to reference genome (Fasta)"
        },
        {
          "aln": "Path to aligned reads (BAM)"
        }
      ],
      "output_types": [
        {
          "cpg": "Path to CpG metrics (BedGraph)"
        },
        {
          "chg": "Optional path to CHG metrics (BedGraph)"
        },
        {
          "chh": "Optional path to CHH metrics (BedGraph)"
        }
      ],
      "rule": "rule test_methyldackel_extract_fraction:\n    input:\n        ref=\"chgchh.fa\",\n        aln=\"chgchh_aln.bam\",\n        aln_bai=\"chgchh_aln.bam.bai\",\n        bw=\"chgchh.bw\",\n    output:\n        cpg=\"cpg.meth.bg\",\n        chh=\"chh.meth.bg\",\n        chg=\"chg.meth.bg\",\n    log:\n        \"logs/md_extract/meth.log\",\n    params:\n        extra=\"--fraction\",\n    wrapper:\n        \"master/bio/methyldackel/extract\"\n\n\nrule test_methyldackel_extract_count:\n    input:\n        ref=\"chgchh.fa\",\n        aln=\"chgchh_aln.bam\",\n        aln_bai=\"chgchh_aln.bam.bai\",\n        bw=\"chgchh.bw\",\n    output:\n        cpg=\"cpg.count.bg\",\n        chh=\"chh.count.bg\",\n        chg=\"chg.count.bg\",\n    log:\n        \"logs/md_extract/count.log\",\n    params:\n        extra=\"--counts\",\n    wrapper:\n        \"master/bio/methyldackel/extract\"\n\n\nrule test_methyldackel_extract_logit:\n    input:\n        ref=\"chgchh.fa\",\n        aln=\"chgchh_aln.bam\",\n        aln_bai=\"chgchh_aln.bam.bai\",\n        bw=\"chgchh.bw\",\n    output:\n        cpg=\"cpg.logit.bg\",\n        chh=\"chh.logit.bg\",\n        chg=\"chg.logit.bg\",\n    log:\n        \"logs/md_extract/logit.log\",\n    params:\n        extra=\"--logit\",\n    wrapper:\n        \"master/bio/methyldackel/extract\"\n\n\nrule test_methyldackel_extract_report:\n    input:\n        ref=\"chgchh.fa\",\n        aln=\"chgchh_aln.bam\",\n        aln_bai=\"chgchh_aln.bam.bai\",\n        bw=\"chgchh.bw\",\n    output:\n        cytosine_report=\"report.tsv\",\n    log:\n        \"logs/md_extract/report.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/methyldackel/extract\"\n"
    },
    {
      "name": "test_msisensor_msi",
      "input": {
        "normal": "example.normal.bam",
        "tumor": "example.tumor.bam",
        "microsat": "example.microsate.sites"
      },
      "output": {
        "default": "example.msi"
      },
      "log": {
        "default": "example.log"
      },
      "params": {
        "out_prefix": "example.msi"
      },
      "wrapper": {
        "default": "master/bio/msisensor/msi"
      },
      "input_types": [
        "A microsatellite and homopolymer list from MSIsensor Scan",
        "A pair of normal/tumoral bams"
      ],
      "output_types": [
        "A text file containing MSI scores",
        "A TSV formatted file containing read count distribution",
        "A TSV formatted file containing somatic sites",
        "A TSV formatted file containing germline sites"
      ],
      "rule": "rule test_msisensor_msi:\n    input:\n        normal = \"example.normal.bam\",\n        tumor = \"example.tumor.bam\",\n        microsat = \"example.microsate.sites\"\n    output:\n        \"example.msi\",\n        \"example.msi_dis\",\n        \"example.msi_germline\",\n        \"example.msi_somatic\"\n    message:\n        \"Testing MSIsensor msi\"\n    threads:\n        1\n    log:\n        \"example.log\"\n    params:\n        out_prefix = \"example.msi\"\n    wrapper:\n        \"master/bio/msisensor/msi\"\n"
    },
    {
      "name": "test_msisensor_scan",
      "input": {
        "default": "genome.fasta"
      },
      "output": {
        "default": "microsat.list"
      },
      "log": {
        "default": "logs/msisensor_scan.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/msisensor/scan"
      },
      "input_types": [
        "A (multi)fasta formatted file"
      ],
      "output_types": [
        "A text file containing homopolymers and microsatelites"
      ],
      "rule": "rule test_msisensor_scan:\n    input:\n        \"genome.fasta\"\n    output:\n        \"microsat.list\"\n    message:\n        \"Testing MSISensor scan\"\n    threads:\n        1\n    params:\n        extra = \"\"\n    log:\n        \"logs/msisensor_scan.log\"\n    wrapper:\n        \"master/bio/msisensor/scan\"\n"
    },
    {
      "name": "test_mtnucratio",
      "input": {
        "default": "a.bam"
      },
      "output": {
        "txt": "ratio.txt",
        "json": "ratio.json"
      },
      "log": {
        "default": "mtnucratio.log"
      },
      "params": {
        "chrom": "ref2"
      },
      "wrapper": {
        "default": "master/bio/mtnucratio"
      },
      "input_types": [
        "Path to a bam file"
      ],
      "output_types": [
        {
          "json": "Optional path to json-formatted results"
        },
        {
          "txt": "Optional path to text-formatted results"
        }
      ],
      "rule": "rule test_mtnucratio:\n    input:\n        \"a.bam\",\n    output:\n        txt=\"ratio.txt\",\n        json=\"ratio.json\",\n    threads: 1\n    log:\n        \"mtnucratio.log\",\n    params:\n        chrom=\"ref2\",\n    wrapper:\n        \"master/bio/mtnucratio\"\n"
    },
    {
      "name": "test_multiqc_dir",
      "input": {
        "default": "expand('samtools_stats/{sample}.txt', sample=['a', 'b'])"
      },
      "output": {
        "default": "qc/multiqc.html"
      },
      "log": {
        "default": "logs/multiqc.log"
      },
      "params": {
        "extra": "--verbose"
      },
      "wrapper": {
        "default": "master/bio/multiqc"
      },
      "input_types": [
        "input directory containing qc files, default behaviour is to extract folder path from the provided files or parent folder if a folder is provided."
      ],
      "output_types": [
        "qc report (html)",
        "multiqc data folder or zip (optional)"
      ],
      "rule": "rule test_multiqc_dir:\n    input:\n        expand(\"samtools_stats/{sample}.txt\", sample=[\"a\", \"b\"]),\n    output:\n        \"qc/multiqc.html\",\n        directory(\"qc_data/multiqc_data\"),\n    params:\n        extra=\"--verbose\",  # Optional: extra parameters for multiqc.\n    log:\n        \"logs/multiqc.log\",\n    wrapper:\n        \"master/bio/multiqc\"\n\n\nrule test_multiqc_file:\n    input:\n        expand(\"samtools_stats/{sample}.txt\", sample=[\"a\"]),\n    output:\n        \"qc/multiqc.a.html\",\n        \"qc_data/multiqc.a_data.zip\",\n    params:\n        extra=\"--verbose\",  # Optional: extra parameters for multiqc.\n        use_input_files_only=True,  # Optional, use only a.txt and don't search folder samtools_stats for files\n    log:\n        \"logs/multiqc.log\",\n    wrapper:\n        \"master/bio/multiqc\"\n\n\nrule test_multiqc_config:\n    input:\n        expand(\"samtools_stats/{sample}.txt\", sample=[\"a\", \"b\"]),\n        config=\"config/multiqc_config.yaml\",\n    output:\n        \"qc/multiqc.config.html\",\n        \"qc_data/multiqc.config_data.zip\",\n    params:\n        extra=\"--verbose\",\n    log:\n        \"logs/multiqc.log\",\n    wrapper:\n        \"master/bio/multiqc\"\n"
    },
    {
      "name": "test_ngsbits_sampleancestry",
      "input": {
        "default": "sample.vcf"
      },
      "output": {
        "default": "ancestry.tsv"
      },
      "log": {
        "default": "ancestry.log"
      },
      "params": {
        "extra": "-min_snps 4 -build hg19"
      },
      "wrapper": {
        "default": "master/bio/ngsbits/sampleancestry"
      },
      "input_types": [
        "Path to one or multiple VCF file(s)."
      ],
      "output_types": [
        "Path to results table (TSV)"
      ],
      "rule": "rule test_ngsbits_sampleancestry:\n    input:\n        # Either a single VCF or a list of VCF files\n        \"sample.vcf\",\n    output:\n        \"ancestry.tsv\",\n    threads: 1\n    log:\n        \"ancestry.log\",\n    params:\n        extra=\"-min_snps 4 -build hg19\",\n    wrapper:\n        \"master/bio/ngsbits/sampleancestry\"\n"
    },
    {
      "name": "test_ngsbits_samplesimilarity",
      "input": {
        "samples": "expand('{sample}.vcf', sample=('a', 'b'))"
      },
      "output": {
        "default": "similarity.tsv"
      },
      "log": {
        "default": "samplesimilarity.log"
      },
      "params": {
        "extra": "-build hg19"
      },
      "wrapper": {
        "default": "master/bio/ngsbits/samplesimilarity"
      },
      "input_types": [
        {
          "samples": "list of paths to vcf/vcf.gz files, or list of paths to bam/sam/cram files"
        },
        {
          "ref": "Optional path to reference genome index file (FAI). Required for CRAM input."
        },
        {
          "regions": "Optional path to regions of interest (BED)."
        }
      ],
      "output_types": [
        "Path to output TSV results"
      ],
      "rule": "rule test_ngsbits_samplesimilarity:\n    input:\n        # ref=\"\", # Optional path to fasta.fai file\n        # regions=\"\", # Optional path to regions of interest (bed)\n        samples=expand(\"{sample}.vcf\", sample=(\"a\", \"b\")),\n    output:\n        \"similarity.tsv\",\n    threads: 1\n    log:\n        \"samplesimilarity.log\",\n    params:\n        extra=\"-build hg19\",\n    wrapper:\n        \"master/bio/ngsbits/samplesimilarity\"\n"
    },
    {
      "name": "test_ngscheckmate_fastq_pair_ended",
      "input": {
        "samples": "expand('{i}.small.fastq.gz', i=('a', 'b', 'b', 'a'))",
        "fasta": "small_genome.fasta",
        "pattern": "small_pt.pt"
      },
      "output": {
        "pdf": "fastq_paired.pdf",
        "match": "fastq_paired_matched.txt",
        "txt": "fastq_paired_all.txt"
      },
      "log": {
        "default": "test_ngscheckmate_fastq_paired.log"
      },
      "params": {
        "extra": "--depth 5",
        "paired": true
      },
      "wrapper": {
        "default": "master/bio/ngscheckmate/ncm"
      },
      "input_types": {
        "samples": "Either a path to a list-file, or list of paths to alignment (BAM/SAM) files, or list of paths to variants files (VCF/BCF), or list of paths to FastQ files.",
        "bed": "Path to a interval (BED) file, required for VCF/BAM input.",
        "pt": "Path to a pattern file, required for Fastq input"
      },
      "output_types": {
        "pdf": "Path to plot file (PDF formatted)",
        "matched": "Path to matched samples table",
        "txt": "Path to samples description",
        "matrix": "Path to samples matrix (metrics)"
      },
      "rule": "rule test_ngscheckmate_fastq_pair_ended:\n    input:\n        samples=expand(\"{i}.small.fastq.gz\", i=(\"a\", \"b\", \"b\", \"a\")),\n        fasta=\"small_genome.fasta\",\n        pattern=\"small_pt.pt\",\n    output:\n        pdf=\"fastq_paired.pdf\",\n        match=\"fastq_paired_matched.txt\",\n        txt=\"fastq_paired_all.txt\",\n    threads: 1\n    params:\n        # Optional parameters besides IO and threading\n        extra=\"--depth 5\",\n        # Either `True` for pair-ended fastq files,\n        #    or  `False` for single-ended fastq files\n        # Used only for FastQ input files.\n        paired=True,\n    log:\n        \"test_ngscheckmate_fastq_paired.log\",\n    wrapper:\n        \"master/bio/ngscheckmate/ncm\"\n\n\nrule test_ngscheckmate_fastq_single_ended:\n    input:\n        samples=expand(\"{i}.small.fastq.gz\", i=(\"a\", \"b\")),\n        fasta=\"small_genome.fasta\",\n        pattern=\"small_pt.pt\",\n    output:\n        pdf=\"fastq.pdf\",\n        match=\"fastq_matched.txt\",\n        txt=\"fastq_all.txt\",\n    threads: 1\n    params:\n        # Optional parameters besides IO and threading\n        extra=\"--depth 5\",\n        # Either `True` for pair-ended fastq files,\n        #    or  `False` for single-ended fastq files\n        # Used only for FastQ input files.\n        paired=False,\n    log:\n        \"test_ngscheckmate_fastq.log\",\n    wrapper:\n        \"master/bio/ngscheckmate/ncm\"\n\n\nrule test_ngscheckmate_bam:\n    input:\n        samples=expand(\"{i}.small.bam\", i=(\"a\", \"b\")),\n        bed=\"small.bed\",\n        fasta=\"small_genome.fasta\",\n    output:\n        pdf=\"bam.pdf\",\n        matrix=\"bam_matrix.txt\",\n        match=\"bam_matched.txt\",\n        txt=\"small_all.txt\",\n    threads: 1\n    log:\n        \"test_ngscheckmate_bam.log\",\n    params:\n        # Optional parameters besides IO and threading\n        extra=\"--nonzero\",\n    wrapper:\n        \"master/bio/ngscheckmate/ncm\"\n\n\nrule test_ngscheckmate_vcf:\n    input:\n        samples=expand(\"{i}.small.vcf\", i=(\"a\", \"b\")),\n        bed=\"small.bed\",\n        fasta=\"small_genome.fasta\",\n    output:\n        pdf=\"vcf.pdf\",\n        matrix=\"vcf_matrix.txt\",\n        match=\"vcf_matched.txt\",\n        txt=\"vcf_all.txt\",\n    threads: 1\n    log:\n        \"test_ngscheckmate_vcf.log\",\n    params:\n        # Optional parameters besides IO and threading\n        extra=\"--nonzero\",\n    wrapper:\n        \"master/bio/ngscheckmate/ncm\"\n"
    },
    {
      "name": "test_ngscheckmate_makesnvpattern",
      "input": {
        "fasta": "genome.fasta",
        "bed": "variants.bed",
        "index": "multiext('genome_bwt', '.1.ebwt', '.2.ebwt', '.3.ebwt', '.4.ebwt', '.rev.1.ebwt', '.rev.2.ebwt')"
      },
      "output": {
        "pattern": "genome.pt",
        "fasta": "temp('genome.pt.fasta')",
        "pattern_uncompressed": "temp('genome.pt.txt.sorted')"
      },
      "log": {
        "default": "makesnvpattern.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/ngscheckmate/makesnvpattern"
      },
      "input_types": [
        {
          "bed": "Path to bed intervals"
        },
        {
          "fasta": "Path to fasta genome sequence"
        },
        {
          "index": "List of paths to `bowtie` index files"
        }
      ],
      "output_types": [
        {
          "fasta": "Path to fasta-formatted regions extracted from bed intervals. Unique numeric names are given to each region."
        },
        {
          "pattern_uncompressed": "Path to uncompressed patterns, used for internal patterns checks only. Col1 = Sequence, Col2 = reference max count, Col3 = variant max count."
        },
        {
          "pattern": "Path to compressed (binary) pattern file. Main output file."
        }
      ],
      "rule": "rule test_ngscheckmate_makesnvpattern:\n    input:\n        fasta=\"genome.fasta\",\n        bed=\"variants.bed\",\n        index=multiext(\n            \"genome_bwt\",\n            \".1.ebwt\",\n            \".2.ebwt\",\n            \".3.ebwt\",\n            \".4.ebwt\",\n            \".rev.1.ebwt\",\n            \".rev.2.ebwt\",\n        ),\n    output:\n        pattern=\"genome.pt\",\n        fasta=temp(\"genome.pt.fasta\"),\n        pattern_uncompressed=temp(\"genome.pt.txt.sorted\"),\n    threads: 4\n    log:\n        \"makesnvpattern.log\",\n    wrapper:\n        \"master/bio/ngscheckmate/makesnvpattern\"\n"
    },
    {
      "name": "test_ngsderive_endedness",
      "input": {
        "ngs": "A.rg.bam"
      },
      "output": {
        "tsv": "A.endedness.tsv"
      },
      "log": {
        "default": "ngsderive/endedness.log"
      },
      "params": {
        "command": "endedness",
        "extra": "--n-reads 2"
      },
      "wrapper": {
        "default": "master/bio/ngsderive"
      },
      "input_types": [
        {
          "ngs": "Path to BAM/SAM/Fastq file. SAM/BAM files should be indexed."
        },
        {
          "gene_model": "Path to sorted GTF/GFF file. Should be tabix indexed."
        }
      ],
      "output_types": [
        {
          "tsv": "Path to output file"
        },
        {
          "junctions": "Optional path to junction directory, or list of paths to junction files with a common prefix"
        }
      ],
      "rule": "rule test_ngsderive_endedness:\n    input:\n        ngs=\"A.rg.bam\",\n    output:\n        tsv=\"A.endedness.tsv\",\n    log:\n        \"ngsderive/endedness.log\",\n    params:\n        command=\"endedness\",\n        extra=\"--n-reads 2\",\n    wrapper:\n        \"master/bio/ngsderive\"\n\n\nrule test_ngsderive_junction_annotation:\n    input:\n        ngs=\"A.rg.bam\",\n        gene_model=\"annotation.sorted.gtf.gz\",\n    output:\n        tsv=\"A.junctions.tsv\",\n        junction_dir=directory(\"junctions\"),\n    log:\n        \"ngsderive/junctions.log\",\n    params:\n        command=\"junction-annotation\",\n        extra=\"--min-intron 2 --consider-unannotated-references-novel\",\n    wrapper:\n        \"master/bio/ngsderive\"\n\n\nrule test_ngsderive_junction_annotation_list:\n    input:\n        ngs=\"A.rg.bam\",\n        gene_model=\"annotation.sorted.gtf.gz\",\n    output:\n        tsv=\"A.junctions_list.tsv\",\n        junction_dir=[\"junctions/A.rg.bam.junctions.tsv\"],\n    log:\n        \"ngsderive/junctions.log\",\n    params:\n        command=\"junction-annotation\",\n        extra=\"--min-intron 2 --consider-unannotated-references-novel\",\n    wrapper:\n        \"master/bio/ngsderive\"        \n\n\nrule test_ngsderive_strandeness:\n    input:\n        ngs=\"A.rg.bam\",\n        gene_model=\"annotation.sorted.gtf.gz\",\n    output:\n        tsv=\"A.strandedness.tsv\",\n    log:\n        \"ngsderive/strand.log\",\n    params:\n        command=\"strandedness\",\n        extra=\"--verbose --minimum-reads-per-gene 2 --n-genes 1\",\n    wrapper:\n        \"master/bio/ngsderive\"\n\n\nrule test_ngsderive_encoding:\n    input:\n        ngs=\"A.rg.bam\",\n    output:\n        tsv=\"A.encoding.tsv\",\n    log:\n        \"ngsderive/encoding.log\",\n    params:\n        command=\"encoding\",\n        extra=\"--n-reads 2\",\n    wrapper:\n        \"master/bio/ngsderive\"\n\n\nrule test_ngsderive_instrument:\n    input:\n        ngs=\"A.rg.bam\",\n    output:\n        tsv=\"A.instrument.tsv\",\n    log:\n        \"ngsderive/instrument.log\",\n    params:\n        command=\"instrument\",\n        extra=\"--n-reads 2 --verbose\",\n    wrapper:\n        \"master/bio/ngsderive\"\n\n\nrule test_ngsderive_readlen:\n    input:\n        ngs=\"A.rg.bam\",\n    output:\n        tsv=\"A.readlen.tsv\",\n    log:\n        \"ngsderive/readlen.log\",\n    params:\n        command=\"readlen\",\n        extra=\"--majority-vote-cutoff 10 --n-reads 2\",\n    wrapper:\n        \"master/bio/ngsderive\"\n"
    },
    {
      "name": "test_nonpareil_plot",
      "input": {
        "npo": "{sample}.npo"
      },
      "output": {
        "pdf": "results/{sample}.pdf",
        "tsv": "results/{sample}.tsv",
        "json": "results/{sample}.json"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": "lambda w: f'--labels {w.sample} --col blue'"
      },
      "wrapper": {
        "default": "master/bio/nonpareil/plot"
      },
      "input_types": [
        "NPO file(s)"
      ],
      "output_types": [
        "PDF file with plot (optional)",
        "TSV file with summary stats (optional)",
        "JSON file with detailed info (optional)"
      ],
      "rule": "rule test_nonpareil_plot:\n    input:\n        npo=\"{sample}.npo\",\n    output:\n        pdf=\"results/{sample}.pdf\",\n        tsv=\"results/{sample}.tsv\",\n        json=\"results/{sample}.json\",\n    threads: 1\n    log:\n        \"logs/{sample}.log\",\n    params:\n        extra=lambda w: f\"--labels {w.sample} --col blue\",\n    wrapper:\n        \"master/bio/nonpareil/plot\"\n\n\nuse rule test_nonpareil_plot as test_nonpareil_plot_multiple with:\n    input:\n        npo=[\"a.npo\", \"b.npo\", \"c.npo\"],\n    output:\n        pdf=\"results/samples.pdf\",\n        tsv=\"results/samples.tsv\",\n        json=\"results/samples.json\",\n    log:\n        \"logs/samples.log\",\n    params:\n        extra=\"--labels 'Model A,Model B,Model C' --col blue,red,green\",\n\n\nuse rule test_nonpareil_plot as test_nonpareil_plot_nomodel with:\n    output:\n        pdf=\"results/{sample}.nomodel.pdf\",\n        tsv=\"results/{sample}.nomodel.tsv\",\n        json=\"results/{sample}.nomodel.json\",\n    log:\n        \"logs/{sample}.nomodel.log\",\n    params:\n        extra=lambda w: f\"--labels {w.sample} --col blue --no-model\",\n"
    },
    {
      "name": "test_pcaexplorer_pcaplot",
      "input": {
        "default": "dst.RDS"
      },
      "output": {
        "default": "pca.svg"
      },
      "log": {
        "default": "logs/pca.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pcaexplorer/pcaplot"
      },
      "input_types": [
        "Path to DESeqTransform object, such as rlog or vst transformed data"
      ],
      "output_types": [
        "Path to PCA plot (SVG formatted)"
      ],
      "rule": "rule test_pcaexplorer_pcaplot:\n    input:\n        \"dst.RDS\",\n    output:\n        \"pca.svg\",\n    params:\n        extra=\"\",\n        #width=480,\n        #height=480,\n    log:\n        \"logs/pca.log\",\n    wrapper:\n        \"master/bio/pcaexplorer/pcaplot\"\n"
    },
    {
      "name": "test_pyfaidx_out_fasta",
      "input": {
        "fasta": "sequence.fasta",
        "bed": "interval.bed"
      },
      "output": {
        "default": "retrieved.fasta"
      },
      "log": {
        "default": "test_pyfaidx.log"
      },
      "params": {
        "extra": "",
        "regions": ""
      },
      "wrapper": {
        "default": "master/bio/pyfaidx"
      },
      "input_types": [
        {
          "fasta": "Path to a sequence fasta file"
        },
        {
          "bed": "Path to BED intervals (optional)"
        }
      ],
      "output_types": [
        "Path to the modified sequences/intervals"
      ],
      "rule": "rule test_pyfaidx_out_fasta:\n    input:\n        fasta=\"sequence.fasta\",\n        bed=\"interval.bed\",\n    output:\n        \"retrieved.fasta\",\n    log:\n        \"test_pyfaidx.log\",\n    params:\n        extra=\"\",\n        regions=\"\",\n    wrapper:\n        \"master/bio/pyfaidx\"\n\n\nrule test_pyfaidx_index_fasta:\n    input:\n        fasta=\"sequence.fasta\",\n        bed=\"interval.bed\",\n    output:\n        \"sequence.fasta.fai\",\n    log:\n        \"test_pyfaidx_index_fasta.log\",\n    params:\n        extra=\"\",\n        regions=\"\",\n    wrapper:\n        \"master/bio/pyfaidx\"\n\n\nrule test_pyfaidx_out_sizes:\n    input:\n        fasta=\"sequence.fasta\",\n        bed=\"interval.bed\",\n    output:\n        \"retrieved.chrom\",\n    params:\n        extra=\"\",\n        regions=\"\",\n    log:\n        \"test_pyfaidx_out_sizes.log\",\n    wrapper:\n        \"master/bio/pyfaidx\"\n\n\nrule test_pyfaidx_out_bed:\n    input:\n        fasta=\"sequence.fasta\",\n        bed=\"interval.bed\",\n    output:\n        \"retrieved.bed\",\n    params:\n        extra=\"\",\n        regions=\"\",\n    log:\n        \"test_pyfaidx_out_bed.log\",\n    wrapper:\n        \"master/bio/pyfaidx\"\n\n\nrule test_pyfaidx_fetch_regions:\n    input:\n        #bed=\"interval.bed\",\n        fasta=\"sequence.fasta\",\n    output:\n        \"regions.fa\",\n    params:\n        extra=\"\",\n        regions=\"seq1\",\n    log:\n        \"test_pyfaidx_fetch_regions.log\",\n    wrapper:\n        \"master/bio/pyfaidx\"\n\n\nrule test_pyfaidx_fetch_list_regions:\n    input:\n        #bed=\"interval.bed\",\n        fasta=\"sequence.fasta\",\n    output:\n        \"list_regions.fa\",\n    params:\n        extra=\"\",\n        regions=[\"seq1\", \"seq2\"],\n    log:\n        \"test_pyfaidx_fetch_list_regions.log\",\n    wrapper:\n        \"master/bio/pyfaidx\"\n"
    },
    {
      "name": "test_pyroe_idtoname",
      "input": {
        "default": "annotation.{format}"
      },
      "output": {
        "default": "id2name.{format}.tsv"
      },
      "log": {
        "default": "logs/{format}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pyroe/idtoname"
      },
      "input_types": [
        "Path to genome annotation (GTF or GFF3)"
      ],
      "output_types": [
        "Path to gene id <-> gene names mapping"
      ],
      "rule": "rule test_pyroe_idtoname:\n    input:\n        \"annotation.{format}\",\n    output:\n        \"id2name.{format}.tsv\",\n    threads: 1\n    log:\n        \"logs/{format}.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/pyroe/idtoname\"\n"
    },
    {
      "name": "test_pyroe_makesplicedintronic",
      "input": {
        "fasta": "genome.fasta",
        "gtf": "annotation.gtf",
        "spliced": "extra_spliced.fasta",
        "unspliced": "extra_unspliced.fasta"
      },
      "output": {
        "fasta": "splici_full/spliced_intronic_sequences.fasta",
        "gene_id_to_name": "splici_full/gene_id_to_name.tsv",
        "t2g": "splici_full/t2g.tsv"
      },
      "log": {
        "default": "logs/pyroe.log"
      },
      "params": {
        "read_length": 91,
        "flank_trim_length": 5,
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pyroe/makesplicedintronic"
      },
      "input_types": [
        {
          "gtf": "Path to the genome annotation (GTF formatted)"
        },
        {
          "fasta": "Path to the genome sequence (Fasta formatted)"
        },
        {
          "spliced": "Optional path to additional spliced sequences (Fasta formatted)"
        },
        {
          "unspliced": "Optional path to unspliced sequences (Fasta formatted)"
        }
      ],
      "output_types": [
        {
          "fasta": "Path to spliced+intronic sequences (Fasta formatted)"
        },
        {
          "gene_id_to_name": "Path to a TSV formatted text file containing gene_id <-> gene_name correspondence"
        },
        {
          "t2g": "Path to a TSV formatted text file containing the transcript_id <-> gene_name <-> splicing status correspondence"
        }
      ],
      "rule": "rule test_pyroe_makesplicedintronic:\n    input:\n        fasta=\"genome.fasta\",\n        gtf=\"annotation.gtf\",\n        spliced=\"extra_spliced.fasta\",  # Optional path to additional spliced sequences (FASTA)\n        unspliced=\"extra_unspliced.fasta\",  # Optional path to additional unspliced sequences (FASTA)\n    output:\n        fasta=\"splici_full/spliced_intronic_sequences.fasta\",\n        gene_id_to_name=\"splici_full/gene_id_to_name.tsv\",\n        t2g=\"splici_full/t2g.tsv\",\n    threads: 1\n    log:\n        \"logs/pyroe.log\",\n    params:\n        read_length=91,  # Required\n        flank_trim_length=5,  # Optional l\n        extra=\"\",  # Optional parameters\n    wrapper:\n        \"master/bio/pyroe/makesplicedintronic\"\n"
    },
    {
      "name": "test_pyroe_makesplicedunspliced",
      "input": {
        "fasta": "genome.fasta",
        "gtf": "annotation.gtf",
        "spliced": "extra_spliced.fasta",
        "unspliced": "extra_unspliced.fasta"
      },
      "output": {
        "gene_id_to_name": "gene_id_to_name.tsv",
        "fasta": "spliceu.fa",
        "g2g": "spliceu_g2g.tsv",
        "t2g_3col": "spliceu_t2g_3col.tsv",
        "t2g": "spliceu_t2g.tsv"
      },
      "log": {
        "default": "logs/pyroe.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/pyroe/makeunspliceunspliced/"
      },
      "input_types": [
        {
          "gtf": "Path to the genome annotation (GTF formatted)"
        },
        {
          "fasta": "Path to the genome sequence (Fasta formatted)"
        },
        {
          "spliced": "Optional path to additional spliced sequences (Fasta formatted)"
        },
        {
          "unspliced": "Optional path to unspliced sequences (Fasta formatted)"
        }
      ],
      "output_types": [
        {
          "fasta": "Path to spliced+unspliced sequences (Fasta formatted)"
        },
        {
          "gene_id_to_name": "Path to a TSV formatted text file containing gene_id <-> gene_name correspondence"
        },
        {
          "t2g_3col": "Path to a TSV formatted text file containing the transcript_id <-> gene_name <-> splicing status correspondence"
        },
        {
          "t2g": "Path to a TSV formatted text file containing the transcript_id <-> gene_name"
        },
        {
          "g2g": "Path to a TSV formatted text file containing the gene_id <-> gene_name"
        }
      ],
      "rule": "\nrule test_pyroe_makesplicedunspliced:\n    input:\n        fasta=\"genome.fasta\",\n        gtf=\"annotation.gtf\",\n        spliced=\"extra_spliced.fasta\",  # Optional path to additional spliced sequences (FASTA)\n        unspliced=\"extra_unspliced.fasta\",  # Optional path to additional unspliced sequences (FASTA)\n    output:\n        gene_id_to_name=\"gene_id_to_name.tsv\",\n        fasta=\"spliceu.fa\",\n        g2g=\"spliceu_g2g.tsv\",\n        t2g_3col=\"spliceu_t2g_3col.tsv\",\n        t2g=\"spliceu_t2g.tsv\",\n    threads: 1\n    log:\n        \"logs/pyroe.log\",\n    params:\n        extra=\"\",  # Optional parameters\n    wrapper:\n        \"master/bio/pyroe/makeunspliceunspliced/\"\n"
    },
    {
      "name": "test_pytmb",
      "input": {
        "vcf": "sample.bcf",
        "db_config": "dbconfig.yaml",
        "var_config": "varconfig.yaml",
        "bed": "regions.bed"
      },
      "output": {
        "res": "tmb.txt",
        "vcf": "tmp.vcf"
      },
      "log": {
        "default": "pytmb.log"
      },
      "params": {
        "extra": "--verbose"
      },
      "wrapper": {
        "default": "master/bio/tmb/pytmb"
      },
      "input_types": [
        {
          "vcf": "Path to input variants (`vcf`, `vcf.gz`, or `bcf` formatted)"
        },
        {
          "db_config": "Path to database config file (`yaml` formatted)"
        },
        {
          "var_config": "Path to variant config file (`yaml` formatted)"
        },
        {
          "bed": "Path to intervals file to compute effective genome size (`bed` formatted)"
        }
      ],
      "output_types": [
        {
          "res": "Path to TMB results"
        },
        {
          "vcf": "Optional path to variants considered for TMB calculation"
        }
      ],
      "rule": "rule test_pytmb:\n    input:\n        vcf=\"sample.bcf\",\n        db_config=\"dbconfig.yaml\",\n        var_config=\"varconfig.yaml\",\n        bed=\"regions.bed\",\n    output:\n        res=\"tmb.txt\",\n        vcf=\"tmp.vcf\",\n    log:\n        \"pytmb.log\",\n    params:\n        extra=\"--verbose\",\n    wrapper:\n        \"master/bio/tmb/pytmb\"\n"
    },
    {
      "name": "test_rseqc_bam_stat",
      "input": {
        "default": "a.bam"
      },
      "output": {
        "default": "a.stats"
      },
      "log": {
        "default": "bastat.log"
      },
      "params": {
        "extra": "--mapq 5"
      },
      "wrapper": {
        "default": "master/bio/rseqc/bam_stat"
      },
      "input_types": [
        "Path to BAM/SAM file(s) to summarize."
      ],
      "output_types": [
        "Path to summary"
      ],
      "rule": "rule test_rseqc_bam_stat:\n    input:\n        \"a.bam\",\n    output:\n        \"a.stats\",\n    threads: 1\n    params:\n        extra=\"--mapq 5\",\n    log:\n        \"bastat.log\",\n    wrapper:\n        \"master/bio/rseqc/bam_stat\"\n"
    },
    {
      "name": "test_rseqc_infer_experiment",
      "input": {
        "aln": "a.bam",
        "refgene": "genes.bed"
      },
      "output": {
        "default": "a.experiment.txt"
      },
      "log": {
        "default": "rseqc/infer_experiment.log"
      },
      "params": {
        "extra": "-s 4 -q 3"
      },
      "wrapper": {
        "default": "master/bio/rseqc/infer_experiment"
      },
      "input_types": [
        {
          "aln": "Path to SAM/BAM alignment file"
        },
        {
          "refgene": "Path to reference gene model in bed format"
        }
      ],
      "output_types": [
        "Path to text formated results"
      ],
      "rule": "rule test_rseqc_infer_experiment:\n    input:\n        aln=\"a.bam\",\n        refgene=\"genes.bed\",\n    output:\n        \"a.experiment.txt\",\n    log:\n        \"rseqc/infer_experiment.log\",\n    params:\n        extra=\"-s 4 -q 3\",\n    wrapper:\n        \"master/bio/rseqc/infer_experiment\"\n"
    },
    {
      "name": "test_rseqc_inner_distance",
      "input": {
        "aln": "A.bam",
        "refgene": "annotation.bed"
      },
      "output": {
        "reads_inner_distance": "a.txt",
        "freq": "freq.txt",
        "pdf": "a.pdf",
        "plot_r": "script.a.r"
      },
      "log": {
        "default": "rseqc.log"
      },
      "params": {
        "extra": "-k3 -q2"
      },
      "wrapper": {
        "default": "master/bio/rseqc/inner_distance"
      },
      "input_types": [
        {
          "aln": "Path to SAM/BAM input"
        },
        {
          "refgene": "Path to refgene model"
        }
      ],
      "output_types": [
        {
          "reads_inner_distance": "Optional path to per-read inner distance table"
        },
        {
          "pdf": "Optional path to pdf graph"
        },
        {
          "plot_r": "Optional Path to R script"
        },
        {
          "freq": "Optional path to inner distance frequence"
        }
      ],
      "rule": "rule test_rseqc_inner_distance:\n    input:\n        aln=\"A.bam\",\n        refgene=\"annotation.bed\",\n    output:\n        reads_inner_distance=\"a.txt\",\n        freq=\"freq.txt\",\n        pdf=\"a.pdf\",\n        plot_r=\"script.a.r\",\n    log:\n        \"rseqc.log\",\n    params:\n        extra=\"-k3 -q2\",\n    wrapper:\n        \"master/bio/rseqc/inner_distance\"\n"
    },
    {
      "name": "test_rseqc_read_distribution",
      "input": {
        "aln": "A.bam",
        "refgene": "annotation.bed"
      },
      "output": {
        "default": "a.read_distribution.txt"
      },
      "log": {
        "default": "rseqc.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/rseqc/read_distribution"
      },
      "input_types": [
        {
          "aln": "Path to SAM/BAM input file"
        },
        {
          "refgene": "Path to refgene model (BED)"
        }
      ],
      "output_types": [
        "Path to read distribution (txt)"
      ],
      "rule": "rule test_rseqc_read_distribution:\n    input:\n        aln=\"A.bam\",\n        refgene=\"annotation.bed\",\n    output:\n        \"a.read_distribution.txt\",\n    log:\n        \"rseqc.log\",\n    wrapper:\n        \"master/bio/rseqc/read_distribution\"\n"
    },
    {
      "name": "test_rseqc_read_duplication",
      "input": {
        "default": "A.bam"
      },
      "output": {
        "pos": "a.dup.pos.xls",
        "seq": "a.dup.seq.xls",
        "plot_r": "script.a_plot.R",
        "pdf": "a.pdf"
      },
      "log": {
        "default": "rseqc.log"
      },
      "params": {
        "extra": "-q 10"
      },
      "wrapper": {
        "default": "master/bio/rseqc/read_duplication"
      },
      "input_types": [
        "Path to SAM/BAM file"
      ],
      "output_types": [
        {
          "pos": "Optional path to read duplication rate determined from mapping position of read"
        },
        {
          "seq": "Optional path to read duplication rate determined from sequence of read"
        },
        {
          "plot_r": "Optional path to R script"
        },
        {
          "pdf": "Optional path to pdf-formatted graph"
        }
      ],
      "rule": "rule test_rseqc_read_duplication:\n    input:\n        \"A.bam\",\n    output:\n        pos=\"a.dup.pos.xls\",\n        seq=\"a.dup.seq.xls\",\n        plot_r=\"script.a_plot.R\",\n        pdf=\"a.pdf\",\n    log:\n        \"rseqc.log\",\n    params:\n        extra=\"-q 10\",\n    wrapper:\n        \"master/bio/rseqc/read_duplication\"\n"
    },
    {
      "name": "test_rseqc_read_gc",
      "input": {
        "default": "A.bam"
      },
      "output": {
        "xls": "A.gc_percent.xls",
        "plot_r": "A.script.r",
        "pdf": "A.plot.pdf"
      },
      "log": {
        "default": "rseqc.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/rseqc/read_gc"
      },
      "input_types": [
        "Path to SAM/BAM file"
      ],
      "output_types": [
        {
          "xls": "Optional path to gc percent table"
        },
        {
          "plot_r": "Optional path to R script"
        },
        {
          "pdf": "Optional path to PDF-formatted graph"
        }
      ],
      "rule": "rule test_rseqc_read_gc:\n    input:\n        \"A.bam\",\n    output:\n        xls=\"A.gc_percent.xls\",\n        plot_r=\"A.script.r\",\n        pdf=\"A.plot.pdf\",\n    log:\n        \"rseqc.log\",\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/rseqc/read_gc\"\n"
    },
    {
      "name": "test_salmon_decoy",
      "input": {
        "transcriptome": "transcriptome.fasta.gz",
        "genome": "genome.fasta.gz"
      },
      "output": {
        "gentrome": "gentrome.fasta.gz",
        "decoys": "decoys.txt"
      },
      "log": {
        "default": "decoys.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/salmon/decoys"
      },
      "input_types": [
        {
          "transcriptome": "Path to transcriptome sequences, fasta (gz/bz2) formatted."
        },
        {
          "genome": "Path to genome sequences, fasta (gz/bz2) formatted."
        }
      ],
      "output_types": [
        {
          "gentrome": "Path to gentrome, fasta (gz/bz2) formatted."
        },
        {
          "decoys": "Path to text file contianing decoy sequence names."
        }
      ],
      "rule": "rule test_salmon_decoy:\n    input:\n        transcriptome=\"transcriptome.fasta.gz\",\n        genome=\"genome.fasta.gz\",\n    output:\n        gentrome=\"gentrome.fasta.gz\",\n        decoys=\"decoys.txt\",\n    threads: 2\n    log:\n        \"decoys.log\"\n    wrapper:\n        \"master/bio/salmon/decoys\"\n"
    },
    {
      "name": "test_sexdeterrmine",
      "input": {
        "depth": "samples.depth.tsv"
      },
      "output": {
        "tsv": "results.tsv",
        "json": "results.json"
      },
      "log": {
        "default": "sexdeterrmine.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/sexdeterrmine"
      },
      "input_types": [
        {
          "depth": "Path to samtools depths file accross multiple samples with a header line giving sample names."
        }
      ],
      "output_types": [
        "Path to result table"
      ],
      "rule": "rule test_sexdeterrmine:\n    input:\n        depth=\"samples.depth.tsv\",\n    output:\n        tsv=\"results.tsv\",\n        json=\"results.json\",\n    threads: 1\n    log:\n        \"sexdeterrmine.log\",\n    wrapper:\n        \"master/bio/sexdeterrmine\"\n"
    },
    {
      "name": "test_snpsift_annotate",
      "input": {
        "call": "in.vcf",
        "database": "annotation.vcf"
      },
      "output": {
        "call": "annotated/out.vcf"
      },
      "log": {
        "default": "annotate.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/snpsift/annotate"
      },
      "input_types": [
        "A VCF-formatted file that is to be annoated",
        "A VCF-formatted annotation file"
      ],
      "output_types": [
        "A VCF-formatted file"
      ],
      "rule": "rule test_snpsift_annotate:\n    input:\n        call=\"in.vcf\",\n        database=\"annotation.vcf\"\n    output:\n        call=\"annotated/out.vcf\"\n    log:\n        \"annotate.log\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    wrapper:\n        \"master/bio/snpsift/annotate\"\n"
    },
    {
      "name": "test_snpsift_dbnsfp",
      "input": {
        "call": "in.vcf",
        "dbNSFP": "dbNSFP.txt.gz"
      },
      "output": {
        "call": "out.vcf"
      },
      "log": {},
      "params": {},
      "wrapper": {
        "default": "master/bio/snpsift/dbnsfp"
      },
      "input_types": [
        "Calls that are to be annoated",
        "A dnNSFP text file"
      ],
      "output_types": [
        "Annotated calls"
      ],
      "rule": "rule test_snpsift_dbnsfp:\n    input:\n        call = \"in.vcf\",\n        dbNSFP = \"dbNSFP.txt.gz\"\n    output:\n        call = \"out.vcf\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    wrapper:\n        \"master/bio/snpsift/dbnsfp\"\n"
    },
    {
      "name": "test_snpsift_gmt",
      "input": {
        "call": "in.vcf",
        "gmt": "fake_set.gmt"
      },
      "output": {
        "call": "annotated/out.vcf"
      },
      "log": {},
      "params": {},
      "wrapper": {
        "default": "master/bio/snpsift/genesets"
      },
      "input_types": [
        "Calls that are to be annotated",
        "A GMT-formatted annotation file"
      ],
      "output_types": [
        "Annotated calls"
      ],
      "rule": "rule test_snpsift_gmt:\n    input:\n        call = \"in.vcf\",\n        gmt = \"fake_set.gmt\"\n    output:\n        call = \"annotated/out.vcf\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    wrapper:\n        \"master/bio/snpsift/genesets\"\n"
    },
    {
      "name": "test_snpsift_gwascat",
      "input": {
        "call": "in.vcf",
        "gwascat": "gwascatalog.txt"
      },
      "output": {
        "call": "annotated/out.vcf"
      },
      "log": {},
      "params": {},
      "wrapper": {
        "default": "master/bio/snpsift/gwascat"
      },
      "input_types": [
        "Calls that are to be annotated (vcf, bcf, vcf.gz)",
        "A GWAS Catalog TSV-formatted file"
      ],
      "output_types": [
        "Annotated calls (vcf, bcf, vcf.gz)"
      ],
      "rule": "rule test_snpsift_gwascat:\n    input:\n        call = \"in.vcf\",\n        gwascat = \"gwascatalog.txt\"\n    output:\n        call = \"annotated/out.vcf\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    wrapper:\n        \"master/bio/snpsift/gwascat\"\n"
    },
    {
      "name": "test_snpsift_vartype",
      "input": {
        "vcf": "in.vcf"
      },
      "output": {
        "vcf": "annotated/out.vcf"
      },
      "log": {
        "default": "varType.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/snpsift/varType"
      },
      "input_types": [
        "A VCF-formatted file"
      ],
      "output_types": [
        "A VCF-formatted file"
      ],
      "rule": "rule test_snpsift_vartype:\n    input:\n        vcf=\"in.vcf\"\n    output:\n        vcf=\"annotated/out.vcf\"\n    message:\n        \"Testing SnpSift varType\"\n    # optional specification of memory usage of the JVM that snakemake will respect with global\n    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)\n    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:\n    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties\n    resources:\n        mem_mb=1024\n    log:\n        \"varType.log\"\n    wrapper:\n        \"master/bio/snpsift/varType\"\n"
    },
    {
      "name": "test_unicycler",
      "input": {
        "paired": "expand('reads/{sample}.{read}.fq.gz', read=['R1', 'R2'], allow_missing=True)"
      },
      "output": {
        "default": "result/{sample}/assembly.fasta"
      },
      "log": {
        "default": "logs/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/unicycler"
      },
      "input_types": [
        "Fastq-formatted reads"
      ],
      "output_types": [
        "Assembled reads"
      ],
      "rule": "rule test_unicycler:\n    input:\n        # R1 and R2 short reads:\n        paired = expand(\n            \"reads/{sample}.{read}.fq.gz\",\n            read=[\"R1\", \"R2\"],\n            allow_missing=True\n        )\n        # Long reads:\n        # long = long_reads/{sample}.fq.gz\n        # Unpaired reads:\n        # unpaired = reads/{sample}.fq.gz\n    output:\n        \"result/{sample}/assembly.fasta\"\n    log:\n        \"logs/{sample}.log\"\n    params:\n        extra=\"\"\n    wrapper:\n        \"master/bio/unicycler\"\n"
    },
    {
      "name": "toulligqc_sequencing_summary",
      "input": {
        "default": "demodata/sequencing_summary.txt"
      },
      "output": {
        "default": "toulligqc_sequencing_summary/report.html"
      },
      "log": {
        "default": "toulligqc_sequencing_summary/merged.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/toulligqc"
      },
      "input_types": [
        "path to input data. Can be either a sequencing summary file, fastq file (uncompressed/ compressed) or bam file."
      ],
      "output_types": [
        "report and plots of QC results"
      ],
      "rule": "rule toulligqc_sequencing_summary:\n    input:\n        \"demodata/sequencing_summary.txt\",\n    output:\n        \"toulligqc_sequencing_summary/report.html\",\n    log:\n        \"toulligqc_sequencing_summary/merged.log\",\n    params:\n        extra=\"\",  # optional additional parameters as string\n    wrapper:\n        \"master/bio/toulligqc\"\n\nrule toulligqc_bam:\n    input:\n        \"demodata/test.sorted.bam\",\n    output:\n        \"toulligqc_bam/report.html\",\n    log:\n        \"toulligqc_bam/merged.log\",\n    params:\n        extra=\"\",  # optional additional parameters as string\n    wrapper:\n        \"master/bio/toulligqc\"\n\nrule toulligqc_fastq:\n    input:\n        \"demodata/test.fastq.gz\",\n    output:\n        \"toulligqc_fastq/report.html\",\n    log:\n        \"toulligqc_fastq/merged.log\",\n    params:\n        extra=\"\",  # optional additional parameters as string\n    wrapper:\n        \"master/bio/toulligqc\""
    },
    {
      "name": "transdecoder_longorfs",
      "input": {
        "fasta": "test.fa.gz",
        "gene_trans_map": "test.gtm"
      },
      "output": {
        "default": "test.fa.transdecoder_dir/longest_orfs.pep"
      },
      "log": {
        "default": "logs/transdecoder/test-longorfs.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/transdecoder/longorfs"
      },
      "input_types": [
        "fasta transcripts"
      ],
      "output_types": [
        "ORFs peptide file(s)"
      ],
      "rule": "rule transdecoder_longorfs:\n    input:\n        fasta=\"test.fa.gz\", # required\n        gene_trans_map=\"test.gtm\" # optional gene-to-transcript identifier mapping file (tab-delimited, gene_id<tab>trans_id<return> )\n    output:\n        \"test.fa.transdecoder_dir/longest_orfs.pep\"\n    log:\n        \"logs/transdecoder/test-longorfs.log\"\n    params:\n        extra=\"\"\n    wrapper:\n        \"master/bio/transdecoder/longorfs\"\n"
    },
    {
      "name": "transdecoder_predict",
      "input": {
        "fasta": "test.fa.gz",
        "pfam_hits": "pfam_hits.txt",
        "blastp_hits": "blastp_hits.txt"
      },
      "output": {
        "default": "test.fa.transdecoder.bed"
      },
      "log": {
        "default": "logs/transdecoder/test-predict.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/transdecoder/predict"
      },
      "input_types": [
        "fasta assembly"
      ],
      "output_types": [
        "candidate coding regions (pep, cds, gff3, bed output formats)"
      ],
      "rule": "rule transdecoder_predict:\n    input:\n        fasta=\"test.fa.gz\", # required input; optionally gzipped\n        pfam_hits=\"pfam_hits.txt\", # optionally retain ORFs with hits by inputting pfam results here (run separately)\n        blastp_hits=\"blastp_hits.txt\", # optionally retain ORFs with hits by inputting blastp results here (run separately) \n        # you may also want to add your transdecoder longorfs result here - predict will fail if you haven't first run longorfs\n        #longorfs=\"test.fa.transdecoder_dir/longest_orfs.pep\"\n    output:\n        \"test.fa.transdecoder.bed\",\n        \"test.fa.transdecoder.cds\",\n        \"test.fa.transdecoder.pep\",\n        \"test.fa.transdecoder.gff3\"\n    log:\n        \"logs/transdecoder/test-predict.log\"\n    params:\n        extra=\"\"\n    wrapper:\n        \"master/bio/transdecoder/predict\"\n"
    },
    {
      "name": "trim_galore_pe",
      "input": {
        "default": [
          "reads/{sample}.1.fastq.gz",
          "reads/{sample}.2.fastq.gz"
        ]
      },
      "output": {
        "fasta_fwd": "trimmed/{sample}_R1.fq.gz",
        "report_fwd": "trimmed/reports/{sample}_R1_trimming_report.txt",
        "fasta_rev": "trimmed/{sample}_R2.fq.gz",
        "report_rev": "trimmed/reports/{sample}_R2_trimming_report.txt"
      },
      "log": {
        "default": "logs/trim_galore/{sample}.log"
      },
      "params": {
        "extra": "--illumina -q 20"
      },
      "wrapper": {
        "default": "master/bio/trim_galore/pe"
      },
      "input_types": [
        "two (paired-end) fastq files (can be gzip compressed)"
      ],
      "output_types": [
        "two trimmed (paired-end) fastq files",
        "two trimming reports"
      ],
      "rule": "rule trim_galore_pe:\n    input:\n        [\"reads/{sample}.1.fastq.gz\", \"reads/{sample}.2.fastq.gz\"],\n    output:\n        fasta_fwd=\"trimmed/{sample}_R1.fq.gz\",\n        report_fwd=\"trimmed/reports/{sample}_R1_trimming_report.txt\",\n        fasta_rev=\"trimmed/{sample}_R2.fq.gz\",\n        report_rev=\"trimmed/reports/{sample}_R2_trimming_report.txt\",\n    threads: 1\n    params:\n        extra=\"--illumina -q 20\",\n    log:\n        \"logs/trim_galore/{sample}.log\",\n    wrapper:\n        \"master/bio/trim_galore/pe\"\n\n\nrule trim_galore_pe_uncompressed:\n    input:\n        [\"reads/{sample}_R1.fastq\", \"reads/{sample}_R2.fastq\"],\n    output:\n        fasta_fwd=\"trimmed/{sample}_R1.fastq\",\n        report_fwd=\"trimmed/reports/{sample}_R1_trimming_report.txt\",\n        fasta_rev=\"trimmed/{sample}_R2.fastq\",\n        report_rev=\"trimmed/reports/{sample}_R2_trimming_report.txt\",\n    threads: 1\n    params:\n        extra=\"--illumina -q 20\",\n    log:\n        \"logs/trim_galore/{sample}.log\",\n    wrapper:\n        \"master/bio/trim_galore/pe\"\n"
    },
    {
      "name": "trim_galore_se",
      "input": {
        "default": "reads/{sample}.fastq.gz"
      },
      "output": {
        "fasta": "trimmed/{sample}_trimmed.fq.gz",
        "report": "trimmed/report/{sample}.fastq.gz_trimming_report.txt"
      },
      "log": {
        "default": "logs/trim_galore/{sample}.log"
      },
      "params": {
        "extra": "--illumina -q 20"
      },
      "wrapper": {
        "default": "master/bio/trim_galore/se"
      },
      "input_types": [
        "fastq file with untrimmed reads (can be gzip compressed)"
      ],
      "output_types": [
        "trimmed fastq file",
        "trimming report"
      ],
      "rule": "rule trim_galore_se:\n    input:\n        \"reads/{sample}.fastq.gz\",\n    output:\n        fasta=\"trimmed/{sample}_trimmed.fq.gz\",\n        report=\"trimmed/report/{sample}.fastq.gz_trimming_report.txt\",\n    params:\n        extra=\"--illumina -q 20\",\n    log:\n        \"logs/trim_galore/{sample}.log\",\n    wrapper:\n        \"master/bio/trim_galore/se\"\n\n\nrule trim_galore_se_uncompressed:\n    input:\n        \"reads/{sample}.fastq\",\n    output:\n        fasta=\"trimmed/{sample}_trimmed.fastq\",\n        report=\"trimmed/report/{sample}.fastq_trimming_report.txt\",\n    params:\n        extra=\"--illumina -q 20\",\n    threads: 1\n    log:\n        \"logs/trim_galore/{sample}.log\",\n    wrapper:\n        \"master/bio/trim_galore/se\"\n"
    },
    {
      "name": "trimmomatic_pe_fq_fq",
      "input": {
        "r1": "reads/{sample}.1.fastq",
        "r2": "reads/{sample}.2.fastq"
      },
      "output": {
        "r1": "trimmed/pe/fq_fq/{sample}.1.fastq",
        "r2": "trimmed/pe/fq_fq/{sample}.2.fastq",
        "r1_unpaired": "trimmed/pe/fq_fq/{sample}.1.unpaired.fastq",
        "r2_unpaired": "trimmed/pe/fq_fq/{sample}.2.unpaired.fastq"
      },
      "log": {
        "default": "logs/trimmomatic/pe/fq_fq/{sample}.log"
      },
      "params": {
        "trimmer": [
          "TRAILING:3"
        ],
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/trimmomatic"
      },
      "input_types": [
        {
          "r1": "fastq(gz) file"
        },
        {
          "r2": "fastq(gz) file (if PE)"
        }
      ],
      "output_types": [
        {
          "r1": "trimmed R1 fastq(gz) file"
        },
        {
          "r2": "trimmed R2 fastq(gz) file (if PE)"
        },
        {
          "r1_unpaired": "unpaired R1 fastq(gz) file (if PE)"
        },
        {
          "r2_unpaired": "unpaired R2 fastq(gz) file (if PE)"
        }
      ],
      "rule": "rule trimmomatic_pe_fq_fq:\n    input:\n        r1=\"reads/{sample}.1.fastq\",\n        r2=\"reads/{sample}.2.fastq\",\n    output:\n        r1=\"trimmed/pe/fq_fq/{sample}.1.fastq\",\n        r2=\"trimmed/pe/fq_fq/{sample}.2.fastq\",\n        # reads where trimming entirely removed the mate\n        r1_unpaired=\"trimmed/pe/fq_fq/{sample}.1.unpaired.fastq\",\n        r2_unpaired=\"trimmed/pe/fq_fq/{sample}.2.unpaired.fastq\",\n    log:\n        \"logs/trimmomatic/pe/fq_fq/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_pe_fq_gz:\n    input:\n        r1=\"reads/{sample}.1.fastq\",\n        r2=\"reads/{sample}.2.fastq\",\n    output:\n        r1=\"trimmed/pe/fq_gz/{sample}.1.fastq.gz\",\n        r2=\"trimmed/pe/fq_gz/{sample}.2.fastq.gz\",\n        # reads where trimming entirely removed the mate\n        r1_unpaired=\"trimmed/pe/fq_gz/{sample}.1.unpaired.fastq.gz\",\n        r2_unpaired=\"trimmed/pe/fq_gz/{sample}.2.unpaired.fastq.gz\",\n    log:\n        \"logs/trimmomatic/pe/fq_gz/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n        compression_level=\"-9\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_pe_gz_fq:\n    input:\n        r1=\"reads/{sample}.1.fastq.gz\",\n        r2=\"reads/{sample}.2.fastq.gz\",\n    output:\n        r1=\"trimmed/pe/gz_fq/{sample}.1.fastq\",\n        r2=\"trimmed/pe/gz_fq/{sample}.2.fastq\",\n        # reads where trimming entirely removed the mate\n        r1_unpaired=\"trimmed/pe/gz_fq/{sample}.1.unpaired.fastq\",\n        r2_unpaired=\"trimmed/pe/gz_fq/{sample}.2.unpaired.fastq\",\n    log:\n        \"logs/trimmomatic/pe/gz_fq/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_pe_gz_gz:\n    input:\n        r1=\"reads/{sample}.1.fastq.gz\",\n        r2=\"reads/{sample}.2.fastq.gz\",\n    output:\n        r1=\"trimmed/pe/gz_gz/{sample}.1.fastq.gz\",\n        r2=\"trimmed/pe/gz_gz/{sample}.2.fastq.gz\",\n        # reads where trimming entirely removed the mate\n        r1_unpaired=\"trimmed/pe/gz_gz/{sample}.1.unpaired.fastq.gz\",\n        r2_unpaired=\"trimmed/pe/gz_gz/{sample}.2.unpaired.fastq.gz\",\n    log:\n        \"logs/trimmomatic/pe/gz_gz/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n        compression_level=\"-9\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_se_fq_fq:\n    input:\n        \"reads/{sample}.fastq\",\n    output:\n        \"trimmed/se/fq_fq/{sample}.fastq\",\n    log:\n        \"logs/trimmomatic/se/fq_fq/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_se_fq_gz:\n    input:\n        \"reads/{sample}.fastq\",\n    output:\n        \"trimmed/se/fq_gz/{sample}.fastq.gz\",\n    log:\n        \"logs/trimmomatic/se/fq_gz/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # compression levels from -0 to -9 and -11\n        compression_level=\"-5\",\n        # optional parameters\n        extra=\"\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_se_gz_fq:\n    input:\n        \"reads/{sample}.fastq.gz\",\n    output:\n        \"trimmed/se/gz_fq/{sample}.fastq\",\n    log:\n        \"logs/trimmomatic/se/gz_fq/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n\n\nrule trimmomatic_se_gz_gz:\n    input:\n        \"reads/{sample}.fastq.gz\",\n    output:\n        \"trimmed/se/gz_gz/{sample}.fastq.gz\",\n    log:\n        \"logs/trimmomatic/se/gz_gz/{sample}.log\",\n    params:\n        # list of trimmers (see manual)\n        trimmer=[\"TRAILING:3\"],\n        # optional parameters\n        extra=\"\",\n        # optional compression levels from -0 to -9 and -11\n        compression_level=\"-9\",\n    threads: 32\n    resources:\n        mem_mb=1024,\n    wrapper:\n        \"master/bio/trimmomatic\"\n"
    },
    {
      "name": "trinity",
      "input": {
        "left": [
          "reads/reads.left.fq.gz",
          "reads/reads2.left.fq.gz"
        ],
        "right": [
          "reads/reads.right.fq.gz",
          "reads/reads2.right.fq.gz"
        ]
      },
      "output": {
        "dir": "temp(directory('trinity_out_dir/'))",
        "fas": "trinity_out_dir.Trinity.fasta",
        "map": "trinity_out_dir.Trinity.fasta.gene_trans_map"
      },
      "log": {
        "default": "logs/trinity/trinity.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/trinity"
      },
      "input_types": [
        "fastq files"
      ],
      "output_types": [
        {
          "fas": "fasta containing assembly"
        },
        {
          "map": "gene transcripts map"
        },
        {
          "dir": "folder for intermediate results"
        }
      ],
      "rule": "\nrule trinity:\n    input:\n        left=[\"reads/reads.left.fq.gz\", \"reads/reads2.left.fq.gz\"],\n        right=[\"reads/reads.right.fq.gz\", \"reads/reads2.right.fq.gz\"],\n    output:\n        dir=temp(directory(\"trinity_out_dir/\")),\n        fas=\"trinity_out_dir.Trinity.fasta\",\n        map=\"trinity_out_dir.Trinity.fasta.gene_trans_map\",\n    log:\n        'logs/trinity/trinity.log',\n    params:\n        extra=\"\",\n    threads: 4\n    resources:\n        mem_gb=10,\n    wrapper:\n        \"master/bio/trinity\"\n"
    },
    {
      "name": "twoBitInfo",
      "input": {
        "default": "{sample}.2bit"
      },
      "output": {
        "default": "{sample}.chrom.sizes"
      },
      "log": {
        "default": "logs/{sample}.chrom.sizes.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/ucsc/twoBitInfo"
      },
      "input_types": [
        "Path to genome \\*.2bit file"
      ],
      "output_types": [
        "Path to output \\*.chrom.sizes file"
      ],
      "rule": "rule twoBitInfo:\n    input:\n        \"{sample}.2bit\"\n    output:\n        \"{sample}.chrom.sizes\"\n    log:\n        \"logs/{sample}.chrom.sizes.log\"\n    params:\n        \"\" # optional params string\n    wrapper:\n        \"master/bio/ucsc/twoBitInfo\"\n"
    },
    {
      "name": "twoBitToFa",
      "input": {
        "default": "{sample}.2bit"
      },
      "output": {
        "default": "{sample}.fa"
      },
      "log": {
        "default": "logs/{sample}.2bit_to_fa.log"
      },
      "params": {
        "default": ""
      },
      "wrapper": {
        "default": "master/bio/ucsc/twoBitToFa"
      },
      "input_types": [
        "Path to genome \\*.2bit file"
      ],
      "output_types": [
        "Path to output '\\*.fa' file"
      ],
      "rule": "rule twoBitToFa:\n    input:\n        \"{sample}.2bit\"\n    output:\n        \"{sample}.fa\"\n    log:\n        \"logs/{sample}.2bit_to_fa.log\"\n    params:\n        \"\" # optional params string\n    wrapper:\n        \"master/bio/ucsc/twoBitToFa\"\n"
    },
    {
      "name": "tximport",
      "input": {
        "quant": "expand('quant/A/quant.sf')"
      },
      "output": {
        "txi": "txi.RDS"
      },
      "log": {},
      "params": {
        "extra": "type='salmon', txOut=TRUE"
      },
      "wrapper": {
        "default": "master/bio/tximport"
      },
      "input_types": [
        "A list of paths to count data"
      ],
      "output_types": [
        "A tximport RDS object"
      ],
      "rule": "rule tximport:\n    input:\n        quant = expand(\"quant/A/quant.sf\")\n        # Optional transcript/gene links as described in tximport\n        # tx2gene = /path/to/tx2gene\n    output:\n        txi = \"txi.RDS\"\n    params:\n        extra = \"type='salmon', txOut=TRUE\"\n    wrapper:\n        \"master/bio/tximport\"\n"
    },
    {
      "name": "umis_bamtag",
      "input": {
        "default": "data/{sample}.bam"
      },
      "output": {
        "default": "data/{sample}.annotated.bam"
      },
      "log": {
        "default": "logs/umis/bamtag/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/umis/bamtag"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule umis_bamtag:\n    input:\n        \"data/{sample}.bam\"\n    output:\n        \"data/{sample}.annotated.bam\"\n    log:\n        \"logs/umis/bamtag/{sample}.log\"\n    params:\n        extra=\"\"\n    threads: 1\n    wrapper:\n        \"master/bio/umis/bamtag\"\n"
    },
    {
      "name": "vardict_single_mode",
      "input": {
        "reference": "data/genome.fasta",
        "regions": "regions.bed",
        "bam": "mapped/{sample}.bam"
      },
      "output": {
        "vcf": "vcf/{sample}.s.vcf"
      },
      "log": {
        "default": "logs/varscan_{sample}_s_.log"
      },
      "params": {
        "extra": "",
        "bed_columns": "-c 1 -S 2 -E 3 -g 4",
        "allele_frequency_threshold": "0.01"
      },
      "wrapper": {
        "default": "master/bio/vardict"
      },
      "input_types": [
        "reference file",
        "bam file",
        "normal file, optional (must be set for tumor/normal mode)",
        "region file"
      ],
      "output_types": [
        "A VCF file"
      ],
      "rule": "rule vardict_single_mode:\n    input:\n        reference=\"data/genome.fasta\",\n        regions=\"regions.bed\",\n        bam=\"mapped/{sample}.bam\",\n    output:\n        vcf=\"vcf/{sample}.s.vcf\",\n    params:\n        extra=\"\",\n        bed_columns=\"-c 1 -S 2 -E 3 -g 4\",  # Optional, default is -c 1 -S 2 -E 3 -g 4\n        allele_frequency_threshold=\"0.01\",  # Optional, default is 0.01\n    threads: 1\n    log:\n        \"logs/varscan_{sample}_s_.log\",\n    wrapper:\n        \"master/bio/vardict\"\n\n\nrule vardict_paired_mode:\n    input:\n        reference=\"data/genome.fasta\",\n        regions=\"regions.bed\",\n        bam=\"mapped/{sample}.bam\",\n        normal=\"mapped/b.bam\",\n    output:\n        vcf=\"vcf/{sample}.tn.vcf\",\n    params:\n        extra=\"\",\n    threads: 1\n    log:\n        \"logs/varscan_{sample}_tn.log\",\n    wrapper:\n        \"master/bio/vardict\"\n"
    },
    {
      "name": "varlociraptor_alignment_properties",
      "input": {
        "ref": "resources/genome.fasta",
        "alignments": "results/alignments/{sample}.bam",
        "ref_idx": "resources/genome.fasta.fai",
        "aln_idx": "results/alignments/{sample}.bam.bai"
      },
      "output": {
        "default": "results/alignment-properties/{sample}.json"
      },
      "log": {
        "default": "logs/varlociraptor/alignment-properties/{sample}.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/varlociraptor/estimate-alignment-properties"
      },
      "input_types": [
        "preprocessed observations for the samples in the scenario (if a sample is omitted, it will be treated as if there are no observations available)",
        "a scenario"
      ],
      "output_types": [
        "variants calls"
      ],
      "rule": "rule varlociraptor_alignment_properties:  # [hide]\n    input:  # [hide]\n        ref=\"resources/genome.fasta\",  # [hide]\n        alignments=\"results/alignments/{sample}.bam\",  # [hide]\n        ref_idx=\"resources/genome.fasta.fai\",  # [hide]\n        aln_idx=\"results/alignments/{sample}.bam.bai\",  # [hide]\n    output:  # [hide]\n        \"results/alignment-properties/{sample}.json\",  # [hide]\n    log:  # [hide]\n        \"logs/varlociraptor/alignment-properties/{sample}.log\",  # [hide]\n    wrapper:  # [hide]\n        \"master/bio/varlociraptor/estimate-alignment-properties\"  # [hide]\n\n\nrule varlociraptor_preprocess:  # [hide]\n    input:  # [hide]\n        ref=\"resources/genome.fasta\",  # [hide]\n        alignment_properties=\"results/alignment-properties/{sample}.json\",  # [hide]\n        alignments=\"results/alignments/{sample}.bam\",  # [hide]\n        candidate_variants=\"results/candidate-variants/{sample}.vcf\",  # [hide]\n    output:  # [hide]\n        \"results/observations/{sample}.bcf\",  # [hide]\n    log:  # [hide]\n        \"logs/varlociraptor/preprocess/{sample}.log\",  # [hide]\n    wrapper:  # [hide]\n        \"master/bio/varlociraptor/preprocess-variants\"  # [hide]\n\n\nrule varlociraptor_call:\n    input:\n        # collect preprocessed observations for the considered sample group\n        # Use lookup or a custom function to obtain the list of samples \n        # for the given sample group here\n        # and below in the params specification.\n        # Example: lookup(query=\"group == '{sample_group}'\", cols=[\"sample\"], within=samples)\n        # assuming that samples in a pandas dataframe.\n        observations=collect(\"results/observations/{sample}.bcf\", sample=[\"NA12878\"]),\n        scenario=\"resources/scenarios/{sample_group}.yaml\",\n    output:\n        \"results/variant-calls/{sample_group}.bcf\",\n    log:\n        \"logs/varlociraptor/call-variants/{sample_group}.log\",\n    params:\n        samples=[\"NA12878\"],\n        extra=\"\",  # optional additional parameters\n    wrapper:\n        \"master/bio/varlociraptor/call-variants\"\n"
    },
    {
      "name": "varscan_somatic_single_mpileup",
      "input": {
        "default": "mpileup/{sample}.mpileup.gz"
      },
      "output": {
        "snp": "single_mpileup/vcf/{sample}.snp.vcf",
        "indel": "single_mpileup/vcf/{sample}.indel.vcf"
      },
      "log": {
        "default": "logs/single_mpileup/{sample}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/varscan/somatic"
      },
      "input_types": [
        "A pair of pileup files (Normal/Tumor)"
      ],
      "output_types": [
        "A VCF file"
      ],
      "rule": "rule varscan_somatic_single_mpileup:\n    input:\n        \"mpileup/{sample}.mpileup.gz\",\n    output:\n        snp=\"single_mpileup/vcf/{sample}.snp.vcf\",\n        indel=\"single_mpileup/vcf/{sample}.indel.vcf\",\n    log:\n        \"logs/single_mpileup/{sample}.log\",\n    message:\n        \"Calling somatic variants from sample {wildcards.sample} using a normal-tumor file\"\n    threads: 1\n    resources:\n        mem_mb=1024,\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/varscan/somatic\"\n\n\nrule varscan_somatic_dual_mpileup:\n    input:\n        \"mpileup/{sample}.mpileup.gz\",\n        \"mpileup/{sample}.tumor.mpileup.gz\",\n    output:\n        snp=\"dual_mpileup/vcf/{sample}.snp.vcf\",\n        indel=\"dual_mpileup/vcf/{sample}.indel.vcf\",\n    log:\n        \"logs/dual_mpileup/{sample}.log\",\n    message:\n        \"Calling somatic variants from sample {wildcards.sample} using both normal and tumor files.\"\n    threads: 1\n    resources:\n        mem_mb=1024,\n    params:\n        extra=\"\",\n    wrapper:\n        \"master/bio/varscan/somatic\"\n"
    },
    {
      "name": "vembrane_filter",
      "input": {
        "vcf": "in.vcf"
      },
      "output": {
        "vcf": "filtered/out.vcf"
      },
      "log": {
        "default": "logs/vembrane.log"
      },
      "params": {
        "expression": "POS > 4000",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/vembrane/filter"
      },
      "input_types": [
        "A VCF-formatted file"
      ],
      "output_types": [
        "A VCF-formatted file"
      ],
      "rule": "rule vembrane_filter:\n    input:\n        vcf=\"in.vcf\",\n    output:\n        vcf=\"filtered/out.vcf\"\n    params:\n        expression=\"POS > 4000\",\n        extra=\"\"\n    log:\n        \"logs/vembrane.log\"\n    wrapper:\n        \"master/bio/vembrane/filter\"\n"
    },
    {
      "name": "vembrane_table",
      "input": {
        "vcf": "in.vcf"
      },
      "output": {
        "vcf": "table/out.tsv"
      },
      "log": {
        "default": "logs/vembrane.log"
      },
      "params": {
        "expression": "CHROM, POS, ALT, REF",
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/vembrane/table"
      },
      "input_types": [
        "A VCF-formatted file"
      ],
      "output_types": [
        "A table-like textfile"
      ],
      "rule": "rule vembrane_table:\n    input:\n        vcf=\"in.vcf\",\n    output:\n        vcf=\"table/out.tsv\"\n    params:\n        expression=\"CHROM, POS, ALT, REF\",\n        extra=\"\"\n    log:\n        \"logs/vembrane.log\"\n    wrapper:\n        \"master/bio/vembrane/table\"\n"
    },
    {
      "name": "verify_bam_id",
      "input": {
        "bam": "a.bam",
        "ref": "genome.fasta",
        "svd_mu": "ref.vcf.mu"
      },
      "output": {
        "selfsm": "a.selfSM",
        "ancestry": "a.ancestry"
      },
      "log": {
        "default": "logs/verifybamid2/a.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/verifybamid/verifybamid2"
      },
      "input_types": [
        "bam file"
      ],
      "output_types": [
        "estimated intraspacies contamination"
      ],
      "rule": "rule verify_bam_id:\n    input:\n        bam=\"a.bam\",\n        ref=\"genome.fasta\",\n        # optional - this can be used to specify custom resource files if\n        # necessary (if using GRCh37 or GRCh38 instead simply specify\n        # params.genome_build=\"38\", for example)\n        # N.B. if svd_mu={prefix}.mu, then {prefix}.bed, {prefix}.UD, and\n        # {prefix}.V must also exist\n        svd_mu=\"ref.vcf.mu\",\n    output:\n        selfsm=\"a.selfSM\",\n        ancestry=\"a.ancestry\",\n    params:\n        # optional - see note for input.svd_mu\n        # current choices are {37,38}\n        # genome_build=\"38\",\n    log:\n        \"logs/verifybamid2/a.log\",\n    wrapper:\n        \"master/bio/verifybamid/verifybamid2\"\n"
    },
    {
      "name": "vg_autoindex_giraffe",
      "input": {
        "ref": "{genome}.fasta"
      },
      "output": {
        "default": "multiext('resources/{genome}', '.dist', '.shortread.zipcodes', '.shortread.withzip.min', '.giraffe.gbz')"
      },
      "log": {
        "default": "logs/autoindex/{genome}.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/vg/autoindex"
      },
      "input_types": [
        {
          "ref": "FASTA reference"
        },
        {
          "vcf": "haplotypes in vcf format (optional)"
        }
      ],
      "output_types": [
        "GBZ graph (.giraffe.gbz)",
        "Distance index (.dist)",
        "Minimizer index (.shortread.withzip.min)",
        "Zipcodes (.shortread.zipcodes)"
      ],
      "rule": "rule vg_autoindex_giraffe:\n    input:\n        ref=\"{genome}.fasta\",\n        # Optional vcf file containing haplotypes for graph creation\n        #vcf=\"\",\n    output:\n        multiext(\"resources/{genome}\", \".dist\", \".shortread.zipcodes\", \".shortread.withzip.min\", \".giraffe.gbz\"),\n    log:\n        \"logs/autoindex/{genome}.log\",\n    params:\n        extra=\"\",\n    threads: 8\n    wrapper:\n        \"master/bio/vg/autoindex\"\n\n\nrule vg_autoindex_map:\n    input:\n        ref=\"{genome}.fasta\",\n        # Optional vcf file containing haplotypes for graph creation\n        #vcf=\"\",\n    output:\n        multiext(\"resources/{genome}\", \".xg\", \".gcsa\", \".gcsa.lcp\"),\n    log:\n        \"logs/autoindex/{genome}.log\",\n    params:\n        extra=\"\",\n    threads: 8\n    wrapper:\n        \"master/bio/vg/autoindex\"\n"
    },
    {
      "name": "vg_giraffe_map",
      "input": {
        "reads": [
          "reads/{sample}.1.fastq",
          "reads/{sample}.2.fastq"
        ],
        "graph": "resources/{sample}.gbz"
      },
      "output": {
        "bam": "mapped/{sample}.bam",
        "indexes": "multiext('resources/{sample}', '.dist', '.shortread.withzip.min', '.shortread.zipcodes')"
      },
      "log": {
        "default": "logs/vg_giraffe/{sample}.log"
      },
      "params": {
        "extra": "",
        "sorting": "none",
        "sort_order": "queryname",
        "sort_extra": ""
      },
      "wrapper": {
        "default": "master/bio/vg/giraffe"
      },
      "input_types": [
        "FASTQ file(s)",
        "reference graph"
      ],
      "output_types": [
        "BAM/SAM or CRAM file"
      ],
      "rule": "rule vg_giraffe_map:\n    input:\n        reads=[\"reads/{sample}.1.fastq\", \"reads/{sample}.2.fastq\"],\n        graph=\"resources/{sample}.gbz\",\n        #kmers=\"resources/{sample}.kff\", # optional: kmer counts\n        #hapl=\"resources/{genome}.hapl\", # optional: haplotype index\n    output:\n        bam=\"mapped/{sample}.bam\",\n        indexes=multiext(\n            \"resources/{sample}\",\n            \".dist\",\n            \".shortread.withzip.min\",\n            \".shortread.zipcodes\",\n        ),\n    log:\n        \"logs/vg_giraffe/{sample}.log\",\n    params:\n        extra=\"\",\n        sorting=\"none\",  # Can be 'none', 'samtools' or 'picard'.\n        sort_order=\"queryname\",  # Can be 'queryname' or 'coordinate'.\n        sort_extra=\"\",  # Extra args for samtools/picard.\n    threads: 8\n    wrapper:\n        \"master/bio/vg/giraffe\"\n"
    },
    {
      "name": "vsearch_cluster_fast",
      "input": {
        "cluster_fast": "reads/{sample}.fasta"
      },
      "output": {
        "profile": "out/cluster_fast/{sample}.profile"
      },
      "log": {
        "vsearch": "out/maskfasta/{sample}.log"
      },
      "params": {
        "extra": "--id 0.2 --sizeout --minseqlength 5"
      },
      "wrapper": {
        "default": "master/bio/vsearch"
      },
      "input_types": [
        "input file(s)"
      ],
      "output_types": [
        "output file(s)"
      ],
      "rule": "rule vsearch_cluster_fast:\n    input:\n        cluster_fast=\"reads/{sample}.fasta\",\n    output:\n        profile=\"out/cluster_fast/{sample}.profile\",\n    log:\n        \"logs/vsearch/cluster_fast/{sample}.log\",\n        vsearch=\"out/maskfasta/{sample}.log\",\n    params:\n        extra=\"--id 0.2 --sizeout --minseqlength 5\",\n    threads: 1\n    wrapper:\n        \"master/bio/vsearch\"\n\n\nrule vsearch_maskfasta:\n    input:\n        maskfasta=\"reads/{sample}.fasta\",\n    output:\n        output=\"out/maskfasta/{sample}.fasta\",\n    log:\n        \"logs/vsearch/maskfasta/{sample}.log\",\n        vsearch=\"out/maskfasta/{sample}.log\",\n    params:\n        extra=\"--hardmask\",\n    threads: 1\n    wrapper:\n        \"master/bio/vsearch\"\n\n\nrule vsearch_fastx_uniques:\n    input:\n        fastx_uniques=\"reads/{sample}.fastq\",\n    output:\n        fastqout=\"out/fastx_uniques/{sample}.fastq\",\n    log:\n        \"logs/vsearch/fastx_uniques/{sample}.log\",\n        vsearch=\"out/fastx_uniques/{sample}.log\",\n    params:\n        extra=\"--strand both --minseqlength 5\",\n    threads: 1\n    wrapper:\n        \"master/bio/vsearch\"\n\n\nrule vsearch_fastx_uniques_gzip:\n    input:\n        fastx_uniques=\"reads/{sample}.fastq\",\n    output:\n        fastqout=\"out/fastx_uniques/{sample}.fastq.gz\",\n    log:\n        \"logs/vsearch/fastx_uniques/{sample}.log\",\n        vsearch=\"out/fastx_uniques/{sample}.log\",\n    params:\n        extra=\"--strand both --minseqlength 5\",\n    threads: 2\n    wrapper:\n        \"master/bio/vsearch\"\n\n\nrule vsearch_fastx_uniques_bzip2:\n    input:\n        fastx_uniques=\"reads/{sample}.fastq\",\n    output:\n        fastqout=\"out/fastx_uniques/{sample}.fastq.bz2\",\n    log:\n        \"logs/vsearch/fastx_uniques/{sample}.log\",\n        vsearch=\"out/fastx_uniques/{sample}.log\",\n    params:\n        extra=\"--strand both --minseqlength 5\",\n    threads: 2\n    wrapper:\n        \"master/bio/vsearch\"\n\n\nrule vsearch_fastq_convert:\n    input:\n        fastq_convert=\"reads/{sample}.fastq\",\n    output:\n        fastqout=\"out/fastq_convert/{sample}.fastq\",\n    log:\n        \"logs/vsearch/fastq_convert/{sample}.log\",\n        vsearch=\"out/fastq_convert/{sample}.log\",\n    params:\n        extra=\"--fastq_ascii 33 --fastq_asciiout 64\",\n    threads: 2\n    wrapper:\n        \"master/bio/vsearch\"\n"
    },
    {
      "name": "wgsim",
      "input": {
        "ref": "genome.fa"
      },
      "output": {
        "read1": "reads/1.fq",
        "read2": "reads/2.fq"
      },
      "log": {
        "default": "logs/wgsim/sim.log"
      },
      "params": {
        "default": "-X 0 -R 0 -r 0.1 -h"
      },
      "wrapper": {
        "default": "master/bio/wgsim"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule wgsim:\n    input:\n        ref=\"genome.fa\"\n    output:\n        read1=\"reads/1.fq\",\n        read2=\"reads/2.fq\"\n    log:\n        \"logs/wgsim/sim.log\"\n    params:\n        \"-X 0 -R 0 -r 0.1 -h\"\n    wrapper:\n        \"master/bio/wgsim\"\n"
    },
    {
      "name": "whatshap_haplotag",
      "input": {
        "vcf": "phased.vcf.gz",
        "aln": "alignment.bam",
        "ref": "reference.fasta"
      },
      "output": {
        "default": "alignment.phased.bam"
      },
      "log": {
        "default": "logs/haplotag.10X.phased.log"
      },
      "params": {
        "extra": ""
      },
      "wrapper": {
        "default": "master/bio/whatshap/haplotag"
      },
      "input_types": [
        {
          "vcf": "Path to vcf.gz/bcf file of phased SNPs."
        },
        "Path to vcf index file (.tbi for vcf.gz, .csi for .bcf).",
        {
          "aln": "Path to alignments for the sample in BAM/CRAM format."
        },
        "Path to alignment index file in .bai/.crai format.",
        {
          "ref": "Path to FASTA reference used to create vcf file."
        },
        "Path to FASTA index file in .fai format"
      ],
      "output_types": "Path to output phased BAM file.",
      "rule": "rule whatshap_haplotag:\n    input:\n        \"phased.vcf.gz.tbi\",\n        \"alignment.bam.bai\", \n        \"reference.fasta.fai\",\n        vcf =\"phased.vcf.gz\",\n        aln =\"alignment.bam\",\n        ref = \"reference.fasta\"\n    output:\n        \"alignment.phased.bam\"\n    params:\n        extra=\"\" # optionally use --ignore-linked-read, --tag-supplementary, etc.\n    log:\n        \"logs/haplotag.10X.phased.log\"\n    threads: 4\n    wrapper:\n        \"master/bio/whatshap/haplotag\"\n"
    },
    {
      "name": "xg",
      "input": {
        "vgs": "x.vg"
      },
      "output": {
        "xg": "index/x.xg"
      },
      "log": {
        "default": "logs/vg/index/xg/x.log"
      },
      "params": {},
      "wrapper": {
        "default": "master/bio/vg/index/xg"
      },
      "input_types": "undefined",
      "output_types": "undefined",
      "rule": "rule xg:\n    input:\n        vgs=\"x.vg\"\n    output:\n        xg=\"index/x.xg\"\n    log:\n        \"logs/vg/index/xg/x.log\"\n    threads:\n        4\n    wrapper:\n        \"master/bio/vg/index/xg\"\n"
    }
  ]
}